1、线程概述
    几乎所有的操作系统都支持同时运行多个任务，一个任务通常就是一个程序，每个运行中的程序就是一个进程。
    当一个程序运行时，内部可能包含了多个顺序执行流，每个顺序执行流就是一个线程。
2、线程和进程
    几乎所有的操作系统都有进程的概念，所有运行中的任务通常对应一条进程。当一个程序进入内存运行，就是一个进程了。
    进程是处于运行中的程序，具有一定的独立能力，进程是系统进行资源分配和调度的一个独立单位。
  进程特征：
    A、独立性：进程是系统中独立存在的实体，可以拥有自己独立的资源，每个进程都拥有自己的私有地址地址。
            在没有经过进程本身允许的情况下，一个用户进程不可以访问其他进程地址空间。
    B、动态性：进程和程序的区别在于，程序只是一个静态的指令集合，而进程是一个正在系统中活动的指令集合。
            在程序中加入了时间概念，进程具有自己的生命周期和各种不同的状态，这些概念是程序不具备的。
    C、并发性：多个进程可以在单个处理器上并发执行，多个进程之间不会互相影响。
 
    多线程则扩展了多进程的概念，使得同一个进程可以同时并发处理多个任务。线程也被称为轻量级进程(Lightweight Process)，线程是进程的执行单元。
就像进程在操作系统中的地位一样，线程在程序中是独立、并发执行流。当进程被初始化后，主线程就被创建。对于绝大多数应用程序来说，通常仅要一个主线程，
但我们也可以在该进程内创建多条顺序执行流，这些顺序执行流就是线程，每条线程也互相独立的。
    线程是进程的组成部分，一个进程可以拥有多个线程，一个线程必须有一个父进程。线程可以拥有自己的堆、栈、程序计数器、局部变量，但不能拥有系统资源，
它与父进程的其他线程共享该进程所有的全部资源。因为多个线程共享父进程的全部资源。
    线程可以完成一定的任务，可与其他线程共享父进程中的变量和部分环境，相互之间协作共同完成进程所要完成的任务。
    线程是独立运行的，它并不知道进程中是否还有其他进程存在。线程的执行是抢占方式的，也就是说，当前运行的线程在任何时候都可以被挂起，以便其他线程运行。
一个线程可以创建和撤销另一个线程，同一个进程中的多个线程可以并发执行。
综述：一个程序运行后至少有一个进程，一个进程可以包含多个线程。至少包含一个线程。
    
3、并发和并行
    并发性(concurrency)和并行性(parallel)是两个概念；
    并行指在同一时刻，有多条指令（线程）在多个处理器上同时执行；
    并发指在同一时刻只能有一个指令（线程）执行，但多个进程指令被快速轮换执行，使得宏观上具有多个进程同时执行的效果。
4、多线程的优势
    线程划分尺度小于进程，使得多线程划分的并发性高。进程在执行时有自己独立的单元，多个线程共享内存，从而提高了运行效率。
    线程比进程具有更高的性能，这是由于同一个进程中的线程都有共性：多个线程将共享同一个进程的虚拟空间。
    线程共性的环境包括：进程代码段、进程共有数据等。线程很容易就利用共性的数据进行通信。
    当操作系统创建一个进程时，必须给该进程分别独立的内存空间，并分配大量相关的资源；但创建一个线程则简单得多，因此多线程来实现并发要比多进程实现并发的性能高得多。
多线程优点：
    A、进程之间不能共享内存，但线程之间共享内存非常容易。
    B、系统创建进程需要为该进程重新分配系统资源，但创建线程则代价要小得多，因此使用线程来实现多任务并发比多进程的效率高。
    C、Java语言内置多线程功能支持，而不是单纯的作为底层操作系统的调度方式，从而简化Java的多线程编程。
5、线程的创建和启动
    A、继承Thread类或实现Runnable接口，重写或实现run方法，run方法代表线程要完成的任务
    B、创建Thread子类或是Runnable的实现类，即创建的线程对象；不同的是接口实现线程，
        需要将接口的实现类作为参数传递给Thread类的构造参数
    C、用线程对象的start方法启动线程
 
6、继承Thread和实现Runnable接口创建线程的区别
    采用Runnable接口实现线程：
    优势：
        A、线程类只是实现了Runnable接口，还可以继承其他的类
        B、在这种方式下，可以多个线程共享同一个目标对象，所以很合适多个线程来处理同一份资源的情况，
            从而可以将CPU、代码和数据分开，形成清晰的模型，较好的面相对象思想。
    劣势：编程稍微复杂，如果需要访问当前线程需要用Thread.currentThread方法来获取
 
    采用继承Thread类的方式实现线程：
    优势：编写简单，如果要获得当前线程直接this即可
    劣势：线程类继承了Thread，不能在继承其他类
    相对而言，用Runnable的方式更好，具体可以根据当前需要而定；
 
7、线程生命周期
    线程被创建启动后，不并不是启动后就进入了执行状态，也不是一直处于的执行状态。
    线程的生命周期分为创建（new）、就绪（Runnable）、运行（running）、阻塞（Blocked）、死亡（Dead）五种状态。
    线程启动后不会一直霸占CPU资源，所以CPU需要在多条线程中切换执行，线程就会在多次的运行和阻塞中切换。
 
8、新建（new）和就绪（Runnable）状态
    当new一个线程后，该线程处于新建状态，此时它和Java对象一样，仅仅由Java虚拟机为其分配内存空间，并初始化成员变量。
    此时线程对象没有表现出任何的动态特征，程序也不会执行线程的执行体。
    注意：run方法是线程的执行体，不能由我们手动调用。我们可以用start方法启动线程，系统会把run方法当成线程的执行体来运行，
    如果直接调用线程对象run方法，则run方法立即会被运行。而且在run方法返回之前其他线程无法并行执行，
    也就是说系统会把当前线程类当成一个普通的Java对象，而run方法也是一个普通的方法，而不是线程的执行体。
 
9、运行（running）和阻塞（Blocked）状态
    如果处于就绪状态的线程就获得了CPU，开始执行run方法的线程执行体，则该线程处于运行状态。
    单CPU的机器，任何时刻只有一条线程处于运行状态。当然，在多CPU机器上将会有多线程并行（parallel）执行，
    当线程大于CPU数量时，依然会在同一个CPU上切换执行。
    线程运行机制：一个线程运行后，它不可能一直处于运行状态（除非它执行的时间很短，瞬间执行完成），线程在运行过程中需要中断，
    目的是让其他的线程有运行机会，线程的调度取决于底层的策略。对应抢占式的系统而言，系统会给每个可执行的线程一个小时间段来处理任务，
    当时间段到达系统就会剥夺该线程的资源，让其他的线程有运行的机会。在选择下一个线程时，系统会考虑线程优先级。
    以下情况会出现线程阻塞状态：
        A、线程调用sleep方法，主动放弃占用的处理器资源
        B、线程调用了阻塞式IO方法，在该方法返回前，该线程被阻塞
        C、线程试图获得一个同步监视器，但该同步监视器正被其他线程所持有。
        D、线程等待某个通知（notify）
        E、程序调用了suspend方法将该线程挂起。不过这个方法容易导致死锁，尽量不免使用该方法
    当线程被阻塞后，其他线程将有机会执行。被阻塞的线程会在合适的时候重新进入就绪状态，注意是就绪状态不是运行状态。
    也就是被阻塞线程在阻塞解除后，必须重新等待线程调度器再次调用它。
    针对上面线程阻塞的情况，发生以下特定的情况可以解除阻塞，让进程进入就绪状态：
        A、调用sleep方法的经过了指定的休眠时间
        B、线程调用的阻塞IO已经返回，阻塞方法执行完毕
        C、线程成功获得了试图同步的监视器
        D、线程正在等待某个通知，其他线程发出了通知
        E、处于挂起状态的线程调用了resume恢复方法
    线程从阻塞状态只能进入就绪状态，无法进入运行状态。而就绪和运行状态之间的转换通常不受程序控制，而是由系统调度所致的。
    当就绪状态的线程获得资源时，该线程进入运行状态；当运行状态的线程事情处理器资源时就进入了就绪状态。
    但对调用了yield的方法就例外，此方法可以让运行状态转入就绪状态。
 
10、线程死亡（Dead）状态
    线程会在以下方式进入死亡状态：
    A、run方法执行完成，线程正常结束
    B、线程抛出未捕获的异常或Error
    C、直接调用该线程的stop方法来结束线程—该方法易导致死锁，注意使用
    注意：当主线程结束的时候，其他线程不受任何影响。一旦子线程启动后，会拥有和主线程相同的地位，不受主线程影响。
    isAlive方法可以测试当前线程是否死亡，当线程处于就绪、运行、阻塞状态，该方法返回true，如果线程处于新建或死亡状态就会返回false。
    不要试图对死亡的线程调用start方法，来启动它。死亡线程不可能再次运行。
 
11、控制线程
    Java线程提供了很多工具方法，这些方法都很好的控制线程
    A、join线程
        让一个线程等待另一个线程完成的方法。当某个程序执行流中调用其他线程的join方法时，调用线程将会被阻塞，直到被join方法的join线程执行完成为止。
        join方法通常有使用线程的程序调用，将大问题划分成许多小问题。每个小问题分配一个线程。当所有的小问题得到处理后，再调用主线程进一步操作。
        join有三种重载模式：
            一、join等待被join的线程执行完成
            二、join(long millis)等待被join的线程时间最长为millis毫秒，如果在millis毫秒外，被join的线程还没有执行完则不再等待
            三、join(long millis, int nanos)被join的线程等待时间长为millis毫秒加上nanos微秒
        通常我们很少用第三种join，原因有二：程序对时间的精度无需精确到千分之一毫秒
        计算机硬件、操作系统也无法做到精确到千分之一毫秒
    
    B、后台线程
        有一种线程，在后台运行，它的任务是为其他线程提供服务，这种线程被称为“后台线程(Daemon Thread)”，有被称为“守护线程”或“精灵线程”。
        JVM的垃圾回收器线程就是后台进程。
        后台进程有个特征是：如果前台的进程都死亡，那么后台进程也死亡。（它为前台进程服务）
        用Thread的setDaemon (true)方法可以指定当前线程为后台线程。
        注意：前台线程执行完成死亡后，JVM会通知后台线程，后台线程就会死亡。但它得到通知到后台线程作成响应，需要一段时间，
        而且要将某个线程设置为后台线程，必需要在该线程启动前设置，也就是说设置setDaemon必需在start方法前面调用。
        否则会出现java.lang.IllegalThreadStateException异常
    
    C、线程休眠sleep
        如果需要当前线程暂停一段时间，并进入阻塞状态就需要用sleep，sleep有2中重载方式：
        sleep(long millis)让当前线程暂停millis毫秒后，并进入阻塞状态，该方法受系统计时器和线程调度器的影响
        sleep(long millis, int nanos)让当前正在执行的线程暂停millis毫秒+nanos微秒，并进入阻塞
        当调用sleep方法进入阻塞状态后，在sleep时间段内，该线程不会获得执行机会，即使没有其他可运行的线程，处于sleep的线程不会执行。
 
    D、线程让步yield
        yield和sleep有点类似，它也可以让当前执行的线程暂停，但它不会阻塞线程，只是将该线程转入到就绪状态。
        yield只是让当前线程暂停下，让系统线程调度器重新调度下。
        当yield的线程后，当前线程暂停。系统线程调度器会让优先级相同或是更高的线程运行。
        
        sleep和yield的区别
            （1）、sleep方法暂停当前线程后，会给其他线程执行集合，不会理会线程的优先级。但yield则会给优先级相同或高优先级的线程执行机会
            （2）、sleep方法会将线程转入阻塞状态，直到经过阻塞时间才会转入到就绪状态；而yield则不会将线程转入到阻塞状态，它只是强制当前线程进入就绪状态。
                    因此完全有可能调用yield方法暂停之后，立即再次获得处理器资源继续运行。
            （3）、sleep声明抛出了InterruptedException异常，所以调用sleep方法时，要么捕获异常，要么抛出异常。而yield没有申明抛出任何异常
        
    E、改变线程优先级
        每个线程都有优先级，优先级决定线程的运行机会的多少。
        每个线程默认和它创建的父类的优先级相同，main方法的优先级是普通优先级，那在main方法中创建的子线程都是普通优先级。
        getPriority(int newPriority)/setPriority(int)
        设置优先级有以下级别：
            MAX_PRIORITY 值是10
            MIN_PRIORITY 值是1
            NORM_PRIORITY 值是5
            范围是1-10；
			
12、线程同步
    当多个线程访问同一个数据时，非常容易出现线程安全问题。这时候就需要用线程同步
    Case：银行取钱问题，有以下步骤：
    A、用户输入账户、密码，系统判断是否登录成功
    B、用户输入取款金额
    C、系统判断取款金额是否大于现有金额
    D、如果金额大于取款金额，就成功，否则提示小于余额
 
    现在模拟2个人同时对一个账户取款，多线程操作就会出现问题。这时候需要同步才行；
    同步代码块：
    synchronized (object) {
        //同步代码
    }
    Java多线程支持方法同步，方法同步只需用用synchronized来修饰方法即可，那么这个方法就是同步方法了。
    对于同步方法而言，无需显示指定同步监视器，同步方法监视器就是本身this
    同步方法：
    public synchronized void editByThread() {
        //doSomething
    }
 
    需要用同步方法的类具有以下特征：
    A、该类的对象可以被多个线程访问
    B、每个线程调用对象的任意都可以正常的结束，返回正常结果
    C、每个线程调用对象的任意方法后，该对象状态保持合理状态
    不可变类总是线程安全的，因为它的对象状态是不可改变的，但可变类对象需要额外的方法来保证线程安全。
    例如Account就是一个可变类，它的money就是可变的，当2个线程同时修改money时，程序就会出现异常或错误。
    所以要对Account设置为线程安全的，那么就需要用到同步synchronized关键字。
    
    
    下面的方法用synchronized同步关键字修饰，那么这个方法就是一个同步的方法。这样就只能有一个线程可以访问这个方法，
    在当前线程调用这个方法时，此方法是被锁状态，同步监视器是this。只有当此方法修改完毕后其他线程才能调用此方法。
    这样就可以保证线程的安全，处理多线程并发取钱的的安全问题。
    public synchronized void drawMoney(double money) {
        //取钱操作
    }
    注意：synchronized可以修饰方法、代码块，但不能修饰属性、构造方法
    
    可变类的线程安全是以降低程序的运行效率为代价，为了减少线程安全所带来的负面影响，可以采用以下策略：
    A、不要对线程安全类的所有方法都采用同步模式，只对那些会改变竞争资源（共享资源）的方法进行同步。
    B、如果可变类有2中运行环境：单线程环境和多线程环境，则应该为该可变提供2种版本；线程安全的和非线程安全的版本。
    在单线程下采用非线程安全的提高运行效率保证性能，在多线程环境下采用线程安全的控制安全性问题。
    
    释放同步监视器的锁定
    任何线程进入同步代码块、同步方法之前，必须先获得对同步监视器的锁定，那么何时会释放对同步监视器锁定？
    程序无法显示的释放对同步监视器的锁定，线程可以通过以下方式释放锁定：
    A、当线程的同步方法、同步代码库执行结束，就可以释放同步监视器
    B、当线程在同步代码库、方法中遇到break、return终止代码的运行，也可释放
    C、当线程在同步代码库、同步方法中遇到未处理的Error、Exception，导致该代码结束也可释放同步监视器
    D、当线程在同步代码库、同步方法中，程序执行了同步监视器对象的wait方法，导致方法暂停，释放同步监视器
 
    下面情况不会释放同步监视器：
    A、当线程在执行同步代码库、同步方法时，程序调用了Thread.sleep()/Thread.yield()方法来暂停当前程序，当前程序不会释放同步监视器
    B、当线程在执行同步代码库、同步方法时，其他线程调用了该线程的suspend方法将该线程挂起，该线程不会释放同步监视器。注意尽量避免使用suspend、resume
    
    同步锁（Lock）
    通常认为：Lock提供了比synchronized方法和synchronized代码块更广泛的锁定操作，Lock更灵活的结构，有很大的差别，并且可以支持多个Condition对象
    Lock是控制多个线程对共享资源进行访问的工具。通常，锁提供了对共享资源的独占访问，每次只能有一个线程对Lock对象加锁，
    线程开始访问共享资源之前应先获得Lock对象。不过某些锁支持共享资源的并发访问，如：ReadWriteLock（读写锁），在线程安全控制中，
    通常使用ReentrantLock（可重入锁）。使用该Lock对象可以显示加锁、释放锁。
     
    class C {
        //锁对象
        private final ReentrantLock lock = new ReentrantLock();
        ......
        //保证线程安全方法
        public void method() {
            //上锁
            lock.lock();
            try {
                //保证线程安全操作代码
            } catch() {
            
            } finally {
                lock.unlock();//释放锁
            }
        }
    }
    使用Lock对象进行同步时，锁定和释放锁时注意把释放锁放在finally中保证一定能够执行。
    
    使用锁和使用同步很类似，只是使用Lock时显示的调用lock方法来同步。而使用同步方法synchronized时系统会隐式使用当前对象作为同步监视器，
    同样都是“加锁->访问->释放锁”的操作模式，都可以保证只能有一个线程操作资源。
    同步方法和同步代码块使用与竞争资源相关的、隐式的同步监视器，并且强制要求加锁和释放锁要出现在一个块结构中，而且获得多个锁时，
    它们必须以相反的顺序释放，且必须在与所有锁被获取时相同的范围内释放所有资源。
    Lock提供了同步方法和同步代码库没有的其他功能，包括用于非块结构的tryLock方法，已经试图获取可中断锁lockInterruptibly()方法，
    还有获取超时失效锁的tryLock(long, timeUnit)方法。
    ReentrantLock具有重入性，也就是说线程可以对它已经加锁的ReentrantLock再次加锁，ReentrantLock对象会维持一个计数器来追踪lock方法的嵌套调用，
    线程在每次调用lock()加锁后，必须显示的调用unlock()来释放锁，所以一段被保护的代码可以调用另一个被相同锁保护的方法。
    
    死锁
    当2个线程相互等待对方是否同步监视器时就会发生死锁，JVM没有采取处理死锁的措施，这需要我们自己处理或避免死锁。
    一旦死锁，整个程序既不会出现异常，也不会出现错误和提示，只是线程将处于阻塞状态，无法继续。
    主线程保持对Foo的锁定，等待对Bar对象加锁，而副线程却对Bar对象保持锁定，等待对Foo加锁2条线程相互等待对方先释放锁，进入死锁状态。
    由于Thread类的suspend也很容易导致死锁，所以Java不推荐使用此方法暂停线程。
 
13、线程通信
    （1）、线程的协调运行
        场景：用2个线程，这2个线程分别代表存款和取款。——现在系统要求存款者和取款者不断重复的存款和取款的动作，
        而且每当存款者将钱存入账户后，取款者立即取出这笔钱。不允许2次连续存款、2次连续取款。
        实现上述场景需要用到Object类，提供的wait、notify和notifyAll三个方法，这3个方法并不属于Thread类。但这3个方法必须由同步监视器调用，可分为2种情况：
        A、对于使用synchronized修饰的同步方法，因为该类的默认实例this就是同步监视器，所以可以在同步中直接调用这3个方法。
        B、对于使用synchronized修改的同步代码块，同步监视器是synchronized后可括号中的对象，所以必须使用括号中的对象调用这3个方法
        方法概述：
        一、wait方法：导致当前线程进入等待，直到其他线程调用该同步监视器的notify方法或notifyAll方法来唤醒该线程。
                wait方法有3中形式：无参数的wait方法，会一直等待，直到其他线程通知；带毫秒参数的wait和微妙参数的wait，
                这2种形式都是等待时间到达后苏醒。调用wait方法的当前线程会释放对该对象同步监视器的锁定。
        二、notify：唤醒在此同步监视器上等待的单个线程。如果所有线程都在此同步监视器上等待，则会随机选择唤醒其中一个线程。
            只有当前线程放弃对该同步监视器的锁定后（用wait方法），才可以执行被唤醒的线程。
        三、notifyAll：唤醒在此同步监视器上等待的所有线程。只有当前线程放弃对该同步监视器的锁定后，才能执行唤醒的线程。
    （2）、条件变量控制协调
        如果程序不使用synchronized关键字来保证同步，而是直接使用Lock对象来保证同步，则系统中不存在隐式的同步监视器对象，
        也不能使用wait、notify、notifyAll方法来协调进程的运行。
        当使用Lock对象同步，Java提供一个Condition类来保持协调，使用Condition可以让那些已经得到Lock对象却无法组合使用，
        为每个对象提供了多个等待集（wait-set），这种情况下，Lock替代了同步方法和同步代码块，Condition替代同步监视器的功能。
        Condition实例实质上被绑定在一个Lock对象上，要获得特定的Lock实例的Condition实例，调用Lock对象的newCondition即可。
        Condition类方法介绍：
        一、await：类似于隐式同步监视器上的wait方法，导致当前程序等待，直到其他线程调用Condition的signal方法和signalAll方法来唤醒该线程。
            该await方法有跟多获取变体：long awaitNanos(long nanosTimeout),void awaitUninterruptibly()、awaitUntil(Date daadline)
        二、signal：唤醒在此Lock对象上等待的单个线程，如果所有的线程都在该Lock对象上等待，则会选择随机唤醒其中一个线程。
            只有当前线程放弃对该Lock对象的锁定后，使用await方法，才可以唤醒在执行的线程。
        三、signalAll：唤醒在此Lock对象上等待的所有线程。只有当前线程放弃对该Lock对象的锁定后，才可以执行被唤醒的线程。
     
    （3）、使用管道流
        线程通信使用管道流，管道流有3种形式：
        PipedInputStream、PipedOutputStream、PipedReader和PipedWriter以及Pipe.SinkChannel和Pipe.SourceChannel，
        它们分别是管道流的字节流、管道字符流和新IO的管道Channel。
        管道流通信基本步骤：
        A、使用new操作法来创建管道输入、输出流
        B、使用管道输入流、输出流的connect方法把2个输入、输出流连接起来
        C、将管道输入、输出流分别传入2个线程
        D、2个线程可以分别依赖各自的管道输入流、管道输出流进行通信
    
14、线程组和未处理异常
    ThreadGroup表示线程组，它可以表示一批线程进行分类管理，Java允许程序对
    Java允许直接对线程组控制，对线程组控制相对于同时控制这批线程。用户创建的所有线程都属于指定的线程组。
    如果程序没有值得线程属于哪个组，那这个线程就属于默认线程组。在默认情况下，子线程和创建它父线程属于同一组。
    一旦某个线程加入了指定线程组之后，该线程将属于该线程组，直到该线程死亡，线程运行中途不能改变它所属的线程组。
    Thread类提供一些构造设置线程所属的哪个组，具有以下方法：
    A、Thread(ThreadGroup group, Runnable target):target的run方法作为线程执行体创建新线程，属于group线程组
    B、Thread(ThreadGroup group, Runnalbe target, String name):target的run方法作为线程执行体创建的新线程，该线程属于group线程组，且线程名为name
    C、Thread(ThreadGroup group, String name):创建新线程，新线程名为name，属于group组
 
    因为中途不能改变线程所属的组，所以Thread提供ThreadGroup的setter方法，但提供了getThreadGroup方法来返回该线程所属的线程组，
    getThreadGroup方法的返回值是ThreadGroup对象的表示，表示一个线程组。
    ThreadGroup有2个构造形式：
    A、ThreadGroup(String name):name线程组的名称
    B、ThreadGroup(ThreadGroup parent, String name):指定名称、指定父线程组创建的一个新线程组
 
    上面的构造都指定线程名称，也就是线程组都必须有自己的一个名称，可以通过调用ThreadGroup的getName方法得到，
    但不允许中途改变名称。ThreadGroup有以下常用的方法：
    A、activeCount：返回线程组活动线程数目
    B、interrupt：中断此线程组中的所有线程
    C、isDeamon：判断该线程是否在后台运行
    D、setDeamon：把该线程组设置为后台线程组，后台线程具有一个特征，当后台线程的最后一个线程执行结束或最后一个线程被销毁，后台线程组自动销毁。
    E、setMaxPriority：设置线程组最高优先级
    uncaughtException(Thread t, Throwable e)该方法可以处理该线程组内的线程所抛出的未处理的异常，
    Thread.UncaughtExceptionHandler是Thread类的一个内部公共静态接口，
    该接口内只有一个方法：void uncaughtException(Thread t, Throwable e) 该方法中的t代表出现异常的线程，而e代表该线程抛出的异常
     
    Thread类中提供2个方法来设置异常处理器：
    A、staticsetDefaultUnaughtExceptionHandler(Thread.UncaughtExceptionHandler eh):为该线程类的所有线程实例设置默认的异常处理器
    B、setUncaughtExceptionHandler(Thread.UncaughtExceptionHander eh):为指导线程实例设置异常处理器
 
    ThreadGroup实现了Thread.UncaughtExceptionHandler接口，所以每个线程所属的线程组将会作为默认的异常处理器。当一个线程抛出未处理异常时，
    JVM会首先查找该异常对应的异常处理器，（setUncaughtExceptionHandler设置异常处理器），如果找到该异常处理器，将调用该异常处理器处理异常。
    否则，JVM将会调用该线程的所属线程组的uncaughtException处理异常，线程组处理异常流程如下：
    A、如果该线程有父线程组，则调用父线程组的uncaughtException方法来处理异常
    B、如果该线程实例所属的线程类有默认的异常处理器（setDefaultUnaughtExceptionHandler方法设置异常处理器），那就调用该异常处理器来处理异常信息
    C、将异常调用栈的信息打印到System.err错误输出流，并结束该线程
 
15、Callable和Future
    Callable接口定义了一个call方法可以作为线程的执行体，但call方法比run方法更强大：
    A、call方法可以有返回值
    B、call方法可以申明抛出异常
 
    Callable接口是JDK5后新增的接口，而且不是Runnable的子接口，所以Callable对象不能直接作为Thread的target。而且call方法还有一个返回值，
    call方法不能直接调用，它作为线程的执行体被调用。那么如何接收call方法的返回值？
    JDK1.5提供了Future接口来代表Callable接口里的call方法的返回值，并为Future接口提供了一个FutureTask实现类，该实现类实现Future接口，
    并实现了Runnable接口—可以作为Thread的target。
 
    Future接口里定义了如下几个公共方法控制他关联的Callable任务：
    A、boolean cancel(Boolean mayInterruptlfRunning):试图取消该Future里关联的Callable任务
    B、V get()：返回Callable任务里的call方法的返回值，调用该方法将导致线程阻塞，必须等到子线程结束才得到返回值
    C、V get(long timeout, TimeUnit unit)：返回Callable任务里的call方法的返回值，该方法让程序最多阻塞timeout和unit指定的时间。
        如果经过指定时间后Callable任务依然没有返回值，将会抛出TimeoutException。
    D、boolean isCancelled：如果在Callable任务正常完成前被取消，则返回true。
    E、boolean isDone：如果Callable任务已经完成，则返回true
 
    创建、并启动有返回值的线程的步骤如下：
    一、创建Callable接口的实现类，并实现call方法，该call方法的返回值，并作为线程的执行体。
    二、创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call方法的返回值
    三、使用FutureTask对象作为Thread对象的target创建、并启动新线程
    四、调用FutureTask对象的方法来获得子线程执行结束后的返回值
    			
			
16、线程池
    Why? 系统启动一个新线程的成本比较高，因为涉及到与操作系统交互。这个时候用线程池可以很好的提高性能，
    尤其是当程序中需要创建大量生存期很短暂的线程时，更应该考虑使用线程池。
    原理：（流程）线程池和数据库连接池有点类似的是，线程池在系统启动时创建大量空闲线程，程序将一个Runnable对象传给线程池，
    线程池就会启动一条线程来执行该线程对象的run方法，当run方法执行结束后，该线程并不会死亡，而是再次返回线程池中成为空闲线程，
    等待执行下一个Runnable对象的run方法。
 
    优点：使用线程池可以有效的控制系统中并发线程的数量，当系统中包含大量的并发线程时，会导致系统性能剧烈下降，
    甚至导致JVM的崩溃，而线程池的最大线程参数可以控制系统中并发线程数目不超过此数目。
 
    在JDK1.5开始，提供Java内建的线程池，JDK提供一个Executors工厂类来产生线程池，该工程类包含如下几个静态工厂方法来创建连接池：
    A、newCachedThreadPool()：创建一个具有缓存功能的线程池，系统根据需要创建线程，这些线程将会被缓存在线程池中。
    B、newFixedThreadPool(int nThreads)：创建一个可重用的、具有固定线程数的线程池
    C、newSingleThreadExecutor()：创建一个只有单线程的线程池，它相当于newFixedThreadPool方法传递参数1
    D、newScheduledThreadPool(int corePoolSize)：创建具有指定线程数的线程池，它可以在指定延迟后执行线程任务，
        corePoolSize 指池中所保持的线程数，即使线程是空闲的也被保存在线程池内。
    E、newSingleThreadScheduiedExecutor()：创建只有一条线程的线程池，它可以在指定延时后执行线程任务。
    以上5个方法的前三个方法返回的是一个ExecutorService对象，该对象代表一个线程池，它可以执行Runnable对象或Callable对象所代表的线程。
    而后两个方法返回一个ScheduledExecutorService线程池，它是ExecutorService的子类，它可以在指定延时后执行线程任务。
 
    ExecutorService代表尽快执行线程的线程池（只要线程中有空闲的线程就立即执行线程任务）。
    程序只要将一个Runnable对象或Callable对象（代表线程任务）提及给该线程池即可，该线程池就会尽快的执行任务。
    ExecutorService里提供如下3个方法：
    A、Future<?> submit(Runnable task)：将一个Runnable对象提交给指定的线程池。线程池将在有空闲线程时执行Runnable对象的代表的任务。
        其中Future对象代表Runnable任务的返回值—run方法蛮腰返回值，所以Future对象将在run方法执行结束后返回null，
        但可以调用Future的isDone，isCancelled方法来获得Runnable对象的执行状态
    B、<T> Future<T> submit(Runnable task, T reslut)：将一个Runnable对象提及给指定的线程池，线程池将在有空闲线程时执行Runnable对象代表的任务，
        result显示执行线程执行结束后的返回值，所以Future对象将在run方法执行结束后返回result
    C、<T> Future<T> submit(Callable<T> task)：将一个Callable对象提交给指定线程池。线程池将在有空闲线程时执行Callable对象代表的任务，
        Future代表Callable对象里的call方法的返回值
    
    ScheduledExecutorService代表可在指定延迟或周期性执行线程任务的线程池，它提供了如下方法：    
    A、ScheduledFuture<V> schedule(Callable<V> callable, long delay, Timeout unit)：指定Callable任务将在delay延迟后执行
    B、ScheduledFuture<V> schedule(Runnable command, long delay, Timeout unit)：指定command任务将在delay延迟后执行
    C、ScheduleFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)
        指定command任务将在delay延长后执行，而且以设定频率重复执行，也就是说，在initialDelay后开始执行，
        异常在initialDelay+2* period 处重复运行，依次类推
    D、ScheduleFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, Timeout unit)
        创建并执行一个在给定初始延迟后首次启用的定期操作，随后，在每一次执行终止和下一次执行开始之间都存在给定的延迟。
        如果任务的任一次运行遇到异常，就会取消后续运行。否则，只能通过程序来显示取消或终止任务
    当用完一个线程池后，应该调用shutdown方法，该方法将启动线程池的关闭序列，调用了shutdown方法后线程池不再接受新的任务，
    但会将以前所有一提交的任务执行完成。当线程池所有线程任务执行完毕后，池中所有线程都会死亡。另外也可以执行线程池的shutdownNow方法来关闭线程池，
    该方法试图停止所有正在执行的活动任务，暂停处理正在等待的任务，并返回等待执行任务列表。
    使用线程池来执行线程任务步骤：
    A、调用Executors类的静态工厂方法创建一个ExecutorService对象，该对象代表一个线程池
    B、创建Runnable实现类或是Callable实现类的实例，作为线程的执行任务
    C、调用ExecutorService对象的submit方法来提交Runnable和Callable实例
    D、当不想提交任务时调用ExecutorService对象的shutdown方法来关闭线程池
 
17、线程相关类
    一、ThreadLocal类
        在JDK5后ThreadLocal引入了泛型的支持，通过使用ThreadLocal可以简化多多线程的编程时是并发访问，使用这个工具类可以帮我们更好的实现多线程。
        ThreadLocal，是Thread Local Variable（线程的局部变量）的意思。线程局部变量功能非常简单，就是为每一个使用该变量的线程都提供一个变量值的副本，
        是每一个线程都可以独立的改变自己的副本，而不会和其他线程的副本冲突。
        ThreadLocal提供常用方法：
            A、T get()：返回此线程局部变量中当前线程副本中的值
            B、void remove()：删除此线程局部变量中当前线程副本中的值
            C、void set(T value)：设置此线程局部变量中当前线程副本中的值
        ThreadLocal和其他所有同步机制都是为了解决多线程中对同一变量的访问冲突，在普通的同步机制中，是通过对象加锁来实现多个线程对同一变量的安全访问的。
        在这种情形下，该变量是多个线程共享的，所以要使用这种同步机制需要很细致的分析在什么时候对变量进行读写，
        上面时候需要锁定某个对象，什么时候释放对象锁等。
        在这种情况下系统并没有将这份资源复制多份，只是采用了案情机制来控制队这份资源的访问而已。
        ThreadLocal就从另一个角度来解决多线程的并发访问，ThreadLocal将需要并发访问的资源复制出多份，每个线程拥有一份资源，每个线程都拥有自己的资源副本，
        从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的对象，在编写多线程代码时，可以把不安全的整个变量封装进ThreadLocal，
        或者把该对象与现场相关的状态使用ThreadLocal保存。
        ThreadLocal并不能代替同步机制，两者面向的问题领域不同。同步机制是为了同步多个线程对相同资源的并发访问，是多个线程之间进行通信的有效方式；
        而ThreadLocal是隔离多个线程的数据共享，从根本上避免了多个线程之间共享资源（变量），也就不需要对多个线程进行同步了。
        通常认为：如果需要进行多个线程之间的共享资源，已到达线程之间的通信功能，就使用步机制，如果仅仅需要隔离多个线程之间的共享冲突，就用ThreadLocal。
    
    二、包装线程不安全集合
        当用多线程操作集合时，对线程不安全的集合进行操作容易破坏集合数据的完整性。
        A、<T> Collection<T> synchronizedCollection(Collection<T> c)：返回指定collection对应的线程安全的collection
        B、static <T> List<T> synchronizedList(List<T> list)：返回指定List对应的现场安全的List对象
        C、static <K, V> Map<K, V> synchronizedMap(Map<K, V> m)：返回指定Map对象对应的现场安全的Map对象
        D、static <T> Set<T> synchronizedSet(Set<T> s)：返回指定Set对应的线程安全的Set
        E、static <K, V> SortedMap<K, V> synchronizedSortedMap(SortedMap<K, V> m)：返回指定SortedMap对象所对应线程安全的SortedMap对象
        F、static <K, V> SortedSet<K, V> synchronizedSortedSet(SortedSet<K, V> m)：返回指定SortedSet对象所对应线程安全的SortedSet 对象
        使用线程安全的HashMap对象：
        HashMap map = Collections.synchronizedMap(new HashMap());
        注意：如果需要把某个集合包装成线程安全的集合，则应该在创建之后立即包装，包装后就是线程安全的HashMap对象了。
 
    三、线程安全的集合
        在JDK5后提供了java.util.concurrent包的ConcurrentHashMap、ConcurrentLinkedQueue两个支持并发访问的集合，
        它们分别代表了支持并发访问的HashMap和支持并发访问的Queue。默认都支持多线程并发写入，写入操作是线程安全的，读取不必锁定。
        这两个集合采用了复杂的算法，他们是永远都锁不住的集合。
        当多线程共享访问一个集合时，ConcurrentLinkedQueue最合适不过，Queue不允许为null元素。
        Quee实现了多线程的高效访问，多条线程访问ConcurrentLinkedQueue集合是无需等待。
        ConcurrentHashMap默认支持16条线程并发访问，当有超过16条线程并发访问就需要等待。
        但可以设置concurrentLevel构造方法参数（默认16）来支持更多的线程并发数量。
        与HashMap和普通集合不同的是，当我们用迭代器变量ConcurrentHashMap、ConcurrentLinkedQueue时，
        如果在迭代器创建后对集合元素的修改是不会在迭代器中做出修改，也不会出现异常。
        如果用Collection作为集合对象时，如果对象在创建迭代器后发生变化修改，就会引发ConcurrentModificationException
		
		
		
		
		
		
		
		
Java 多线程断点下载文件

基本原理：利用URLConnection获取要下载文件的长度、头部等相关信息，并设置响应的头部信息。并且通过URLConnection获取输入流，将文件分成指定的块，每一块单独开辟一个线程完成数据的读取、写入。通过输入流读取下载文件的信息，然后将读取的信息用RandomAccessFile随机写入到本地文件中。同时，每个线程写入的数据都文件指针也就是写入数据的长度，需要保存在一个临时文件中。这样当本次下载没有完成的时候，下次下载的时候就从这个文件中读取上一次下载的文件长度，然后继续接着上一次的位置开始下载。并且将本次下载的长度写入到这个文件中。


个人博客：

http://hoojo.cnblogs.com

http://blog.csdn.net/IBM_hoojo

email: hoojo_@126.com

 


一、下载文件信息类、实体

封装即将下载资源的信息

package com.hoo.entity;
 
/**
 * <b>function:</b> 下载文件信息类
 * @author hoojo
 * @createDate 2011-9-21 下午05:14:58
 * @file DownloadInfo.java
 * @package com.hoo.entity
 * @project MultiThreadDownLoad
 * @blog http://blog.csdn.net/IBM_hoojo
 * @email hoojo_@126.com
 * @version 1.0
 */
public class DownloadInfo {
    //下载文件url
    private String url;
    //下载文件名称
    private String fileName;
    //下载文件路径
    private String filePath;
    //分成多少段下载， 每一段用一个线程完成下载
    private int splitter;
    
    //下载文件默认保存路径
    private final static String FILE_PATH = "C:/temp";
    //默认分块数、线程数
    private final static int SPLITTER_NUM = 5;
    
    public DownloadInfo() {
        super();
    }
    
    /**
     * @param url 下载地址
     */
    public DownloadInfo(String url) {
        this(url, null, null, SPLITTER_NUM);
    }
    
    /**
     * @param url 下载地址url
     * @param splitter 分成多少段或是多少个线程下载
     */
    public DownloadInfo(String url, int splitter) {
        this(url, null, null, splitter);
    }
    
    /***
     * @param url 下载地址
     * @param fileName 文件名称
     * @param filePath 文件保存路径
     * @param splitter 分成多少段或是多少个线程下载
     */
    public DownloadInfo(String url, String fileName, String filePath, int splitter) {
        super();
        if (url == null || "".equals(url)) {
            throw new RuntimeException("url is not null!");
        }
        this.url =  url;
        this.fileName = (fileName == null || "".equals(fileName)) ? getFileName(url) : fileName;
        this.filePath = (filePath == null || "".equals(filePath)) ? FILE_PATH : filePath;
        this.splitter = (splitter < 1) ? SPLITTER_NUM : splitter;
    }
    
    /**
     * <b>function:</b> 通过url获得文件名称
     * @author hoojo
     * @createDate 2011-9-30 下午05:00:00
     * @param url
     * @return
     */
    private String getFileName(String url) {
        return url.substring(url.lastIndexOf("/") + 1, url.length());
    }
    
    public String getUrl() {
        return url;
    }
 
    public void setUrl(String url) {
        if (url == null || "".equals(url)) {
            throw new RuntimeException("url is not null!");
        }
        this.url = url;
    }
 
    public String getFileName() {
        return fileName;
    }
 
    public void setFileName(String fileName) {
        this.fileName = (fileName == null || "".equals(fileName)) ? getFileName(url) : fileName;
    }
 
    public String getFilePath() {
        return filePath;
    }
 
    public void setFilePath(String filePath) {
        this.filePath = (filePath == null || "".equals(filePath)) ? FILE_PATH : filePath;
    }
 
    public int getSplitter() {
        return splitter;
    }
 
    public void setSplitter(int splitter) {
        this.splitter = (splitter < 1) ? SPLITTER_NUM : splitter;
    }
    
    @Override
    public String toString() {
        return this.url + "#" + this.fileName + "#" + this.filePath + "#" + this.splitter;
    }
}
 
 

二、随机写入一段文件

package com.hoo.download;
 
import java.io.IOException;
import java.io.RandomAccessFile;
 
/**
 * <b>function:</b> 写入文件、保存文件
 * @author hoojo
 * @createDate 2011-9-21 下午05:44:02
 * @file SaveItemFile.java
 * @package com.hoo.download
 * @project MultiThreadDownLoad
 * @blog http://blog.csdn.net/IBM_hoojo
 * @email hoojo_@126.com
 * @version 1.0
 */
public class SaveItemFile {
    //存储文件
    private RandomAccessFile itemFile;
    
    public SaveItemFile() throws IOException {
        this("", 0);
    }
    
    /**
     * @param name 文件路径、名称
     * @param pos 写入点位置 position
     * @throws IOException
     */
    public SaveItemFile(String name, long pos) throws IOException {
        itemFile = new RandomAccessFile(name, "rw");
        //在指定的pos位置开始写入数据
        itemFile.seek(pos);
    }
    
    /**
     * <b>function:</b> 同步方法写入文件
     * @author hoojo
     * @createDate 2011-9-26 下午12:21:22
     * @param buff 缓冲数组
     * @param start 起始位置
     * @param length 长度
     * @return
     */
    public synchronized int write(byte[] buff, int start, int length) {
        int i = -1;
        try {
            itemFile.write(buff, start, length);
            i = length;
        } catch (IOException e) {
            e.printStackTrace();
        }
        return i;
    }
    
    public void close() throws IOException {
        if (itemFile != null) {
            itemFile.close();
        }
    }
}
这个类主要是完成向本地的指定文件指针出开始写入文件，并返回当前写入文件的长度（文件指针）。这个类将被线程调用，文件被分成对应的块后，将被线程调用。每个线程都将会调用这个类完成文件的随机写入。

 

三、单个线程下载文件

package com.hoo.download;
 
import java.io.IOException;
import java.io.InputStream;
import java.net.HttpURLConnection;
import java.net.MalformedURLException;
import java.net.URL;
import java.net.URLConnection;
import com.hoo.util.LogUtils;
 
/**
 * <b>function:</b> 单线程下载文件
 * @author hoojo
 * @createDate 2011-9-22 下午02:55:10
 * @file DownloadFile.java
 * @package com.hoo.download
 * @project MultiThreadDownLoad
 * @blog http://blog.csdn.net/IBM_hoojo
 * @email hoojo_@126.com
 * @version 1.0
 */
public class DownloadFile extends Thread {
    
    //下载文件url
    private String url;
    //下载文件起始位置  
    private long startPos;
    //下载文件结束位置
    private long endPos;
    //线程id
    private int threadId;
    
    //下载是否完成
    private boolean isDownloadOver = false;
 
    private SaveItemFile itemFile;
    
    private static final int BUFF_LENGTH = 1024 * 8;
    
    /**
     * @param url 下载文件url
     * @param name 文件名称
     * @param startPos 下载文件起点
     * @param endPos 下载文件结束点
     * @param threadId 线程id
     * @throws IOException
     */
    public DownloadFile(String url, String name, long startPos, long endPos, int threadId) throws IOException {
        super();
        this.url = url;
        this.startPos = startPos;
        this.endPos = endPos;
        this.threadId = threadId;
        //分块下载写入文件内容
        this.itemFile = new SaveItemFile(name, startPos);
    }
 
    
    @Override
    public void run() {
        while (endPos > startPos && !isDownloadOver) {
            try {
                URL url = new URL(this.url);
                HttpURLConnection conn = (HttpURLConnection) url.openConnection();
                
                // 设置连接超时时间为10000ms
                conn.setConnectTimeout(10000);
                // 设置读取数据超时时间为10000ms
                conn.setReadTimeout(10000);
                
                setHeader(conn);
                
                String property = "bytes=" + startPos + "-";
                conn.setRequestProperty("RANGE", property);
                
                //输出log信息
                LogUtils.log("开始 " + threadId + "：" + property + endPos);
                //printHeader(conn);
                
                //获取文件输入流，读取文件内容
                InputStream is = conn.getInputStream();
                
                byte[] buff = new byte[BUFF_LENGTH];
                int length = -1;
                LogUtils.log("#start#Thread: " + threadId + ", startPos: " + startPos + ", endPos: " + endPos);
                while ((length = is.read(buff)) > 0 && startPos < endPos && !isDownloadOver) {
                    //写入文件内容，返回最后写入的长度
                    startPos += itemFile.write(buff, 0, length);
                }
                LogUtils.log("#over#Thread: " + threadId + ", startPos: " + startPos + ", endPos: " + endPos);
                LogUtils.log("Thread " + threadId + " is execute over!");
                this.isDownloadOver = true;
            } catch (MalformedURLException e) {
                e.printStackTrace();
            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try {
                    if (itemFile != null) {
                        itemFile.close();
                    }
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
        if (endPos < startPos && !isDownloadOver) {
            LogUtils.log("Thread " + threadId  + " startPos > endPos, not need download file !");
            this.isDownloadOver = true;
        }
        if (endPos == startPos && !isDownloadOver) {
            LogUtils.log("Thread " + threadId  + " startPos = endPos, not need download file !");
            this.isDownloadOver = true;
        }
    }
    
    /**
     * <b>function:</b> 打印下载文件头部信息
     * @author hoojo
     * @createDate 2011-9-22 下午05:44:35
     * @param conn HttpURLConnection
     */
    public static void printHeader(URLConnection conn) {
        int i = 1;
        while (true) {
            String header = conn.getHeaderFieldKey(i);
            i++;
            if (header != null) {
                LogUtils.info(header + ":" + conn.getHeaderField(i));
            } else {
                break;
            }
        }
    }
    
    /**
     * <b>function:</b> 设置URLConnection的头部信息，伪装请求信息
     * @author hoojo
     * @createDate 2011-9-28 下午05:29:43
     * @param con
     */
    public static void setHeader(URLConnection conn) {
        conn.setRequestProperty("User-Agent", "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3) Gecko/2008092510 Ubuntu/8.04 (hardy) Firefox/3.0.3");
        conn.setRequestProperty("Accept-Language", "en-us,en;q=0.7,zh-cn;q=0.3");
        conn.setRequestProperty("Accept-Encoding", "utf-8");
        conn.setRequestProperty("Accept-Charset", "ISO-8859-1,utf-8;q=0.7,*;q=0.7");
        conn.setRequestProperty("Keep-Alive", "300");
        conn.setRequestProperty("connnection", "keep-alive");
        conn.setRequestProperty("If-Modified-Since", "Fri, 02 Jan 2009 17:00:05 GMT");
        conn.setRequestProperty("If-None-Match", "\"1261d8-4290-df64d224\"");
        conn.setRequestProperty("Cache-conntrol", "max-age=0");
        conn.setRequestProperty("Referer", "http://www.baidu.com");
    }
    
    public boolean isDownloadOver() {
        return isDownloadOver;
    }
    
    public long getStartPos() {
        return startPos;
    }
 
    public long getEndPos() {
        return endPos;
    }
}
这个类主要是完成单个线程的文件下载，将通过URLConnection读取指定url的资源信息。然后用InputStream读取文件内容，然后调用调用SaveItemFile类，向本地写入当前要读取的块的内容。

 

四、分段多线程写入文件内容

package com.hoo.download;
 
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.net.HttpURLConnection;
import java.net.MalformedURLException;
import java.net.URL;
import com.hoo.entity.DownloadInfo;
import com.hoo.util.LogUtils;
 
/**
 * <b>function:</b> 分批量下载文件
 * @author hoojo
 * @createDate 2011-9-22 下午05:51:54
 * @file BatchDownloadFile.java
 * @package com.hoo.download
 * @project MultiThreadDownLoad
 * @blog http://blog.csdn.net/IBM_hoojo
 * @email hoojo_@126.com
 * @version 1.0
 */
public class BatchDownloadFile implements Runnable {
    //下载文件信息 
    private DownloadInfo downloadInfo;
    //一组开始下载位置
    private long[] startPos;
    //一组结束下载位置
    private long[] endPos;
    //休眠时间
    private static final int SLEEP_SECONDS = 500;
    //子线程下载
    private DownloadFile[] fileItem;
    //文件长度
    private int length;
    //是否第一个文件
    private boolean first = true;
    //是否停止下载
    private boolean stop = false;
    //临时文件信息
    private File tempFile;
    
    public BatchDownloadFile(DownloadInfo downloadInfo) {
        this.downloadInfo = downloadInfo;
        String tempPath = this.downloadInfo.getFilePath() + File.separator + downloadInfo.getFileName() + ".position";
        tempFile = new File(tempPath);
        //如果存在读入点位置的文件
        if (tempFile.exists()) {
            first = false;
            //就直接读取内容
            try {
                readPosInfo();
            } catch (IOException e) {
                e.printStackTrace();
            }
        } else {
            //数组的长度就要分成多少段的数量
            startPos = new long[downloadInfo.getSplitter()];
            endPos = new long[downloadInfo.getSplitter()];
        }
    }
    
    @Override
    public void run() {
        //首次下载，获取下载文件长度
        if (first) {
            length = this.getFileSize();//获取文件长度
            if (length == -1) {
                LogUtils.log("file length is know!");
                stop = true;
            } else if (length == -2) {
                LogUtils.log("read file length is error!");
                stop = true;
            } else if (length > 0) {
                /**
                 * eg 
                 * start: 1, 3, 5, 7, 9
                 * end: 3, 5, 7, 9, length
                 */
                for (int i = 0, len = startPos.length; i < len; i++) {
                    int size = i * (length / len);
                    startPos[i] = size;
                    
                    //设置最后一个结束点的位置
                    if (i == len - 1) {
                        endPos[i] = length;
                    } else {
                        size = (i + 1) * (length / len);
                        endPos[i] = size;
                    }
                    LogUtils.log("start-end Position[" + i + "]: " + startPos[i] + "-" + endPos[i]);
                }
            } else {
                LogUtils.log("get file length is error, download is stop!");
                stop = true;
            }
        }
        
        //子线程开始下载
        if (!stop) {
            //创建单线程下载对象数组
            fileItem = new DownloadFile[startPos.length];//startPos.length = downloadInfo.getSplitter()
            for (int i = 0; i < startPos.length; i++) {
                try {
                    //创建指定个数单线程下载对象，每个线程独立完成指定块内容的下载
                    fileItem[i] = new DownloadFile(
                        downloadInfo.getUrl(), 
                        this.downloadInfo.getFilePath() + File.separator + downloadInfo.getFileName(), 
                        startPos[i], endPos[i], i
                    );
                    fileItem[i].start();//启动线程，开始下载
                    LogUtils.log("Thread: " + i + ", startPos: " + startPos[i] + ", endPos: " + endPos[i]);
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            
            //循环写入下载文件长度信息
            while (!stop) {
                try {
                    writePosInfo();
                    LogUtils.log("downloading……");
                    Thread.sleep(SLEEP_SECONDS);
                    stop = true;
                } catch (IOException e) {
                    e.printStackTrace();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                for (int i = 0; i < startPos.length; i++) {
                    if (!fileItem[i].isDownloadOver()) {
                        stop = false;
                        break;
                    }
                }
            }
            LogUtils.info("Download task is finished!");
        }
    }
    
    /**
     * 将写入点数据保存在临时文件中
     * @author hoojo
     * @createDate 2011-9-23 下午05:25:37
     * @throws IOException
     */
    private void writePosInfo() throws IOException {
        DataOutputStream dos = new DataOutputStream(new FileOutputStream(tempFile));
        dos.writeInt(startPos.length);
        for (int i = 0; i < startPos.length; i++) {
            dos.writeLong(fileItem[i].getStartPos());
            dos.writeLong(fileItem[i].getEndPos());
            //LogUtils.info("[" + fileItem[i].getStartPos() + "#" + fileItem[i].getEndPos() + "]");
        }
        dos.close();
    }
    
    /**
     * <b>function:</b>读取写入点的位置信息
     * @author hoojo
     * @createDate 2011-9-23 下午05:30:29
     * @throws IOException
     */
    private void readPosInfo() throws IOException {
        DataInputStream dis = new DataInputStream(new FileInputStream(tempFile));
        int startPosLength = dis.readInt();
        startPos = new long[startPosLength];
        endPos = new long[startPosLength];
        for (int i = 0; i < startPosLength; i++) {
            startPos[i] = dis.readLong();
            endPos[i] = dis.readLong();
        }
        dis.close();
    }
    
    /**
     * <b>function:</b> 获取下载文件的长度
     * @author hoojo
     * @createDate 2011-9-26 下午12:15:08
     * @return
     */
    private int getFileSize() {
        int fileLength = -1;
        try {
            URL url = new URL(this.downloadInfo.getUrl());
            HttpURLConnection conn = (HttpURLConnection) url.openConnection();
            
            DownloadFile.setHeader(conn);
 
            int stateCode = conn.getResponseCode();
            //判断http status是否为HTTP/1.1 206 Partial Content或者200 OK
            if (stateCode != HttpURLConnection.HTTP_OK && stateCode != HttpURLConnection.HTTP_PARTIAL) {
                LogUtils.log("Error Code: " + stateCode);
                return -2;
            } else if (stateCode >= 400) {
                LogUtils.log("Error Code: " + stateCode);
                return -2;
            } else {
                //获取长度
                fileLength = conn.getContentLength();
                LogUtils.log("FileLength: " + fileLength);
            }
            
            //读取文件长度
            /*for (int i = 1; ; i++) {
                String header = conn.getHeaderFieldKey(i);
                if (header != null) {
                    if ("Content-Length".equals(header)) {
                        fileLength = Integer.parseInt(conn.getHeaderField(i));
                        break;
                    }
                } else {
                    break;
                }
            }
            */
            
            DownloadFile.printHeader(conn);
        } catch (MalformedURLException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }
        return fileLength;
    }
}
这个类主要是完成读取指定url资源的内容，获取该资源的长度。然后将该资源分成指定的块数，将每块的起始下载位置、结束下载位置，分别保存在一个数组中。每块都单独开辟一个独立线程开始下载。在开始下载之前，需要创建一个临时文件，写入当前下载线程的开始下载指针位置和结束下载指针位置。

 

五、工具类、测试类

日志工具类

package com.hoo.util;
 
/**
 * <b>function:</b> 日志工具类
 * @author hoojo
 * @createDate 2011-9-21 下午05:21:27
 * @file LogUtils.java
 * @package com.hoo.util
 * @project MultiThreadDownLoad
 * @blog http://blog.csdn.net/IBM_hoojo
 * @email hoojo_@126.com
 * @version 1.0
 */
public abstract class LogUtils {
    
    public static void log(Object message) {
        System.err.println(message);
    }
    
    public static void log(String message) {
        System.err.println(message);
    }
    
    public static void log(int message) {
        System.err.println(message);
    }
    
    public static void info(Object message) {
        System.out.println(message);
    }
    
    public static void info(String message) {
        System.out.println(message);
    }
    
    public static void info(int message) {
        System.out.println(message);
    }
}
 

下载工具类

package com.hoo.util;
 
import com.hoo.download.BatchDownloadFile;
import com.hoo.entity.DownloadInfo;
 
/**
 * <b>function:</b> 分块多线程下载工具类
 * @author hoojo
 * @createDate 2011-9-28 下午05:22:18
 * @file DownloadUtils.java
 * @package com.hoo.util
 * @project MultiThreadDownLoad
 * @blog http://blog.csdn.net/IBM_hoojo
 * @email hoojo_@126.com
 * @version 1.0
 */
public abstract class DownloadUtils {
 
    public static void download(String url) {
        DownloadInfo bean = new DownloadInfo(url);
        LogUtils.info(bean);
        BatchDownloadFile down = new BatchDownloadFile(bean);
        new Thread(down).start();
    }
    
    public static void download(String url, int threadNum) {
        DownloadInfo bean = new DownloadInfo(url, threadNum);
        LogUtils.info(bean);
        BatchDownloadFile down = new BatchDownloadFile(bean);
        new Thread(down).start();
    }
    
    public static void download(String url, String fileName, String filePath, int threadNum) {
        DownloadInfo bean = new DownloadInfo(url, fileName, filePath, threadNum);
        LogUtils.info(bean);
        BatchDownloadFile down = new BatchDownloadFile(bean);
        new Thread(down).start();
    }
}
 

下载测试类

package com.hoo.test;
 
import com.hoo.util.DownloadUtils;
 
/**
 * <b>function:</b> 下载测试
 * @author hoojo
 * @createDate 2011-9-23 下午05:49:46
 * @file TestDownloadMain.java
 * @package com.hoo.download
 * @project MultiThreadDownLoad
 * @blog http://blog.csdn.net/IBM_hoojo
 * @email hoojo_@126.com
 * @version 1.0
 */
public class TestDownloadMain {
 
    public static void main(String[] args) {
        /*DownloadInfo bean = new DownloadInfo("http://i7.meishichina.com/Health/UploadFiles/201109/2011092116224363.jpg");
        System.out.println(bean);
        BatchDownloadFile down = new BatchDownloadFile(bean);
        new Thread(down).start();*/
        
        //DownloadUtils.download("http://i7.meishichina.com/Health/UploadFiles/201109/2011092116224363.jpg");
        DownloadUtils.download("http://mp3.baidu.com/j?j=2&url=http%3A%2F%2Fzhangmenshiting2.baidu.com%2Fdata%2Fmusic%2F1669425%2F%25E9%2599%25B7%25E5%2585%25A5%25E7%2588%25B1%25E9%2587%258C%25E9%259D%25A2.mp3%3Fxcode%3D2ff36fb70737c816553396c56deab3f1", "aa.mp3", "c:/temp", 5);
    }
}
多线程下载主要在第三部和第四部，其他的地方还是很好理解。源码中提供相应的注释了，便于理解。






study
线程基本方法


setPriority(10)//设置线程优先级，效果不明显
 setDaemon(true)//设置后台线程，不争抢资源，效果不明显
yield()//
 sleep(10)//
  
 Copyright ©2011 lyt. All Rights Reserved.
 
 
 
 
 
study
创建线程

 // 1、必须有线程类
  ThreadTest tt = new ThreadTest();
  // Thread代表线程2.Thread封装线程类
  Thread t = new Thread(tt);
  // 启动线程，通过start方法自动调用run方法
  t.start();
  Thread th = new Thread(tt);
  th.start();
 Copyright ©2011 lyt. All Rights Reserved.
 
 
 
study
线程类

1.继承Thread
class TestThread extends Thread{
    @Override
   public void run(){
       for(int i=0;i<30;i++){
           System.out.println(Thread.currentThread().getName()+i);
       }
   }
}
 2.实现Runnable
 class ThreadTest implements Runnable {
 public void run() {
  for (int i = 0; i < 30; i++) {
   System.out.println("NO-----" + i);
  }
 }
}
 Copyright ©2011 lyt. All Rights Reserved.
 
 
 
study
自定义中断

class MyThread1 extends Thread{
  boolean flag=true;
     int i=0;
  public void run(){
  while(flag){
   System.out.println(i);
   i++;
  }
 }
  public void shutdown(){
   this.flag=false;
  }
}
 Copyright ©2011 lyt. All Rights Reserved.
 
 
 
 
 
 
study
线程独立、共享

//线程独立
  new TestThread1().start();
  new TestThread1().start();
  new TestThread1().start(); 
//线程共享  TestThread2 tt = new TestThread2();
  new Thread(tt).start();
  new Thread(tt).start();
  new Thread(tt).start();
  new Thread(tt).start();
// 线程共享同步监视 public static void main(String[] args)
 {
  TestThread3 tt = new TestThread3();
  new Thread(tt).start();
  new Thread(tt).start();
  new Thread(tt).start();
  new Thread(tt).start();
  System.out.println("Hello World!");
 }
class TestThread3 implements Runnable
{
 private int tickets = 100;
 private Object obj = new Object();//用来做同步的对象，这个对象必须得是成员变量，否则无法共享。
 public void run()
 {
  while(true)
  {
   synchronized(obj){//当有线程进入时，obj进入锁状态，这样别的线程就进不来，直到进入的线程解锁。
    if(tickets > 0)
    {
     try{
      Thread.sleep(10);
     }
     catch(InterruptedException e)
     {
      System.out.println(e.getMessage());
     }
     System.out.println(Thread.currentThread().getName() + ",tickets :" + tickets--);
    }
    else
     break;
   }
  }
 }
}
 Copyright ©2011 lyt. All Rights Reserved.
 
 
 
 
 
 
 
study
线程池

最近在学习线程池的东西，前面有篇文章《线程池的设计原则》，当然大多都是参考别人的思想。然后发现自己多线程真的写的太少了。现在来补充基础知识咯。。。 
wait导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。当前的线程必须拥有此对象监视器。该线程发布对此监视器的所有权并等待，直到其他线程通过调用 notify 方法，或 notifyAll 方法通知在此对象的监视器上等待的线程醒来。然后该线程将等到重新获得对监视器的所有权后才能继续执行.
以上是jdk api的说明,对照说明写个测试：

<!--<br /><br />Code highlighting produced by Actipro CodeHighlighter (freeware)<br />http://www.CodeHighlighter.com/<br /><br />-->public class Test extends Thread {

    @Override
    public void run() {
        System.out.println("before wait!");
        try {
            synchronized (this) {
                this.wait();
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        try {
            Thread.sleep(20000);
        } catch (Exception e) {
            System.out.println("interrupted!");
        }
        System.out.println("after wait!");
    }

    public synchronized void weakup() {
        this.notify();
    }
}

public class Main {

    public static void main(String[] args) {
        Test test = new Test();
        test.start();
        System.out.println("shit");
        try {
            Thread.sleep(2000);
        } catch (Exception e) {
        }
        test.weakup();
        try {
            Thread.sleep(2000);
        } catch (Exception e) {
        }
        test.interrupt();
        System.out.println("shit");
    }

wait和notify针对的是对象，而不是线程。因为这两个方法都是Object的方法。与线程无关。
所有的线程结束之后，程序才会结束。此处如果不sleep的话，有可能weakup会早于wait先调用。
执行interrupt()时,并不需要获取Thread实例的锁定.任何线程在任何时刻,都可以调用其他线程interrupt().当sleep中的线程被调用interrupt()时,就会放弃暂停的状态.并抛出InterruptedException.
interrupt()不会中断一个正在运行的线程。这一方法实际上完成的是，在线程受到阻塞时抛出一个中断信号，这样线程就得以退出阻塞的状态。更确切的说，如果线程被Object.wait, Thread.join和Thread.sleep三种方法之一阻塞，那么，它将接收到一个中断异常（InterruptedException），从而提早地终结被阻塞状态。 
如果线程没有被阻塞，这时调用interrupt()将不起作用；否则，线程就将得到异常（该线程必须事先预备好处理此状况），接着逃离阻塞状态。 
线程A在执行sleep,wait,join时,线程B调用A的interrupt方法,的确这一个时候A会有InterruptedException异常抛出来.但这其实是在sleep,wait,join这些方法内部会不断检查中断状态的值,而自己抛出的InterruptedException。 
如果线程A正在执行一些指定的操作时如赋值,for,while,if,调用方法等,都不会去检查中断状态,所以线程A不会抛出InterruptedException,而会一直执行着自己的操作.当线程A终于执行到wait(),sleep(),join()时,才马上会抛出InterruptedException. 
若没有调用sleep(),wait(),join()这些方法,或是没有在线程里自己检查中断状态自己抛出InterruptedException的话,那
InterruptedException是不会被抛出来的. 
下面再看tomcat的线程池就比较清楚了：

<!--<br /><br />Code highlighting produced by Actipro CodeHighlighter (freeware)<br />http://www.CodeHighlighter.com/<br /><br />-->class ControlRunnable implements Runnable {
        ThreadPool p;
        Thread t;
        ThreadPoolRunnable toRun;
        boolean shouldTerminate;
        boolean shouldRun;
        boolean noThData;
        Object thData[] = null;

        ControlRunnable(ThreadPool p) {
            toRun = null;
            shouldTerminate = false;
            shouldRun = false;
            this.p = p;
            t = new Thread(this);
            t.start();
            noThData = true;
            thData = null;
        }

        public void run() {
            while (true) {
                try {
                    synchronized (this) {
                        if (!shouldRun && !shouldTerminate) {
                            this.wait();
                        }
                    }
                    if (shouldTerminate) {
                        break;
                    }
                    try {
                        if (noThData) {
                            thData = toRun.getInitData();
                            noThData = false;
                        }
                        if (shouldRun) {
                            toRun.runIt(thData);
                        }
                    } catch (Throwable t) {
                        System.err.println("ControlRunnable Throwable: ");
                        t.printStackTrace();
                        shouldTerminate = true;
                        shouldRun = false;
                        p.notifyThreadEnd();
                    } finally {
                        if (shouldRun) {
                            shouldRun = false;
                            p.returnController(this);
                        }
                    }
                    if (shouldTerminate) {
                        break;
                    }
                } catch (InterruptedException ie) {
                }
            }
        }

        public synchronized void runIt(ThreadPoolRunnable toRun) {
            if (toRun == null) {
                throw new NullPointerException("No Runnable");
            }
            this.toRun = toRun;
            shouldRun = true;
            this.notify();
        }

        public synchronized void terminate() {
            shouldTerminate = true;
            this.notify();
        }

ControlRunnable线程类是线程池中的具体线程，线程构造函数中调用线程的start开始线程，到run方法里得到自己的锁然后wait，等待具体的动作调用：runIt，动作调用就可以notify线程了。里边将线程要做的具体工作委托给了ThreadPoolRunnable接口，用户要使用线程池，只用将自己的任务实现此接口即可。ThreadPoolRunnable的代码如下：
<!--<br /><br />Code highlighting produced by Actipro CodeHighlighter (freeware)<br />http://www.CodeHighlighter.com/<br /><br />-->public interface ThreadPoolRunnable {
    public Object[] getInitData();
    
        public void runIt(Object thData[]);
}
另外，ThreadPool本身还运行了一个MonitorRunnable的线程，用来管理线程池。当(currentThreadCount - currentThreadsBusy) > maxSpareThreads，就会调用ControlRunnable类的terminate方法删除空闲线程，准备删除的线程是否空闲是通过shouldTerminate参数来判断。线程池采用Vector来存储当前空闲的线程。
 
接下来回去研究java nio包。网络编程也是自己一直都想去系统的学习的东西。而且，在java nio中有很多和多线程相通的地方。比如非阻塞和多线程，当然，他们不是一个意思。
Java线程池的瑕疵,For java util concurrent threadpool Since jdk1.5
    java.util.concurrent的作者是Doug Lea : 世界上对Java影响力最大的个人,在jdk1.5之前大家一定熟悉他的backport-util-concurrent.jar."这个鼻梁挂着眼镜，留着德王威廉二世的胡子，脸上永远挂着谦逊腼腆笑容，服务于纽约州立大学Oswego分校计算器科学系的老大爷。",他可是并发编程的大师级人物哦!
    Since jdk1.5,在java.util.concurrent包下的线程池模型是基于queue的,threadpool只有一个,而queue却有多个LinkedBlockingQueue,SynchronousQueue,ScheduledThreadPoolExecutor.DelayedWorkQueue等可参见java.util.concurrent.Executors.注意:我下面的问题是针对LinkedBlockingQueue的,参考的src为jdk1.6.
    Threadpool通过以下的3个属性来标志池中的线程数:
corePoolSize(类似minimumPoolSize),poolSize(当前池中的线程数),maximumPoolSize(最大的线程数).
这3个属性表达的意思是每次新创建或结束一个线程poolSize++/--,在最忙的情况下threadpool创建的线程数不能超过maximumPoolSize,
当空闲的情况下poolSize应该降到corePoolSize,当然threadpool如果从创建时它就从来没有处理过一次请求的话,那么poolSize当然为0.
    通过以上2段的说明下面我要引出我所要讲的问题:
我们来看一下java.util.concurrent.ThreadPoolExecutor的execute方法:
public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        if (poolSize >= corePoolSize || !addIfUnderCorePoolSize(command)) {
            if (runState == RUNNING && workQueue.offer(command)) {
                if (runState != RUNNING || poolSize == 0)
                    ensureQueuedTaskHandled(command);
            }
            else if (!addIfUnderMaximumPoolSize(command))
                reject(command); // is shutdown or saturated
        }
}
它表达的主体意思是:如果当前的poolSize<corePoolSize,那么就增加线程直到poolSize==corePoolSize.
如果poolSize已经到达corePoolSize,那么就把command(task) put to workQueue,如果workQueue为LinkedBlockingQueue的话,
那么只有当workQueue offer commands达到workQueue.capacity后,threadpool才会继续增加线程直到maximumPoolSize.
1.*****如果LinkedBlockingQueue.capacity被设置为Integer.MAX_VALUE,那么池中的线程几乎不可能到达maximumPoolSize.*****
所以你如果使用了Executors.newFixedThreadPool的话,那么maximumPoolSize和corePoolSize是一样的并且LinkedBlockingQueue.capacity==Integer.MAX_VALUE,或者如果这样new ThreadPoolExecutor(corePoolSize,maximumPoolSize,keepAliveTime,timeUnit,new LinkedBlockingQueue<Runnable>(/*Integer.MAX_VALUE*/))的话,
上述的使用都将导致maximumPoolSize是无效的,也就是说线程池中的线程数不会超出corePoolSize.
这个也让那些tomcat6的开发人员可能也郁闷了,他们不得不改写LinkedBlockingQueue,以tomcat-6.0.20-src为例:
org.apache.tomcat.util.net.NioEndpoint.TaskQueue extends LinkedBlockingQueue<Runnable> override offer method: 
 public void setParent(ThreadPoolExecutor tp, NioEndpoint ep) {
            parent = tp;
            this.endpoint = ep;
        }
        
        public boolean offer(Runnable o) {
            //we can't do any checks
            if (parent==null) return super.offer(o);
            //we are maxed out on threads, simply queue the object
            if (parent.getPoolSize() == parent.getMaximumPoolSize()) return super.offer(o);
            //we have idle threads, just add it to the queue
            //this is an approximation, so it could use some tuning
            if (endpoint.activeSocketProcessors.get()<(parent.getPoolSize())) return super.offer(o);
            //if we have less threads than maximum force creation of a new thread
            if (parent.getPoolSize()<parent.getMaximumPoolSize()) return false;
            //if we reached here, we need to add it to the queue
            return super.offer(o);
        } 
org.apache.tomcat.util.net.NioEndpoint.start()-->
   TaskQueue taskqueue = new TaskQueue();/***queue.capacity==Integer.MAX_VALUE***/
                     TaskThreadFactory tf = new TaskThreadFactory(getName() + "-exec-");
                     executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), 60,TimeUnit.SECONDS,taskqueue, tf);
                     taskqueue.setParent( (ThreadPoolExecutor) executor, this);
2.*****如果把LinkedBlockingQueue.capacity设置为一个适当的值远小于Integer.MAX_VALUE,那么只有put到queue的任务数到达LinkedBlockingQueue的capacity后,才会继续增加池中的线程,使得poolSize超出corePoolSize但不超过maximumPoolSize,这个时候来增加线程数是不是有点晚了呢??????*****.
这样一来reject(command)也可能随之而来了,LinkedBlockingQueue.capacity设置为何值又是个头疼的问题.
所以ThreadPoolExecutor+LinkedBlockingQueue表达的意思是首先会增加线程数到corePoolSize,但只有queue的任务容量到达最大capacity后,才会继续在corePoolSize的基数上增加线程来处理任务,直到maximumPoolSize.
    但为什么我们不能这样呢:将LinkedBlockingQueue.capacity设置为Integer.MAX_VALUE,让task尽可能的得到处理,同时在忙的情况下,增加池中的线程充到maximumPoolSize来尽快的处理这些任务.即便是把LinkedBlockingQueue.capacity设置为一个适当的值<<<远小于Integer.MAX_VALUE,也不一定非得在任务数到达LinkedBlockingQueue的capacity之后才去增加线程使poolSize超出corePoolSize趋向maximumPoolSize.
    所以java util concurrent中的ThreadPoolExecutor+LinkedBlockingQueue组合的缺点也就出来了:如果我们想让线程池尽可能多的处理大量的任务的话,我们会把LinkedBlockingQueue.capacity设置为Integer.MAX_VALUE,但是如果这样的话池中的线程数量就不能充到最大maximumPoolSize,也就不能充分发挥线程池的最大处理能力.如果我们把LinkedBlockingQueue.capacity设置为一个较小的值,那么线程池中的线程数量会充到最大maximumPoolSize,但是如果池中的线程都忙的话,线程池又会reject请求的任务,因为队列已满.
    如果我们把LinkedBlockingQueue.capacity设置为一个较大的值但不是Integer.MAX_VALUE,那么等到线程池的线程数量准备开始超出corePoolSize时,也就是任务队列满了,这个时候才去增加线程的话,请求任务的执行会有一定的延时,也就是没有得到及时的处理.
    其实也就是说ThreadPoolExecutor缺乏灵敏的线程调度机制,没有根据当前任务的执行情况,是忙,还是闲,以及队列中的待处理任务的数量级进行动态的调配线程数,使得它的处理效率受到影响.
那么什么是忙的情况的判断呢?  
busy[1]:如果poolSize==corePoolSize,并且现在忙着执行任务的线程数(currentBusyWorkers)等于poolSize.[而不管现在put到queue的任务数是否到达queue.capacity]
busy[2].1:如果poolSize==corePoolSize,并且put到queue的任务数已到达queue.capacity.[queue.capacity是针对有任务队列极限限制的情况]
busy[2].2:线程池的基本目标是尽可能的快速处理大量的请求任务,那么就不一定非得在put到queue的任务数到达queue的capacity之后才判断为忙的情况,只要queue中现有的任务数(task_counter)与poolSize或者maximumPoolSize存在一定的比例时就可以判断为忙情,比如task_counter>=poolSize或者maximumPoolSize的(NumberOfProcessor+1)倍,这样queue.capacity这个限制可以取消了.
在上述busy[1],busy[2]这2种情况下都应增加线程数,直至maximumPoolSize,使请求的任务得到最快的处理.
前面讲的是忙的时候ThreadPoolExecutor+LinkedBlockingQueue在处理上的瑕疵,那么空闲的时候又要如何呢?
如果corePoolSize<poolSize<maximumPoolSize,那么线程等待keepAliveTime之后应该降为corePoolSize,嘿嘿,这个就真的成了bug了哦,一个很难发现的bug,poolSize是被降下来了,可是很可能降过了头<corePoolSize,甚至降为0也有可能.
ThreadPoolExecutor.Worker.run()-->ThreadPoolExecutor.getTask():
Runnable getTask() {
        for (;;) {
            try {
                int state = runState;
                if (state > SHUTDOWN)
                    return null;
                Runnable r;
                if (state == SHUTDOWN)  // Help drain queue
                    r = workQueue.poll();
                else if (poolSize > corePoolSize || allowCoreThreadTimeOut)
      /*queue is empty,这里timeout之后,return null,之后call workerCanExit() return true.*/
                    r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS);
                else
                    r = workQueue.take();
                if (r != null)
                    return r;
                if (workerCanExit()) {
                    if (runState >= SHUTDOWN) // Wake up others
                        interruptIdleWorkers();
                    return null;
                }
                // Else retry
            } catch (InterruptedException ie) {
                // On interruption, re-check runState
            }
        }
}//end getTask.
private boolean workerCanExit() {
        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        boolean canExit;
        try {
            canExit = runState >= STOP ||
                workQueue.isEmpty() ||
                (allowCoreThreadTimeOut &&
                 poolSize > Math.max(1, corePoolSize));
        } finally {
            mainLock.unlock();
        }
        return canExit;
}//end workerCanExit.
在workerCanExit() return true之后,poolSize仍然大于corePoolSize,pooSize的值没有变化,
ThreadPoolExecutor.Worker.run()将结束-->ThreadPoolExecutor.Worker.workerDone-->这个时候才将poolSize--,可惜晚了,在多线程的环境下,poolSize的值将变为小于corePoolSize,而不是等于corePoolSize!!!!!!
例如:如果poolSize(6)大于corePoolSize(5),那么同时timeout的就不一定是一条线程,而是多条,它们都有可能退出run,使得poolSize--减过了corePoolSize.
    提一下java.util.concurrent.ThreadPoolExecutor的allowCoreThreadTimeOut方法, @since 1.6 public void allowCoreThreadTimeOut(boolean value);
它表达的意思是在空闲的时候让线程等待keepAliveTime,timeout后使得poolSize能够降为0.[其实我是希望它降为minimumPoolSize,特别是在服务器的环境下,我们需要线程池保持一定数量的线程来及时处理"零零碎碎的,断断续续的,一股一波的,不是很有压力的"请求],当然你可以把corePoolSize当作minimumPoolSize,而不调用该方法.
    针对上述java util concurrent线程池的瑕疵,我对java util concurrent线程池模型进行了修正,特别是在"忙"(busy[1],busy[2])的情况下的任务处理进行了优化,使得线程池尽可能快的处理尽可能多的任务.
 Copyright ©2011 lyt. All Rights Reserved.
 
 
 
 
 
 
study
java线程

什么是线程？
几乎每种操作系统都支持进程的概念—— 进程就是在某种程度上相互隔离的、独立运行的程序。
线程化是允许多个活动共存于一个进程中的工具。大多数现代的操作系统都支持线程，而且线程的
概念以各种形式已存在了好多年。Java 是第一个在语言本身中显式地包含线程的主流编程语言，它
没有把线程化看作是底层操作系统的工具。
有时候，线程也称作轻量级进程。就象进程一样，线程在程序中是独立的、并发的执行路径，每个
线程有它自己的堆栈、自己的程序计数器和自己的局部变量。但是，与分隔的进程相比，进程中的
线程之间的隔离程度要小。它们共享内存、文件句柄和其它每个进程应有的状态。
进程可以支持多个线程，它们看似同时执行，但互相之间并不同步。一个进程中的多个线程共享相
同的内存地址空间，这就意味着它们可以访问相同的变量和对象，而且它们从同一堆中分配对象。
尽管这让线程之间共享信息变得更容易，但您必须小心，确保它们不会妨碍同一进程里的其它线程。
Java 线程工具和 API 看似简单。但是，编写有效使用线程的复杂程序并不十分容易。因为有多个
线程共存在相同的内存空间中并共享相同的变量，所以您必须小心，确保您的线程不会互相干扰。
每个 Java 程序都使用线程
每个 Java 程序都至少有一个线程— 主线程。当一个 Java 程序启动时，JVM 会创建主线程，并
在该线程中调用程序的 main() 方法。
JVM 还创建了其它线程，您通常都看不到它们— 例如，与垃圾收集、对象终止和其它 JVM 内务处
理任务相关的线程。其它工具也创建线程，如 AWT（抽象窗口工具箱（Abstract Windowing Toolkit））
或 Swing UI 工具箱、servlet 容器、应用程序服务器和 RMI（远程方法调用（Remote Method
Invocation））。
为什么使用线程？
在 Java 程序中使用线程有许多原因。如果您使用 Swing、servlet、RMI 或 Enterprise JavaBeans
（EJB）技术，您也许没有意识到您已经在使用线程了。
使用线程的一些原因是它们可以帮助：
使 UI 响应更快
利用多处理器系统
简化建模
执行异步或后台处理
响应更快的UI
事件驱动的UI 工具箱（如 AWT 和 Swing）有一个事件线程，它处理 UI 事件，如击键或鼠标点击。
AWT 和 Swing 程序把事件侦听器与 UI 对象连接。当特定事件（如单击了某个按钮）发生时，这些
侦听器会得到通知。事件侦听器是在 AWT 事件线程中调用的。
如果事件侦听器要执行持续很久的任务，如检查一个大文档中的拼写，事件线程将忙于运行拼写检
查器，所以在完成事件侦听器之前，就不能处理额外的 UI 事件。这就会使程序看来似乎停滞了，
让用户不知所措。
要避免使 UI 延迟响应，事件侦听器应该把较长的任务放到另一个线程中，这样 AWT 线程在任务的
执行过程中就可以继续处理 UI 事件（包括取消正在执行的长时间运行任务的请求）。
利用多处理器系统
多处理器（MP）系统比过去更普及了。以前只能在大型数据中心和科学计算设施中才能找到它们。
现在许多低端服务器系统— 甚至是一些台式机系统— 都有多个处理器。
现代操作系统，包括Linux、Solaris 和 Windows NT/2000，都可以利用多个处理器并调度线程在
任何可用的处理器上执行。
Java线程
Java爱好者第 5 页http://www.javafan.net
调度的基本单位通常是线程；如果某个程序只有一个活动的线程，它一次只能在一个处理器上运行。
如果某个程序有多个活动线程，那么可以同时调度多个线程。在精心设计的程序中，使用多个线程
可以提高程序吞吐量和性能。
简化建模
在某些情况下，使用线程可以使程序编写和维护起来更简单。考虑一个仿真应用程序，您要在其中
模拟多个实体之间的交互作用。给每个实体一个自己的线程可以使许多仿真和对应用程序的建模大
大简化。
另一个适合使用单独线程来简化程序的示例是在一个应用程序有多个独立的事件驱动的组件的时
候。例如，一个应用程序可能有这样一个组件，该组件在某个事件之后用秒数倒计时，并更新屏幕
显示。与其让一个主循环定期检查时间并更新显示，不如让一个线程什么也不做，一直休眠，直到
某一段时间后，更新屏幕上的计数器，这样更简单，而且不容易出错。这样，主线程就根本无需担
心计时器。
异步或后台处理
服务器应用程序从远程来源（如套接字）获取输入。当读取套接字时，如果当前没有可用数据，那
么对 SocketInputStream.read() 的调用将会阻塞，直到有可用数据为止。
如果单线程程序要读取套接字，而套接字另一端的实体并未发送任何数据，那么该程序只会永远等
待，而不执行其它处理。相反，程序可以轮询套接字，查看是否有可用数据，但通常不会使用这种
做法，因为会影响性能。
但是，如果您创建了一个线程来读取套接字，那么当这个线程等待套接字中的输入时，主线程就可
以执行其它任务。您甚至可以创建多个线程，这样就可以同时读取多个套接字。这样，当有可用数
据时，您会迅速得到通知（因为正在等待的线程被唤醒），而不必经常轮询以检查是否有可用数据。
使用线程等待套接字的代码也比轮询更简单、更不易出错。
Java线程
Java爱好者第 6 页http://www.javafan.net
简单，但有时有风险
虽然 Java 线程工具非常易于使用，但当您创建多线程程序时，应该尽量避免一些风险。
当多个线程访问同一数据项（如静态字段、可全局访问对象的实例字段或共享集合）时，需要确保
它们协调了对数据的访问，这样它们都可以看到数据的一致视图，而且相互不会干扰另一方的更改。
为了实现这个目的，Java 语言提供了两个关键字：synchronized 和 volatile。我们将稍后在本教
程中研究这些关键字的用途和意义。
当从多个线程中访问变量时，必须确保对该访问正确地进行了同步。对于简单变量，将变量声明成
volatile 也许就足够了，但在大多数情况下，需要使用同步。
如果您将要使用同步来保护对共享变量的访问，那么必须确保在程序中所有访问该变量的地方都使
用同步。
不要做过头
虽然线程可以大大简化许多类型的应用程序，过度使用线程可能会危及程序的性能及其可维护性。
线程消耗了资源。因此，在不降低性能的情况下，可以创建的线程的数量是有限制的。
尤其在单处理器系统中，使用多个线程不会使主要消耗 CPU 资源的程序运行得更快。
示例：使用一个线程用于计时，并使用另一个线程完成工作
以下示例使用两个线程，一个用于计时，一个用于执行实际工作。主线程使用非常简单的算法计算
素数。
在它启动之前，它创建并启动一个计时器线程，这个线程会休眠十秒钟，然后设置一个主线程要检
查的标志。十秒钟之后，主线程将停止。请注意，共享标志被声明成 volatile。
/**
Java线程
Java爱好者第 7 页http://www.javafan.net
* CalculatePrimes -- calculate as many primes as we can in ten seconds
*/
public class CalculatePrimes extends Thread {
public static final int MAX_PRIMES = 1000000;
public static final int TEN_SECONDS = 10000;
public volatile boolean finished = false;
public void run() {
int[] primes = new int[MAX_PRIMES];
int count = 0;
for (int i=2; count<MAX_PRIMES; i++) {
// Check to see if the timer has expired
if (finished) {
break;
}
boolean prime = true;
for (int j=0; j<count; j++) {
if (i % primes[j] == 0) {
prime = false;
break;
}
}
if (prime) {
primes[count++] = i;
System.out.println("Found prime: " + i);
}
}
}
public static void main(String[] args) {
CalculatePrimes calculator = new CalculatePrimes();
calculator.start();
try {
Thread.sleep(TEN_SECONDS);
}
Java线程
Java爱好者第 8 页http://www.javafan.net
catch (InterruptedException e) {
// fall through
}
calculator.finished = true;
}
}
小结
Java 语言包含了内置在语言中的功能强大的线程工具。您可以将线程工具用于：
增加 GUI 应用程序的响应速度
利用多处理器系统
当程序有多个独立实体时，简化程序逻辑
在不阻塞整个程序的情况下，执行阻塞I/O
当使用多个线程时，必须谨慎，遵循在线程之间共享数据的规则，我们将在共享对数据的访问中讨
论这些规则。所有这些规则归结为一条基本原则：不要忘了同步。
第三章线程的生命
创建线程
在 Java 程序中创建线程有几种方法。每个 Java 程序至少包含一个线程：主线程。其它线程都是
通过 Thread 构造器或实例化继承类 Thread 的类来创建的。
Java 线程可以通过直接实例化 Thread 对象或实例化继承 Thread 的对象来创建其它线程。在线程
基础中的示例（其中，我们在十秒钟之内计算尽量多的素数）中，我们通过实例化 CalculatePrimes
类型的对象（它继承了 Thread），创建了一个线程。
当我们讨论Java 程序中的线程时，也许会提到两个相关实体：完成工作的实际线程或代表线程的
Thread 对象。正在运行的线程通常是由操作系统创建的；Thread 对象是由 Java VM 创建的，作为
控制相关线程的一种方式。
Java线程
Java爱好者第 9 页http://www.javafan.net
创建线程和启动线程并不相同
在一个线程对新线程的 Thread 对象调用 start() 方法之前，这个新线程并没有真正开始执行。
Thread 对象在其线程真正启动之前就已经存在了，而且其线程退出之后仍然存在。这可以让您控制
或获取关于已创建的线程的信息，即使线程还没有启动或已经完成了。
通常在构造器中通过start() 启动线程并不是好主意。这样做，会把部分构造的对象暴露给新的线
程。如果对象拥有一个线程，那么它应该提供一个启动该线程的start() 或 init() 方法，而不是
从构造器中启动它。（请参阅参考资料，获取提供此概念更详细说明的文章链接。）
结束线程
线程会以以下三种方式之一结束：
线程到达其run() 方法的末尾。
线程抛出一个未捕获到的 Exception 或 Error。
另一个线程调用一个弃用的 stop() 方法。弃用是指这些方法仍然存在，但是您不应该在新
代码中使用它们，并且应该尽量从现有代码中除去它们。
当 Java 程序中的所有线程都完成时，程序就退出了。
加入线程
Thread API 包含了等待另一个线程完成的方法：join() 方法。当调用 Thread.join() 时，调用线
程将阻塞，直到目标线程完成为止。
Thread.join() 通常由使用线程的程序使用，以将大问题划分成许多小问题，每个小问题分配一个
线程。本章结尾处的示例创建了十个线程，启动它们，然后使用 Thread.join() 等待它们全部完成。
Java线程
Java爱好者第 10 页http://www.javafan.net
调度
除了何时使用 Thread.join() 和 Object.wait() 外，线程调度和执行的计时是不确定的。如果两
个线程同时运行，而且都不等待，您必须假设在任何两个指令之间，其它线程都可以运行并修改程
序变量。如果线程要访问其它线程可以看见的变量，如从静态字段（全局变量）直接或间接引用的
数据，则必须使用同步以确保数据一致性。
在以下的简单示例中，我们将创建并启动两个线程，每个线程都打印两行到 System.out：
public class TwoThreads {
public static class Thread1 extends Thread {
public void run() {
System.out.println("A");
System.out.println("B");
}
}
public static class Thread2 extends Thread {
public void run() {
System.out.println("1");
System.out.println("2");
}
}
public static void main(String[] args) {
new Thread1().start();
new Thread2().start();
}
}
我们并不知道这些行按什么顺序执行，只知道“1”在“2”之前打印，以及“A”在“B”之前打印。
输出可能是以下结果中的任何一种：
Java线程
Java爱好者第 11 页http://www.javafan.net
1 2 A B
1 A 2 B
1 A B 2
A 1 2 B
A 1 B 2
A B 1 2
不仅不同机器之间的结果可能不同，而且在同一机器上多次运行同一程序也可能生成不同结果。永
远不要假设一个线程会在另一个线程之前执行某些操作，除非您已经使用了同步以强制一个特定的
执行顺序。
休眠
Thread API 包含了一个 sleep() 方法，它将使当前线程进入等待状态，直到过了一段指定时间，
或者直到另一个线程对当前线程的 Thread 对象调用了 Thread.interrupt()，从而中断了线程。当
过了指定时间后，线程又将变成可运行的，并且回到调度程序的可运行线程队列中。
如果线程是由对 Thread.interrupt() 的调用而中断的，那么休眠的线程会抛出
InterruptedException，这样线程就知道它是由中断唤醒的，就不必查看计时器是否过期。
Thread.yield() 方法就象 Thread.sleep() 一样，但它并不引起休眠，而只是暂停当前线程片刻，
这样其它线程就可以运行了。在大多数实现中，当较高优先级的线程调用Thread.yield() 时，较
低优先级的线程就不会运行。
CalculatePrimes 示例使用了一个后台线程计算素数，然后休眠十秒钟。当计时器过期后，它就会
设置一个标志，表示已经过了十秒。
守护程序线程
我们提到过当 Java 程序的所有线程都完成时，该程序就退出，但这并不完全正确。隐藏的系统线
程，如垃圾收集线程和由 JVM 创建的其它线程会怎么样？我们没有办法停止这些线程。如果那些线
程正在运行，那么 Java 程序怎么退出呢？
Java线程
Java爱好者第 12 页http://www.javafan.net
这些系统线程称作守护程序线程。Java 程序实际上是在它的所有非守护程序线程完成后退出的。
任何线程都可以变成守护程序线程。可以通过调用Thread.setDaemon() 方法来指明某个线程是守
护程序线程。您也许想要使用守护程序线程作为在程序中创建的后台线程，如计时器线程或其它延
迟的事件线程，只有当其它非守护程序线程正在运行时，这些线程才有用。
示例：用多个线程分解大任务
在这个示例中，TenThreads 显示了一个创建了十个线程的程序，每个线程都执行一部分工作。该程
序等待所有线程全部完成，然后收集结果。
/**
* Creates ten threads to search for the maximum value of a large matrix.
* Each thread searches one portion of the matrix.
*/
public class TenThreads {
private static class WorkerThread extends Thread {
int max = Integer.MIN_VALUE;
int[] ourArray;
public WorkerThread(int[] ourArray) {
this.ourArray = ourArray;
}
// Find the maximum value in our particular piece of the array
public void run() {
for (int i = 0; i < ourArray.length; i++)
max = Math.max(max, ourArray[i]);
}
public int getMax() {
return max;
}
}
public static void main(String[] args) {
WorkerThread[] threads = new WorkerThread[10];
int[][] bigMatrix = getBigHairyMatrix();
Java线程
Java爱好者第 13 页http://www.javafan.net
int max = Integer.MIN_VALUE;
// Give each thread a slice of the matrix to work with
for (int i=0; i < 10; i++) {
threads[i] = new WorkerThread(bigMatrix[i]);
threads[i].start();
}
// Wait for each thread to finish
try {
for (int i=0; i < 10; i++) {
threads[i].join();
max = Math.max(max, threads[i].getMax());
}
}
catch (InterruptedException e) {
// fall through
}
System.out.println("Maximum value was " + max);
}
}
小结
就象程序一样，线程有生命周期：它们启动、执行，然后完成。一个程序或进程也许包含多个线程，
而这些线程看来互相单独地执行。
线程是通过实例化 Thread 对象或实例化继承Thread 的对象来创建的，但在对新的 Thread 对象
调用 start() 方法之前，这个线程并没有开始执行。当线程运行到其 run() 方法的末尾或抛出未
经处理的异常时，它们就结束了。
sleep() 方法可以用于等待一段特定时间；而join() 方法可能用于等到另一个线程完成。
第四章无处不在的线程
谁创建线程？
即使您从未显式地创建一个新线程，您仍可能会发现自己在使用线程。线程被从各种来源中引入到
我们的程序中。
有许多工具可以为您创建线程，如果要使用这些工具，应该了解线程如何交互，以及如何防止线程
互相干扰。
AWT 和Swing
任何使用 AWT 或 Swing 的程序都必须处理线程。AWT 工具箱创建单个线程，用于处理 UI 事件，
任何由 AWT 事件调用的事件侦听器都在 AWT 事件线程中执行。
您不仅必须关心同步对事件侦听器和其它线程之间共享的数据项的访问，而且还必须找到一种方法，
让由事件侦听器触发的长时间运行任务（如在大文档中检查拼写或在文件系统中搜索一个文件）在
后台线程中运行，这样当该任务运行时，UI 就不会停滞了（这可能还会阻止用户取消操作）。这样
做的一个好的框架示例是 SwingWorker 类（请参阅参考资料）。
AWT 事件线程并不是守护程序线程；这就是通常使用System.exit() 结束AWT 和Swing 应用程序
的原因。
使用 TimerTask
JDK 1.3 中，TimerTask 工具被引入到Java 语言。这个便利的工具让您可以稍后在某个时间执行
任务（例如，即从现在起十秒后运行一次任务），或者定期执行任务（即，每隔十秒运行任务）。
实现 Timer 类非常简单：它创建一个计时器线程，并且构建一个按执行时间排序的等待事件队列。
TimerTask 线程被标记成守护程序线程，这样它就不会阻止程序退出。
Java线程
Java爱好者第 15 页http://www.javafan.net
因为计时器事件是在计时器线程中执行，所以必须确保正确同步了针对计时器任___________务中使用的任何数
据项的访问。
在 CalculatePrimes 示例中，并没有让主线程休眠，我们可以使用 TimerTask，方法如下：
public static void main(String[] args) {
Timer timer = new Timer();
final CalculatePrimes calculator = new CalculatePrimes();
calculator.start();
timer.schedule(
new TimerTask() {
public void run()
{
calculator.finished = true;
}
}, TEN_SECONDS);
}
servlet 和JavaServer Pages 技术
servlet 容器创建多个线程，在这些线程中执行 servlet 请求。作为 servlet 编写者，您不知道
（也不应该知道）您的请求会在什么线程中执行；如果同时有多个对相同URL 的请求入站，那么同
一个 servlet 可能会同时在多个线程中是活动的。
当编写 servlet 或JavaServer Pages (JSP) 文件时，必须始终假设可以在多个线程中并发地执行
同一个 servlet 或JSP 文件。必须适当同步servlet 或 JSP 文件访问的任何共享数据；这包括
servlet 对象本身的字段。
实现 RMI 对象
Java线程
Java爱好者第 16 页http://www.javafan.net
RMI 工具可以让您调用对在其它 JVM 中运行的对象进行的操作。当调用远程方法时，RMI 编译器创
建的 RMI 存根会打包方法参数，并通过网络将它们发送到远程系统，然后远程系统会将它们解包并
调用远程方法。
假设您创建了一个 RMI 对象，并将它注册到RMI 注册表或者 Java 命名和目录接口（Java Naming
and Directory Interface (JNDI)）名称空间。当远程客户机调用其中的一个方法时，该方法会在
什么线程中执行呢？
实现 RMI 对象的常用方法是继承 UnicastRemoteObject。在构造 UnicastRemoteObject 时，会初
始化用于分派远程方法调用的基础结构。这包括用于接收远程调用请求的套接字侦听器，和一个或
多个执行远程请求的线程。
所以，当接收到执行RMI 方法的请求时，这些方法将在 RMI 管理的线程中执行。
小结
线程通过几种机制进入 Java 程序。除了用 Thread 构造器中显式创建线程之外，还可以用许多其
它机制创建线程：
AWT 和 Swing
RMI
java.util.TimerTask 工具
servlet 和JSP 技术
第五章共享对数据的访问
共享变量
要使多个线程在一个程序中有用，它们必须有某种方法可以互相通信或共享它们的结果。
让线程共享其结果的最简单方法是使用共享变量。它们还应该使用同步来确保值从一个线程正确传
播到另一个线程，以及防止当一个线程正在更新一些相关数据项时，另一个线程看到不一致的中间
结果。
线程基础中计算素数的示例使用了一个共享布尔变量，用于表示指定的时间段已经过去了。这说明
了在线程间共享数据最简单的形式是：轮询共享变量以查看另一个线程是否已经完成执行某项任务。
存在于同一个内存空间中的所有线程
正如前面讨论过的，线程与进程有许多共同点，不同的是线程与同一进程中的其它线程共享相同的
进程上下文，包括内存。这非常便利，但也有重大责任。只要访问共享变量（静态或实例字段），
线程就可以方便地互相交换数据，但线程还必须确保它们以受控的方式访问共享变量，以免它们互
相干扰对方的更改。
任何线程可以访问所有其作用域内的变量，就象主线程可以访问该变量一样。素数示例使用了一个
公用实例字段，叫做 finished，用于表示已经过了指定的时间。当计时器过期时，一个线程会写这
个字段；另一个线程会定期读取这个字段，以检查它是否应该停止。注：这个字段被声明成 volatile，
这对于这个程序的正确运行非常重要。在本章的后面，我们将看到原因。
受控访问的同步
为了确保可以在线程之间以受控方式共享数据，Java 语言提供了两个关键字：synchronized 和
volatile。
Java线程
Java爱好者第 18 页http://www.javafan.net
Synchronized 有两个重要含义：它确保了一次只有一个线程可以执行代码的受保护部分（互斥，
mutual exclusion 或者说 mutex），而且它确保了一个线程更改的数据对于其它线程是可见的（更
改的可见性）。
如果没有同步，数据很容易就处于不一致状态。例如，如果一个线程正在更新两个相关值（比如，
粒子的位置和速率），而另一个线程正在读取这两个值，有可能在第一个线程只写了一个值，还没
有写另一个值的时候，调度第二个线程运行，这样它就会看到一个旧值和一个新值。同步让我们可
以定义必须原子地运行的代码块，这样对于其他线程而言，它们要么都执行，要么都不执行。
同步的原子执行或互斥方面类似于其它操作环境中的临界段的概念。
确保共享数据更改的可见性
同步可以让我们确保线程看到一致的内存视图。
处理器可以使用高速缓存加速对内存的访问（或者编译器可以将值存储到寄存器中以便进行更快的
访问）。在一些多处理器体系结构上，如果在一个处理器的高速缓存中修改了内存位置，没有必要
让其它处理器看到这一修改，直到刷新了写入器的高速缓存并且使读取器的高速缓存无效。
这表示在这样的系统上，对于同一变量，在两个不同处理器上执行的两个线程可能会看到两个不同
的值！这听起来很吓人，但它却很常见。它只是表示在访问其它线程使用或修改的数据时，必须遵
循某些规则。
Volatile 比同步更简单，只适合于控制对基本变量（整数、布尔变量等）的单个实例的访问。当一
个变量被声明成 volatile，任何对该变量的写操作都会绕过高速缓存，直接写入主内存，而任何对
该变量的读取也都绕过高速缓存，直接取自主内存。这表示所有线程在任何时候看到的 volatile 变
量值都相同。
如果没有正确的同步，线程可能会看到旧的变量值，或者引起其它形式的数据损坏。
用锁保护的原子代码块
Volatile 对于确保每个线程看到最新的变量值非常有用，但有时我们需要保护比较大的代码片段，
如涉及更新多个变量的片段。
同步使用监控器（monitor）或锁的概念，以协调对特定代码块的访问。
每个 Java 对象都有一个相关的锁。同一时间只能有一个线程持有 Java 锁。当线程进入
synchronized 代码块时，线程会阻塞并等待，直到锁可用，当它可用时，就会获得这个锁，然后执
行代码块。当控制退出受保护的代码块时，即到达了代码块末尾或者抛出了没有在 synchronized 块
中捕获的异常时，它就会释放该锁。
这样，每次只有一个线程可以执行受给定监控器保护的代码块。从其它线程的角度看，该代码块可
以看作是原子的，它要么全部执行，要么根本不执行。
简单的同步示例
使用 synchronized 块可以让您将一组相关更新作为一个集合来执行，而不必担心其它线程中断或
看到计算的中间结果。以下示例代码将打印“1 0”或“0 1”。如果没有同步，它还会打印“1 1”
（或“0 0”，随便您信不信）。
public class SyncExample {
private static lockObject = new Object();
private static class Thread1 extends Thread {
public void run() {
synchronized (lockObject) {
x = y = 0;
System.out.println(x);
}
}
}
private static class Thread2 extends Thread {
public void run() {
synchronized (lockObject) {
Java线程
Java爱好者第 20 页http://www.javafan.net
x = y = 1;
System.out.println(y);
}
}
}
public static void main(String[] args) {
new Thread1().run();
new Thread2().run();
}
}
在这两个线程中都必须使用同步，以便使这个程序正确工作。
Java 锁定
Java 锁定合并了一种互斥形式。每次只有一个线程可以持有锁。锁用于保护代码块或整个方法，必
须记住是锁的身份保护了代码块，而不是代码块本身，这一点很重要。一个锁可以保护许多代码块
或方法。
反之，仅仅因为代码块由锁保护并不表示两个线程不能同时执行该代码块。它只表示如果两个线程
正在等待相同的锁，则它们不能同时执行该代码。
在以下示例中，两个线程可以同时不受限制地执行 setLastAccess() 中的synchronized 块，因为
每个线程有一个不同的 thingie 值。因此，synchronized 代码块受到两个正在执行的线程中不同
锁的保护。
public class SyncExample {
public static class Thingie {
private Date lastAccess;
public synchronized void setLastAccess(Date date) {
this.lastAccess = date;
}
}
Java线程
Java爱好者第 21 页http://www.javafan.net
public static class MyThread extends Thread {
private Thingie thingie;
public MyThread(Thingie thingie) {
this.thingie = thingie;
}
public void run() {
thingie.setLastAccess(new Date());
}
}
public static void main() {
Thingie thingie1 = new Thingie(),
thingie2 = new Thingie();
new MyThread(thingie1).start();
new MyThread(thingie2).start();
}
}
同步的方法
创建 synchronized 块的最简单方法是将方法声明成 synchronized。这表示在进入方法主体之前，
调用者必须获得锁：
public class Point {
public synchronized void setXY(int x, int y) {
this.x = x;
this.y = y;
}
}
对于普通的synchronized 方法，这个锁是一个对象，将针对它调用方法。对于静态synchronized
方法，这个锁是与 Class 对象相关的监控器，在该对象中声明了方法。
Java线程
Java爱好者第 22 页http://www.javafan.net
仅___________仅因为 setXY() 被声明成synchronized 并不表示两个不同的线程不能同时执行 setXY()，只要
它们调用不同的 Point 实例的 setXY() 就可同时执行。对于一个Point 实例，一次只能有一个线
程执行 setXY()，或Point 的任何其它 synchronized 方法。
同步的块
synchronized 块的语法比 synchronized 方法稍微复杂一点，因为还需要显式地指定锁要保护哪个
块。Point 的以下版本等价于前一页中显示的版本：
public class Point {
public void setXY(int x, int y) {
synchronized (this) {
this.x = x;
this.y = y;
}
}
}
使用 this 引用作为锁很常见，但这并不是必需的。这表示该代码块将与这个类中的 synchronized
方法使用同一个锁。
由于同步防止了多个线程同时执行一个代码块，因此性能上就有问题，即使是在单处理器系统上。
最好在尽可能最小的需要保护的代码块上使用同步。
访问局部（基于堆栈的）变量从来不需要受到保护，因为它们只能被自己所属的线程访问。
大多数类并没有同步
因为同步会带来小小的性能损失，大多数通用类，如java.util 中的 Collection 类，不在内部使
用同步。这表示在没有附加同步的情况下，不能在多个线程中使用诸如 HashMap 这样的类。
Java线程
Java爱好者第 23 页http://www.javafan.net
通过每次访问共享集合中的方法时使用同步，可以在多线程应用程序中使用 Collection 类。对于
任何给定的集合，每次必须用同一个锁进行同步。通常可以选择集合对象本身作为锁。
下一页中的示例类 SimpleCache 显示了如何使用 HashMap 以线程安全的方式提供高速缓存。但是，
通常适当的同步并不只是意味着同步每个方法。
Collections 类提供了一组便利的用于List、Map 和 Set 接口的封装器。您可以用
Collections.synchronizedMap 封装 Map，它将确保所有对该映射的访问都被正确同步。
如果类的文档没有说明它是线程安全的，那么您必须假设它不是。
示例：简单的线程安全的高速缓存
如以下代码样本所示，SimpleCache.java 使用 HashMap 为对象装入器提供了一个简单的高速缓存。
load() 方法知道怎样按对象的键装入对象。在一次装入对象之后，该对象就被存储到高速缓存中，
这样以后的访问就会从高速缓存中检索它，而不是每次都全部地装入它。对共享高速缓存的每个访
问都受到 synchronized 块保护。由于它被正确同步，所以多个线程可以同时调用getObject 和
clearCache 方法，而没有数据损坏的风险。
public class SimpleCache {
private final Map cache = new HashMap();
public Object load(String objectName) {
// load the object somehow
}
public void clearCache() {
synchronized (cache) {
cache.clear();
}
}
public Object getObject(String objectName) {
synchronized (cache) {
Object o = cache.get(objectName);
Java线程
Java爱好者第 24 页http://www.javafan.net
if (o == null) {
o = load(objectName);
cache.put(objectName, o);
}
}
return o;
}
}
小结
由于线程执行的计时是不确定的，我们需要小心，以控制线程对共享数据的访问。否则，多个并发
线程会互相干扰对方的更改，从而损坏数据，或者其它线程也许不能及时看到对共享数据的更改。
通过使用同步来保护对共享变量的访问，我们可以确保线程以可预料的方式与程序变量进行交互。
每个 Java 对象都可以充当锁，synchronized 块可以确保一次只有一个线程执行由给定锁保护的
synchronized 代码。
Java线程
Java爱好者第 25 页http://www.javafan.net
第六章同步详细信息
互斥
在共享对数据的访问中，我们讨论了 synchronized 块的特征，并在实现典型互斥锁（即，互斥或
临界段）时说明了它们，其中每次只有一个线程可以执行受给定锁保护的代码块。
互斥是同步所做工作的重要部分，但同步还有其它几种特征，这些特征对于在多处理器系统上取得
正确结果非常重要。
可见性
除了互斥，同步（如 volatile）强制某些可见性约束。当对象获取锁时，它首先使自己的高速缓存
无效，这样就可以保证直接从主内存中装入变量。
同样，在对象释放锁之前，它会刷新其高速缓存，强制使已做的任何更改都出现在主内存中。
这样，会保证在同一个锁上同步的两个线程看到在synchronized 块内修改的变量的相同值。
什么时候必须同步？
要跨线程维护正确的可见性，只要在几个线程之间共享非 final 变量，就必须使用 synchronized
（或 volatile）以确保一个线程可以看见另一个线程做的更改。
可见性同步的基本规则是在以下情况中必须同步：
读取上一次可能是由另一个线程写入的变量
写入下一次可能由另一个线程读取的变量
用于一致性的同步
除了用于可见性的同步，从应用程序角度看，您还必须用同步来确保一致性得到了维护。当修改多
个相关值时，您想要其它线程原子地看到这组更改— 要么看到全部更改，要么什么也看不到。这
Java线程
Java爱好者第 26 页http://www.javafan.net
适用于相关数据项（如粒子的位置和速率）和元数据项（如链表中包含的数据值和列表自身中的数
据项的链）。
考虑以下示例，它实现了一个简单（但不是线程安全的）的整数堆栈：
public class UnsafeStack {
public int top = 0;
public int[] values = new int[1000];
public void push(int n) {
values[top++] = n;
}
public int pop() {
return values[--top];
}
}
如果多个线程试图同时使用这个类，会发生什么？这可能是个灾难。因为没有同步，多个线程可以
同时执行 push() 和pop()。如果一个线程调用 push()，而另一个线程正好在递增了 top 并要把
它用作 values 的下标之间调用 push()，会发生什么？结果，这两个线程会把它们的新值存储到相
同的位置！当多个线程依赖于数据值之间的已知关系，但没有确保只有一个线程可以在给定时间操
作那些值时，可能会发生许多形式的数据损坏，而这只是其中之一。
对于这种情况，补救办法很简单：同步push() 和pop() 这两者，您将防止线程执行相互干扰。
请注意，使用 volatile 还不够— 需要使用 synchronized 来确保 top 和 values 之间的关系保
持一致。
递增共享计数器
通常，如果正在保护一个基本变量（如一个整数），有时只使用volatile 就可以侥幸过关。但是，
如果变量的新值派生自以前的值，就必须使用同步。为什么？考虑这个类：
Java线程
Java爱好者第 27 页http://www.javafan.net
public class Counter {
private int counter = 0;
public int get() { return counter; }
public void set(int n) { counter = n; }
public void increment() {
set(get() + 1);
}
}
当我们要递增计数器时，会发生什么？请看 increment() 的代码。它很清楚，但不是线程安全的。
如果两个线程试图同时执行 increment()，会发生什么？计数器也许会增加 1，也许增加 2。令人
惊奇的是，把counter 标记成volatile 没有帮助，使 get() 和 set() 都变成 synchronized 也
没有帮助。
设想计数器是零，而两个线程同时执行递增操作代码。这两个线程会调用Counter.get()，并且看
到计数器是零。现在两个线程都对它加一，然后调用 Counter.set()。如果我们的计时不太凑巧，
那么这两个线程都看不到对方的更新，即使 counter 是 volatile，或者get() 和 set() 是
synchronized。现在，即使计数器递增了两次，得到的值也许只是一，而不是二。
要使递增操作正确运行，不仅get() 和 set() 必须是 synchronized，而且 increment() 也必需
是 synchronized！否则，调用 increment() 的线程可能会中断另一个调用 increment() 的线程。
如果您不走运，最终结果将会是计数器只增加了一次，不是两次。同步 increment() 防止了这种情
况的发生，因为整个递增操作是原子的。
当循环遍历Vector 的元素时，同样如此。即使同步了 Vector 的方法，但在循环遍历时，Vector 的
内容仍然会更改。如果要确保Vector 的内容在循环遍历时不更改，必须同步整个代码块。
不变性和final 字段
许多 Java 类，包括String、Integer 和 BigDecimal，都是不可改变的：一旦构造之后，它们的
状态就永远不会更改。如果某个类的所有字段都被声明成 final，那么这个类就是不可改变的。（实
Java线程
Java爱好者第 28 页http://www.javafan.net
际上，许多不可改变的类都有非 final 字段，用于高速缓存以前计算的方法结果，如
String.hashCode()，但调用者看不到这些字段。）
不可改变的类使并发编程变得非常简单。因为不能更改它们的字段，所以就不需要担心把状态的更
改从一个线程传递到另一个线程。在正确构造了对象之后，可以把它看作是常量。
同样，final 字段对于线程也更友好。因为 final 字段在初始化之后，它们的值就不能更改，所以
当在线程之间共享 final 字段时，不需要担心同步访问。
什么时候不需要同步
在某些情况中，您不必用同步来将数据从一个线程传递到另一个，因为 JVM 已经隐含地为您执行同
步。这些情况包括：
由静态初始化器（在静态字段上或 static{} 块中的初始化器）初始化数据时
访问 final 字段时
在创建线程之前创建对象时
线程可以看见它将要处理的对象时
死锁
只要您拥有多个进程，而且它们要争用对多个锁的独占访问，那么就有可能发生死锁。如果有一组
进程或线程，其中每个都在等待一个只有其它进程或线程才可以执行的操作，那么就称它们被死锁
了。
最常见的死锁形式是当线程 1 持有对象 A 上的锁，而且正在等待与 B 上的锁，而线程 2 持有对
象 B 上的锁，却正在等待对象 A 上的锁。这两个线程永远都不会获得第二个锁，或者释放第一个
锁。它们只会永远等待下去。
要避免死锁，应该确保在获取多个锁时，在所有的线程中都以相同的顺序获取锁。
Java线程
Java爱好者第 29 页http://www.javafan.net
性能考虑事项
关于同步的性能代价有许多说法— 其中有许多是错的。同步，尤其是争用的同步，确实有性能问
题，但这些问题并没有象人们普遍怀疑的那么大。
许多人都使用别出心裁但不起作用的技巧以试图避免必须使用同步，但最终都陷入了麻烦。一个典
型的示例是双重检查锁定模式（请参阅参考资料，其中有几篇文章讲述了这种模式有什么问题）。
这种看似无害的结构据说可以避免公共代码路径上的同步，但却令人费解地失败了，而且所有试图
修正它的尝试也失败了。
在编写并发代码时，除非看到性能问题的确凿证据，否则不要过多考虑性能。瓶颈往往出现在我们
最不会怀疑的地方。投机性地优化一个也许最终根本不会成为性能问题的代码路径— 以程序正确
性为代价— 是一桩赔本的生意。
同步准则
当编写 synchronized 块时，有几个简单的准则可以遵循，这些准则在避免死锁和性能危险的风险
方面大有帮助：
使代码块保持简短。Synchronized 块应该简短— 在保证相关数据操作的完整性的同时，
尽量简短。把不随线程变化的预处理和后处理移出synchronized 块。
不要阻塞。不要在synchronized 块或方法中调用可能引起阻塞的方法，如
InputStream.read()。
在持有锁的时候，不要对其它对象调用方法。这听起来可能有些极端，但它消除了最常见的
死锁源头。
Java线程
Java爱好者第 30 页http://www.javafan.net
第七章其它线程API详细信息
wait()、notify() 和notifyAll() 方法
除了使用轮询（它可能消耗大量 CPU 资源，而且具有计时不精确的特征），Object 类还包括一些
方法，可以让线程相互通知事件的发生。
Object 类定义了wait()、notify()和notifyAll()方法。要执行这些方法，必须拥有相关对象的锁。
Wait() 会让调用线程休眠，直到用 Thread.interrupt() 中断它、过了指定的时间、或者另一个线
程用 notify() 或 notifyAll() 唤醒它。
当对某个对象调用 notify() 时，如果有任何线程正在通过 wait() 等待该对象，那么就会唤醒其
中一个线程。当对某个对象调用 notifyAll() 时，会唤醒所有正在等待该对象的线程。
这些方法是更复杂的锁定、排队和并发性代码的构件。但是，notify() 和 notifyAll() 的使用很
复杂。尤其是，使用 notify() 来代替notifyAll() 是有风险的。除非您确实知道正在做什么，否
则就使用 notifyAll()。
与其使用 wait() 和notify() 来编写您自己的调度程序、线程池、队列和锁，倒不如使用
util.concurrent 包（请参阅参考资料），这是一个被广泛使用的开放源码工具箱，里面都是有用
的并发性实用程序。JDK 1.5 将包括 java.util.concurrent 包；它的许多类都派生自
util.concurrent。
线程优先级
Thread API 让您可以将执行优先级与每个线程关联起来。但是，这些优先级如何映射到底层操作系
统调度程序取决于实现。在某些实现中，多个— 甚至全部— 优先级可能被映射成相同的底层操
作系统优先级。
在遇到诸如死锁、资源匮乏或其它意外的调度特征问题时，许多人都想要调整线程优先级。但是，
通常这样只会把问题移到别的地方。大多数程序应该完全避免更改线程优先级。
线程组
ThreadGroup 类原本旨在用于把线程集合构造成组。但是，结果证明 ThreadGroup 并没有那样有用。
您最好只使用 Thread 中的等价方法。
ThreadGroup 确实提供了一个有用的功能部件（Thread 中目前还没有）：uncaughtException() 方
法。线程组中的某个线程由于抛出了未捕获的异常而退出时，会调用
ThreadGroup.uncaughtException() 方法。这就让您有机会关闭系统、将一条消息写到日志文件或
者重新启动失败的服务。
SwingUtilities
虽然 SwingUtilities 类不是Thread API 的一部分，但还是值得简单提一下。
正如前面提到的，Swing 应用程序有一个 UI 线程（有时叫称为事件线程），所有UI 活动都必须
在这个线程中发生。有时，另一个线程也许想要更新屏幕上某样东西的外观，或者触发Swing 对象
上的一个事件。
SwingUtilities.invokeLater() 方法可以让您将 Runnable 对象传送给它，并且在事件线程中执行
指定的 Runnable。它的同类 invokeAndWait() 会在事件线程中调用 Runnable，但invokeAndWait()
会阻塞，直到 Runnable 完成执行之后。
void showHelloThereDialog() throws Exception {
Runnable showModalDialog = new Runnable() {
public void run() {
JOptionPane.showMessageDialog(myMainFrame, "Hello There");
}
};
SwingUtilities.invokeLater(showModalDialog);
}
对于 AWT 应用程序，java.awt.EventQueue 还提供了 invokeLater() 和 invokeAndWait()。
 Copyright ©2011 lyt. All Rights Reserved.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Java多线程实现方式主要有三种：继承Thread类、实现Runnable接口、使用ExecutorService、Callable、Future实现有返回结果的多线程。其中前两种方式线程执行完后都没有返回值，只有最后一种是带返回值的
第三种方式如下
import java.util.concurrent.*;
import java.util.Date;
import java.util.List;
import java.util.ArrayList;

/**
* 有返回值的线程
*/
@SuppressWarnings("unchecked")
public class Test {
public static void main(String[] args) throws ExecutionException,
    InterruptedException {
   System.out.println("----程序开始运行----");
   Date date1 = new Date();

   int taskSize = 5;
   // 创建一个线程池
   ExecutorService pool = Executors.newFixedThreadPool(taskSize);
   // 创建多个有返回值的任务
   List<Future> list = new ArrayList<Future>();
   for (int i = 0; i < taskSize; i++) {
    Callable c = new MyCallable(i + " ");
    // 执行任务并获取Future对象
    Future f = pool.submit(c);
    // System.out.println(">>>" + f.get().toString());
    list.add(f);
   }
   // 关闭线程池
   pool.shutdown();

   // 获取所有并发任务的运行结果
   for (Future f : list) {
    // 从Future对象上获取任务的返回值，并输出到控制台
    System.out.println(">>>" + f.get().toString());
   }

   Date date2 = new Date();
   System.out.println("----程序结束运行----，程序运行时间【"
     + (date2.getTime() - date1.getTime()) + "毫秒】");
}
}

class MyCallable implements Callable<Object> {
private String taskNum;

MyCallable(String taskNum) {
   this.taskNum = taskNum;
}

public Object call() throws Exception {
   System.out.println(">>>" + taskNum + "任务启动");
   Date dateTmp1 = new Date();
   Thread.sleep(1000);
   Date dateTmp2 = new Date();
   long time = dateTmp2.getTime() - dateTmp1.getTime();
   System.out.println(">>>" + taskNum + "任务终止");
   return taskNum + "任务返回运行结果,当前任务时间【" + time + "毫秒】";
}
}


同步代码块嵌套容易导致死锁（互锁），不要使用

vector是线程安全的，arraylist是线程不安全的  add
stringbuffer是线程安全的，stringbuilder是线程不安全的，append stringbuilder用于系统启动时处理速度快
hashtable是线程安全的，hashmap是线程不安全的 put

有方法可以是线程不安全的集合转换成线程安全的，从而避免使用线程安全的类
Connection.synchronizedList(List)
Connection.synchronizedMap(Map)
Connection.synchronizedSet(Set)


锁的方式： syncronize(this)和syncronize(this.getClass) 是锁对象数据和锁对象类型的区别
注意：如果用成员作为锁的对象，则成员类型必须是静态的




Java多线程-线程的调度(守护线程)

守护线程与普通线程写法上基本没啥区别，调用线程对象的方法setDaemon(true)，则可以将其设置为守护线程。

守护线程使用的情况较少，但并非无用，举例来说，JVM的垃圾回收、内存管理等线程都是守护线程。还有就是在做数据库应用时候，使用的数据库连接池，连接池本身也包含着很多后台线程，监控连接个数、超时时间、状态等等。

setDaemon方法的详细说明：
public final void setDaemon(boolean on)：将该线程标记为守护线程或用户线程。当正在运行的线程都是守护线程时，Java虚拟机退出。

该方法必须在启动线程前调用。

该方法首先调用该线程的checkAccess方法，且不带任何参数。这可能抛出SecurityException（在当前线程中）。


参数： 
on - 如果为 true，则将该线程标记为守护线程。 
抛出： 
IllegalThreadStateException - 如果该线程处于活动状态。 
SecurityException - 如果当前线程无法修改该线程。 
另请参见： 
isDaemon(), checkAccess()




thread.Join把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在线程B中调用了线程A的Join()方法，直到线程A执行完毕后，才会继续执行线程B。

t.join();      //使调用线程 t 在此之前执行完毕。
t.join(1000);  //等待 t 线程，等待时间是1000毫秒




1、sleep()
使当前线程（即调用该方法的线程）暂停执行一段时间，让其他线程有机会继续执行，但它并不释放对象锁。也就是说如果有synchronized同步快，其他线程仍然不能访问共享数据。注意该方法要捕捉异常。
例如有两个线程同时执行(没有synchronized)一个线程优先级为MAX_PRIORITY，另一个为MIN_PRIORITY，如果没有Sleep()方法，只有高优先级的线程执行完毕后，低优先级的线程才能够执行；但是高优先级的线程sleep(500)后，低优先级就有机会执行了。
总之，sleep()可以使低优先级的线程得到执行的机会，当然也可以让同优先级、高优先级的线程有执行的机会。

2、join()
join()方法使调用该方法的线程在此之前执行完毕，也就是等待该方法的线程执行完毕后再往下继续执行。注意该方法也需要捕捉异常。
3、yield()
该方法与sleep()类似，只是不能由用户指定暂停多长时间，并且yield（）方法只能让同优先级的线程有执行的机会。
4、wait()和notify()、notifyAll()
这三个方法用于协调多个线程对共享数据的存取，所以必须在synchronized语句块内使用。synchronized关键字用于保护共享数据，阻止其他线程对共享数据的存取，但是这样程序的流程就很不灵活了，如何才能在当前线程还没退出synchronized数据块时让其他线程也有机会访问共享数据呢？此时就用这三个方法来灵活控制。
wait()方法使当前线程暂停执行并释放对象锁标示，让其他线程可以进入synchronized数据块，当前线程被放入对象等待池中。当调用notify()方法后，将从对象的等待池中移走一个任意的线程并放到锁标志等待池中，只有锁标志等待池中线程能够获取锁标志；如果锁标志等待池中没有线程，则notify()不起作用。
notifyAll()则从对象等待池中移走所有等待那个对象的线程并放到锁标志等待池中。
注意 这三个方法都是Java.lang.Object的方法。




二、run和start()
把需要处理的代码放到run()方法中，start()方法启动线程将自动调用run()方法，这个由java的内存机制规定的。并且run()方法必需是public访问权限，返回值类型为void。

三、关键字synchronized
该关键字用于保护共享数据，当然前提条件是要分清哪些数据是共享数据。每个对象都有一个锁标志，当一个线程访问到该对象，被Synchronized修饰的数据将被"上锁"，阻止其他线程访问。当前线程访问完这部分数据后释放锁标志，其他线程就可以访问了。


四、wait()和notify(),notifyAll()是Object类的方法，sleep()和yield()是Thread类的方法。
(1)、常用的wait方法有wait()和wait(long timeout);
void wait() 在其他线程调用此对象的 notify() 方法或者 notifyAll()方法前，导致当前线程等待。
void wait(long timeout)在其他线程调用此对象的notify() 方法 或者 notifyAll()方法，或者超过指定的时间量前，导致当前线程等待。
wait()后，线程会释放掉它所占有的“锁标志”，从而使线程所在对象中的其他shnchronized数据可被别的线程使用。

wait()h和notify()因为会对对象的“锁标志”进行操作，所以他们必需在Synchronized函数或者 synchronized block 中进行调用。如果在non-synchronized 函数或 non-synchronized block 中进行调用，虽然能编译通过，但在运行时会发生IllegalMonitorStateException的异常。。

(2)、Thread.sleep(long millis)必须带有一个时间参数。
sleep(long)使当前线程进入停滞状态，所以执行sleep()的线程在指定的时间内肯定不会被执行；
sleep(long)可使优先级低的线程得到执行的机会，当然也可以让同优先级的线程有执行的机会；
sleep(long)是不会释放锁标志的。

(3)、yield()没有参数
sleep 方法使当前运行中的线程睡眠一段时间，进入不可以运行状态，这段时间的长短是由程序设定的，yield方法使当前线程让出CPU占有权，但让出的时间是不可设定的。
yield()也不会释放锁标志。
实际上，yield()方法对应了如下操作；先检测当前是否有相同优先级的线程处于同可运行状态，如有，则把CPU的占有权交给次线程，否则继续运行原来的线程，所以yield()方法称为“退让”，它把运行机会让给了同等级的其他线程。

sleep 方法允许较低优先级的线程获得运行机会，但yield（）方法执行时，当前线程仍处在可运行状态，所以不可能让出较低优先级的线程此时获取CPU占有权。在一个运行系统中，如果较高优先级的线程没有调用sleep方法，也没有受到I/O阻塞，那么较低优先级线程只能等待所有较高优先级的线程运行结束，方可有机会运行。

yield()只是使当前线程重新回到可执行状态，所有执行yield()的线程有可能在进入到可执行状态后马上又被执行，所以yield()方法只能使同优先级的线程有执行的机会





Timer是一种线程设施，用于安排以后在后台线程中执行的任务。可安排任务执行一次，或者定期重复执行，可以看成一个定时器，可以调度TimerTask。TimerTask是一个抽象类，实现了Runnable接口，所以具备了多线程的能力。

 public static void main(String[] args) {  
        Timer timer = new Timer();    
  
        timer.schedule(new OneTask(1), 5000);// 5秒后启动任务  
          
        OneTask secondTask= new OneTask(2);  
        timer.schedule(secondTask, 1000, 3000);// 1秒后启动任务,以后每隔3秒执行一次线程  
          
        Date date = new Date();   
        timer.schedule(new OneTask(3),new Date(date.getTime()+1000));//以date为参数，指定某个时间点执行线程  
          
//      timer.cancel();  
//      secondTask.cancel();  
        System.out.println("end in main thread...");  
    }  




lock()和unlock()取代syncronize(){}












工作中，经常会涉及到线程。比如有些任务，经常会交与线程去异步执行。抑或服务端程序为每个请求单独建立一个线程处理任务。线程之外的，比如我们用的数据库连接。这些创建销毁或者打开关闭的操作，非常影响系统性能。所以，“池”的用处就凸显出来了。

1. 为什么要使用线程池

在3.6.1节介绍的实现方式中，对每个客户都分配一个新的工作线程。当工作线程与客户通信结束，这个线程就被销毁。这种实现方式有以下不足之处：

服务器创建和销毁工作的开销( 包括所花费的时间和系统资源 )很大。这一项不用解释，可以去查下"线程创建过程"。除了机器本身所做的工作，我们还要实例化，启动，这些都需要占用堆栈资源。

除了创建和销毁线程的开销之外，活动的线程也消耗系统资源。 这个应该是对堆栈资源的消耗，猜测数据库连接数设置一个合理的值，也有这个考虑。

如果线程数目固定，并且每个线程都有很长的声明周期，那么线程切换也是相对固定的。不同的操作系统有不同的切换周期，一般20ms左右。这里说的切换是在jvm以及底层操作系统的调度下，线程之间转让cpu的使用权。如果频繁创建和销毁线程，那么就将频繁的切换线程，因为一个线程销毁后，必然要让出使用权给已经就绪的线程，使该线程获得运行机会。在这种情况下，线程之间的切换就不在遵循系统的固定切换周期，切换线程的开销甚至比创建和销毁的开销还要大。

相对来说，使用线程池，会预创建一些线程，它们不断的从工作队列中取出任务，然后执行该任务。当工作线程执行完一个任务后，就会继续执行工作队列中的另一个任务。优点如下：

减少了创建和销毁的次数，每个工作线程都可以一直被重用，能执行多个任务。

可以根据系统的承载能力，方便的调整线程池中线程的数目，防止因为消耗过量的系统资源而导致系统崩溃。

2. 线程池的简单实现

下面是自己写的一个简单的线程池，也是从Java网络编程这本书上直接照着敲出来的



package thread;import java.util.LinkedList;/**
 * 线程池的实现，根据常规线程池的长度，最大长度，队列长度，我们可以增加数目限制实现
 * @author Han */public class MyThreadPool extends ThreadGroup{    //cpu 数量 ---Runtime.getRuntime().availableProcessors();    //是否关闭
    private boolean isClosed = false;    //队列
    private LinkedList<Runnable> workQueue;    //线程池id
    private static int threadPoolID;    private int threadID;    public MyThreadPool(int poolSize){        super("MyThreadPool."+threadPoolID);
        threadPoolID++;
        setDaemon(true);
        workQueue = new LinkedList<Runnable>();        for(int i = 0;i<poolSize;i++){            new WorkThread().start();
        }
    }    //这里可以换成ConcurrentLinkedQueue,就可以避免使用synchronized的效率问题
    public synchronized void execute(Runnable task){        if(isClosed){            throw new IllegalStateException("连接池已经关闭...");
        }else{
            workQueue.add(task);
            notify();
        }
    }    
    protected synchronized Runnable getTask() throws InterruptedException {        while(workQueue.size() == 0){            if(isClosed){                return null;
            }
            wait();
        }        return workQueue.removeFirst();
    }    
    public synchronized void close(){        if(!isClosed){
            isClosed = true;
            workQueue.clear();
            interrupt();
        }
    }    
    public void join(){        synchronized (this) {
            isClosed = true;
            notifyAll();
        }
        Thread[] threads = new Thread[activeCount()];        int count = enumerate(threads);        for(int i = 0;i<count;i++){            try {
                threads[i].join();
            } catch (Exception e) {
            }
        }
    }    
    class WorkThread extends Thread{        public WorkThread(){            super(MyThreadPool.this,"workThread"+(threadID++));
            System.out.println("create...");
        }
        @Override        public void run() {            while(!isInterrupted()){
                System.out.println("run..");
                Runnable task = null;                try {                    //这是一个阻塞方法
                    task = getTask();
                    
                } catch (Exception e) {
                    
                }                if(task != null){
                    task.run();
                }else{                    break;
                }
            }
        }
    }
}


该线程池主要定义了一个工作队列和一些预创建的线程。只要调用execute方法，就可以向线程提交任务。

后面线程在没有任务的时候，会阻塞在getTask(),直到有新任务进来被唤醒。

join和close都可以用来关闭线程池。不同的是，join会把队列中的任务执行完，而close则立刻清空队列，并且中断所有的工作线程。close()中的interrupt()相当于调用了ThreadGroup中包含子线程的各自的interrupt()，所以有线程处于wait或者sleep时，都会抛出InterruptException

测试类如下:



public class TestMyThreadPool {    public static void main(String[] args) throws InterruptedException {
        MyThreadPool pool = new MyThreadPool(3);        for(int i = 0;i<10;i++){
            pool.execute(new Runnable() {
                @Override                public void run() {                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                    }
                    System.out.println("working...");
                }
            });
        }
        pool.join();        //pool.close();
    }
}


3. jdk类库提供的线程池

java提供了很好的线程池实现，比我们自己的实现要更加健壮以及高效，同时功能也更加强大。

类图如下：



关于这类线程池，前辈们已经有很好的讲解。任意百度下java线程池，都有写的非常详细的例子和教程，这里就不再赘述。

java自带线程池和队列详解

4. spring注入线程池

在使用spring框架的时候，如果我们用java提供的方法来创建线程池，在多线程应用中非常不方便管理，而且不符合我们使用spring的思想。(虽然spring可以通过静态方法注入)

其实,Spring本身也提供了很好的线程池的实现。这个类叫做ThreadPoolTaskExecutor。

在spring中的配置如下：



<bean id="executorService" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor">
        <property name="corePoolSize" value="${threadpool.corePoolSize}" />
        <!-- 线程池维护线程的最少数量 -->
        <property name="keepAliveSeconds" value="${threadpool.keepAliveSeconds}" />
        <!-- 线程池维护线程所允许的空闲时间 -->
        <property name="maxPoolSize" value="${threadpool.maxPoolSize}" />
        <!-- 线程池维护线程的最大数量 -->
        <property name="queueCapacity" value="${threadpool.queueCapacity}" />
        <!-- 线程池所使用的缓冲队列 -->
    </bean>


5. 使用线程池的注意事项

死锁

任何多线程程序都有死锁的风险，最简单的情形是两个线程AB，A持有锁1，请求锁2，B持有锁2，请求锁1。（这种情况在mysql的排他锁也会出现，不会数据库会直接报错提示）。线程池中还有另一种死锁：假设线程池中的所有工作线程都在执行各自任务时被阻塞，它们在等待某个任务A的执行结果。而任务A却处于队列中，由于没有空闲线程，一直无法得以执行。这样线程池的所有资源将一直阻塞下去，死锁也就产生了。

系统资源不足

如果线程池中的线程数目非常多，这些线程会消耗包括内存和其他系统资源在内的大量资源，从而严重影响系统性能。

并发错误

线程池的工作队列依靠wait()和notify()方法来使工作线程及时取得任务，但这两个方法难以使用。如果代码错误，可能会丢失通知，导致工作线程一直保持空闲的状态，无视工作队列中需要处理的任务。因为最好使用一些比较成熟的线程池。

线程泄漏

使用线程池的一个严重风险是线程泄漏。对于工作线程数目固定的线程池，如果工作线程在执行任务时抛出RuntimeException或Error，并且这些异常或错误没有被捕获，那么这个工作线程就异常终止，使线程池永久丢失了一个线程。（这一点太有意思）

另一种情况是，工作线程在执行一个任务时被阻塞，如果等待用户的输入数据，但是用户一直不输入数据，导致这个线程一直被阻塞。这样的工作线程名存实亡，它实际上不执行任何任务了。如果线程池中的所有线程都处于这样的状态，那么线程池就无法加入新的任务了。

任务过载

当工作线程队列中有大量排队等待执行的任务时，这些任务本身可能会消耗太多的系统资源和引起资源缺乏。

综上所述，使用线程池时，要遵循以下原则：

如果任务A在执行过程中需要同步等待任务B的执行结果，那么任务A不适合加入到线程池的工作队列中。如果把像任务A一样的需要等待其他任务执行结果的加入到队列中，可能造成死锁

如果执行某个任务时可能会阻塞，并且是长时间的阻塞，则应该设定超时时间，避免工作线程永久的阻塞下去而导致线程泄漏。在服务器才程序中，当线程等待客户连接，或者等待客户发送的数据时，都可能造成阻塞，可以通过以下方式设置时间：

调用ServerSocket的setSotimeout方法，设定等待客户连接的超时时间。

对于每个与客户连接的socket，调用该socket的setSoTImeout方法，设定等待客户发送数据的超时时间。

了解任务的特点，分析任务是执行经常会阻塞io操作，还是执行一直不会阻塞的运算操作。前者时断时续的占用cpu，而后者具有更高的利用率。预计完成任务大概需要多长时间，是短时间任务还是长时间任务，然后根据任务的特点，对任务进行分类，然后把不同类型的任务加入到不同的线程池的工作队列中，这样就可以根据任务的特点，分配调整每个线程池

调整线程池的大小。线程池的最佳大小主要取决于系统的可用cpu的数目，以及工作队列中任务的特点。假如一个具有N个cpu的系统上只有一个工作队列，并且其中全部是运算性质(不会阻塞)的任务，那么当线程池拥有N或N+1个工作线程时，一般会获得最大的cpu使用率。

如果工作队列中包含会执行IO操作并经常阻塞的任务，则要让线程池的大小超过可用 cpu的数量，因为并不是所有的工作线程都一直在工作。选择一个典型的任务，然后估计在执行这个任务的工程中，等待时间与实际占用cpu进行运算的时间的比例WT/ST。对于一个具有N个cpu的系统，需要设置大约N*(1+WT/ST)个线程来保证cpu得到充分利用。

当然,cpu利用率不是调整线程池过程中唯一要考虑的事项，随着线程池工作数目的增长，还会碰到内存或者其他资源的限制，如套接字，打开的文件句柄或数据库连接数目等。要保证多线程消耗的系统资源在系统承受的范围之内。

避免任务过载。服务器应根据系统的承载能力，限制客户并发连接的数目。当客户的连接超过了限制值，服务器可以拒绝连接，并进行友好提示，或者限制队列长度.


死锁

死锁是两个或更多线程阻塞着等待其它处于死锁状态的线程所持有的锁。死锁通常发生在多个线程同时但以不同的顺序请求同一组锁的时候。

例如，如果线程 1 锁住了 A，然后尝试对 B 进行加锁，同时线程 2 已经锁住了 B，接着尝试对 A 进行加锁，这时死锁就发生了。线程 1 永远得不到 B，线程 2 也永远得不到 A，并且它们永远也不会知道发生了这样的事情。为了得到彼此的对象（A 和 B），它们将永远阻塞下去。这种情况就是一个死锁。

该情况如下：

Thread 1  locks A, waits for B
Thread 2  locks B, waits for A
这里有一个 TreeNode 类的例子，它调用了不同实例的 synchronized 方法：

public class TreeNode {
    TreeNode parent   = null;  
    List children = new ArrayList();

    public synchronized void addChild(TreeNode child){
        if(!this.children.contains(child)) {
            this.children.add(child);
            child.setParentOnly(this);
        }
    }

    public synchronized void addChildOnly(TreeNode child){
        if(!this.children.contains(child){
            this.children.add(child);
        }
    }

    public synchronized void setParent(TreeNode parent){
        this.parent = parent;
        parent.addChildOnly(this);
    }

    public synchronized void setParentOnly(TreeNode parent){
        this.parent = parent;
    }
}
如果线程 1 调用 parent.addChild(child)方法的同时有另外一个线程 2 调用 child.setParent(parent)方法，两个线程中的 parent 表示的是同一个对象，child 亦然，此时就会发生死锁。下面的伪代码说明了这个过程：

Thread 1: parent.addChild(child); //locks parent
          --> child.setParentOnly(parent);

Thread 2: child.setParent(parent); //locks child
          --> parent.addChildOnly()
首先线程 1 调用 parent.addChild(child)。因为 addChild()是同步的，所以线程 1 会对 parent 对象加锁以不让其它线程访问该对象。

然后线程 2 调用 child.setParent(parent)。因为 setParent()是同步的，所以线程 2 会对 child 对象加锁以不让其它线程访问该对象。

现在 child 和 parent 对象被两个不同的线程锁住了。接下来线程 1 尝试调用 child.setParentOnly()方法，但是由于 child 对象现在被线程 2 锁住的，所以该调用会被阻塞。线程 2 也尝试调用 parent.addChildOnly()，但是由于 parent 对象现在被线程 1 锁住，导致线程 2 也阻塞在该方法处。现在两个线程都被阻塞并等待着获取另外一个线程所持有的锁。

注意：像上文描述的，这两个线程需要同时调用 parent.addChild(child)和 child.setParent(parent)方法，并且是同一个 parent 对象和同一个 child 对象，才有可能发生死锁。上面的代码可能运行一段时间才会出现死锁。

这些线程需要同时获得锁。举个例子，如果线程 1 稍微领先线程 2，然后成功地锁住了 A 和 B 两个对象，那么线程 2 就会在尝试对 B 加锁的时候被阻塞，这样死锁就不会发生。因为线程调度通常是不可预测的，因此没有一个办法可以准确预测什么时候死锁会发生，仅仅是 可能会发生。

更复杂的死锁
死锁可能不止包含 2 个线程，这让检测死锁变得更加困难。下面是 4 个线程发生死锁的例子：

Thread 1  locks A, waits for B
Thread 2  locks B, waits for C
Thread 3  locks C, waits for D
Thread 4  locks D, waits for A
线程 1 等待线程 2，线程 2 等待线程 3，线程 3 等待线程 4，线程 4 等待线程 1。

数据库的死锁
更加复杂的死锁场景发生在数据库事务中。一个数据库事务可能由多条 SQL 更新请求组成。当在一个事务中更新一条记录，这条记录就会被锁住避免其他事务的更新请求，直到第一个事务结束。同一个事务中每一个更新请求都可能会锁住一些记录。

当多个事务同时需要对一些相同的记录做更新操作时，就很有可能发生死锁，例如：

Transaction 1, request 1, locks record 1 for update
Transaction 2, request 1, locks record 2 for update
Transaction 1, request 2, tries to lock record 2 for update.
Transaction 2, request 2, tries to lock record 1 for update.
因为锁发生在不同的请求中，并且对于一个事务来说不可能提前知道所有它需要的锁，因此很难检测和避免数据库事务中的死锁。



避免死锁

在有些情况下死锁是可以避免的。本文将展示三种用于避免死锁的技术：

加锁顺序
加锁时限
死锁检测
加锁顺序
当多个线程需要相同的一些锁，但是按照不同的顺序加锁，死锁就很容易发生。

如果能确保所有的线程都是按照相同的顺序获得锁，那么死锁就不会发生。看下面这个例子：

Thread 1:
  lock A 
  lock B

Thread 2:
   wait for A
   lock C (when A locked)

Thread 3:
   wait for A
   wait for B
   wait for C
如果一个线程（比如线程 3）需要一些锁，那么它必须按照确定的顺序获取锁。它只有获得了从顺序上排在前面的锁之后，才能获取后面的锁。

例如，线程 2 和线程 3 只有在获取了锁 A 之后才能尝试获取锁 C(译者注：获取锁 A 是获取锁 C 的必要条件)。因为线程 1 已经拥有了锁 A，所以线程 2 和 3 需要一直等到锁 A 被释放。然后在它们尝试对 B 或 C 加锁之前，必须成功地对 A 加了锁。

按照顺序加锁是一种有效的死锁预防机制。但是，这种方式需要你事先知道所有可能会用到的锁(译者注：并对这些锁做适当的排序)，但总有些时候是无法预知的。

加锁时限
另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行(译者注：加锁超时后可以先继续运行干点其它事情，再回头来重复之前加锁的逻辑)。

以下是一个例子，展示了两个线程以不同的顺序尝试获取相同的两个锁，在发生超时后回退并重试的场景：

Thread 1 locks A
Thread 2 locks B

Thread 1 attempts to lock B but is blocked
Thread 2 attempts to lock A but is blocked

Thread 1's lock attempt on B times out
Thread 1 backs up and releases A as well
Thread 1 waits randomly (e.g. 257 millis) before retrying.

Thread 2's lock attempt on A times out
Thread 2 backs up and releases B as well
Thread 2 waits randomly (e.g. 43 millis) before retrying.
在上面的例子中，线程 2 比线程 1 早 200 毫秒进行重试加锁，因此它可以先成功地获取到两个锁。这时，线程 1 尝试获取锁 A 并且处于等待状态。当线程 2 结束时，线程 1 也可以顺利的获得这两个锁（除非线程 2 或者其它线程在线程 1 成功获得两个锁之前又获得其中的一些锁）。

需要注意的是，由于存在锁的超时，所以我们不能认为这种场景就一定是出现了死锁。也可能是因为获得了锁的线程（导致其它线程超时）需要很长的时间去完成它的任务。

此外，如果有非常多的线程同一时间去竞争同一批资源，就算有超时和回退机制，还是可能会导致这些线程重复地尝试但却始终得不到锁。如果只有两个线程，并且重试的超时时间设定为 0 到 500 毫秒之间，这种现象可能不会发生，但是如果是 10 个或 20 个线程情况就不同了。因为这些线程等待相等的重试时间的概率就高的多（或者非常接近以至于会出现问题）。

(译者注：超时和重试机制是为了避免在同一时间出现的竞争，但是当线程很多时，其中两个或多个线程的超时时间一样或者接近的可能性就会很大，因此就算出现竞争而导致超时后，由于超时时间一样，它们又会同时开始重试，导致新一轮的竞争，带来了新的问题。)

这种机制存在一个问题，在 Java 中不能对 synchronized 同步块设置超时时间。你需要创建一个自定义锁，或使用 Java5 中 java.util.concurrent 包下的工具。写一个自定义锁类不复杂，但超出了本文的内容。后续的 Java 并发系列会涵盖自定义锁的内容。

死锁检测
死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。

每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph 等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。

当一个线程请求锁失败时，这个线程可以遍历锁的关系图看看是否有死锁发生。例如，线程 A 请求锁 7，但是锁 7 这个时候被线程 B 持有，这时线程 A 就可以检查一下线程 B 是否已经请求了线程 A 当前所持有的锁。如果线程 B 确实有这样的请求，那么就是发生了死锁（线程 A 拥有锁 1，请求锁 7；线程 B 拥有锁 7，请求锁 1）。

当然，死锁一般要比两个线程互相持有对方的锁这种情况要复杂的多。线程 A 等待线程 B，线程 B 等待线程 C，线程 C 等待线程 D，线程 D 又在等待线程 A。线程 A 为了检测死锁，它需要递进地检测所有被 B 请求的锁。从线程 B 所请求的锁开始，线程 A 找到了线程 C，然后又找到了线程 D，发现线程 D 请求的锁被线程 A 自己持有着。这是它就知道发生了死锁。

下面是一幅关于四个线程（A,B,C 和 D）之间锁占有和请求的关系图。像这样的数据结构就可以被用来检测死锁。



那么当检测出死锁时，这些线程该做些什么呢？

一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试。这个和简单的加锁超时类似，不一样的是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞争同一批锁，它们还是会重复地死锁（编者注：原因同超时类似，不能从根本上减轻竞争）。

一个更好的方案是给这些线程设置优先级，让一个（或几个）线程回退，剩下的线程就像没发生死锁一样继续保持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这个问题，可以在死锁发生的时候设置随机的优先级。









并发性与多线程介绍

在过去单 CPU 时代，单任务在一个时间点只能执行单一程序。之后发展到多任务阶段，计算机能在同一时间点并行执行多任务或多进程。虽然并不是真正意义上的“同一时间点”，而是多个任务或进程共享一个 CPU，并交由操作系统来完成多任务间对 CPU 的运行切换，以使得每个任务都有机会获得一定的时间片运行。

随着多任务对软件开发者带来的新挑战，程序不在能假设独占所有的CPU时间、所有的内存和其他计算机资源。一个好的程序榜样是在其不再使用这些资源时对其进行释放，以使得其他程序能有机会使用这些资源。

再后来发展到多线程技术，使得在一个程序内部能拥有多个线程并行执行。一个线程的执行可以被认为是一个 CPU 在执行该程序。当一个程序运行在多线程下，就好像有多个 CPU 在同时执行该程序。

多线程比多任务更加有挑战。多线程是在同一个程序内部并行执行，因此会对相同的内存空间进行并发读写操作。这可能是在单线程程序中从来不会遇到的问题。其中的一些错误也未必会在单 CPU 机器上出现，因为两个线程从来不会得到真正的并行执行。然而，更现代的计算机伴随着多核CPU的出现，也就意味着不同的线程能被不同的 CPU 核得到真正意义的并行执行。

如果一个线程在读一个内存时，另一个线程正向该内存进行写操作，那进行读操作的那个线程将获得什么结果呢？是写操作之前旧的值？还是写操作成功之后的新值？或是一半新一半旧的值？或者，如果是两个线程同时写同一个内存，在操作完成后将会是什么结果呢？是第一个线程写入的值？还是第二个线程写入的值？还是两个线程写入的一个混合值？因此如没有合适的预防措施，任何结果都是可能的。而且这种行为的发生甚至不能预测，所以结果也是不确定性的。

Java 的多线程和并发性
Java 是最先支持多线程的开发的语言之一，Java 从一开始就支持了多线程能力，因此 Java 开发者能常遇到上面描述的问题场景。这也是我想为 Java 并发技术而写这篇系列的原因。作为对自己的笔记，和对其他 Java 开发的追随者都可获益的。

该系列主要关注 Java 多线程，但有些在多线程中出现的问题会和多任务以及分布式系统中出现的存在类似，因此该系列会将多任务和分布式系统方面作为参考，所以叫法上称为“并发性”，而不是“多线程”。



多线程的优点

尽管面临很多挑战，多线程有一些优点使得它一直被使用。这些优点是：

资源利用率更好
程序设计在某些情况下更简单
程序响应更快
资源利用率更好
想象一下，一个应用程序需要从本地文件系统中读取和处理文件的情景。比方说，从磁盘读取一个文件需要 5 秒，处理一个文件需要 2 秒。处理两个文件则需要：

5秒读取文件A
2秒处理文件A
5秒读取文件B
2秒处理文件B
---------------------
总共需要14秒
从磁盘中读取文件的时候，大部分的 CPU 时间用于等待磁盘去读取数据。在这段时间里，CPU 非常的空闲。它可以做一些别的事情。通过改变操作的顺序，就能够更好的使用 CPU 资源。看下面的顺序：

5秒读取文件A
5秒读取文件B + 2秒处理文件A
2秒处理文件B
---------------------
总共需要12秒
CPU 等待第一个文件被读取完。然后开始读取第二个文件。当第二文件在被读取的时候，CPU 会去处理第一个文件。记住，在等待磁盘读取文件的时候，CPU大 部分时间是空闲的。

总的说来，CPU 能够在等待 IO 的时候做一些其他的事情。这个不一定就是磁盘 IO。它也可以是网络的 IO，或者用户输入。通常情况下，网络和磁盘的 IO 比 CPU 和内存的 IO 慢的多。

程序设计更简单
在单线程应用程序中，如果你想编写程序手动处理上面所提到的读取和处理的顺序，你必须记录每个文件读取和处理的状态。相反，你可以启动两个线程，每个线程处理一个文件的读取和操作。线程会在等待磁盘读取文件的过程中被阻塞。在等待的时候，其他的线程能够使用 CPU 去处理已经读取完的文件。其结果就是，磁盘总是在繁忙地读取不同的文件到内存中。这会带来磁盘和 CPU 利用率的提升。而且每个线程只需要记录一个文件，因此这种方式也很容易编程实现。

程序响应更快
将一个单线程应用程序变成多线程应用程序的另一个常见的目的是实现一个响应更快的应用程序。设想一个服务器应用，它在某一个端口监听进来的请求。当一个请求到来时，它去处理这个请求，然后再返回去监听。

服务器的流程如下所述：

while(server is active){
    listen for request
    process request
}
如果一个请求需要占用大量的时间来处理，在这段时间内新的客户端就无法发送请求给服务端。只有服务器在监听的时候，请求才能被接收。另一种设计是，监听线程把请求传递给工作者线程(worker thread)，然后立刻返回去监听。而工作者线程则能够处理这个请求并发送一个回复给客户端。这种设计如下所述：

while(server is active){
    listen for request
    hand request to worker thread
}
这种方式，服务端线程迅速地返回去监听。因此，更多的客户端能够发送请求给服务端。这个服务也变得响应更快。

桌面应用也是同样如此。如果你点击一个按钮开始运行一个耗时的任务，这个线程既要执行任务又要更新窗口和按钮，那么在任务执行的过程中，这个应用程序看起来好像没有反应一样。相反，任务可以传递给工作者线程（word thread)。当工作者线程在繁忙地处理任务的时候，窗口线程可以自由地响应其他用户的请求。当工作者线程完成任务的时候，它发送信号给窗口线程。窗口线程便可以更新应用程序窗口，并显示任务的结果。对用户而言，这种具有工作者线程设计的程序显得响应速度更快。




多线程的代价

从一个单线程的应用到一个多线程的应用并不仅仅带来好处，它也会有一些代价。不要仅仅为了使用多线程而使用多线程。而应该明确在使用多线程时能多来的好处比所付出的代价大的时候，才使用多线程。如果存在疑问，应该尝试测量一下应用程序的性能和响应能力，而不只是猜测。

设计更复杂
虽然有一些多线程应用程序比单线程的应用程序要简单，但其他的一般都更复杂。在多线程访问共享数据的时候，这部分代码需要特别的注意。线程之间的交互往往非常复杂。不正确的线程同步产生的错误非常难以被发现，并且重现以修复。

上下文切换的开销
当 CPU 从执行一个线程切换到执行另外一个线程的时候，它需要先存储当前线程的本地的数据，程序指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行。这种切换称为“上下文切换”(“context switch”)。CPU 会在一个上下文中执行一个线程，然后切换到另外一个上下文中执行另外一个线程。

上下文切换并不廉价。如果没有必要，应该减少上下文切换的发生。

你可以通过维基百科阅读更多的关于上下文切换相关的内容：

http://en.wikipedia.org/wiki/Context_switch

增加资源消耗
线程在运行的时候需要从计算机里面得到一些资源。除了CPU，线程还需要一些内存来维持它本地的堆栈。它也需要占用操作系统中一些资源来管理线程。我们可以尝试编写一个程序，让它创建 100 个线程，这些线程什么事情都不做，只是在等待，然后看看这个程序在运行的时候占用了多少内存。




竞态条件与临界区

在同一程序中运行多个线程本身不会导致问题，问题在于多个线程访问了相同的资源。如，同一内存区（变量，数组，或对象）、系统（数据库，web services 等）或文件。实际上，这些问题只有在一或多个线程向这些资源做了写操作时才有可能发生，只要资源没有发生变化,多个线程读取相同的资源就是安全的。

多线程同时执行下面的代码可能会出错：

public class Counter {
    protected long count = 0;
    public void add(long value){
        this.count = this.count + value;   
    }
}
想象下线程 A 和 B 同时执行同一个 Counter 对象的 add()方法，我们无法知道操作系统何时会在两个线程之间切换。JVM 并不是将这段代码视为单条指令来执行的，而是按照下面的顺序：

从内存获取 this.count 的值放到寄存器
将寄存器中的值增加 value
将寄存器中的值写回内存
观察线程 A 和 B 交错执行会发生什么：

this.count = 0;
A: 读取 this.count 到一个寄存器 (0)
B: 读取 this.count 到一个寄存器 (0)
B: 将寄存器的值加 2
B: 回写寄存器值(2)到内存. this.count 现在等于 2
A: 将寄存器的值加 3
A: 回写寄存器值(3)到内存. this.count 现在等于 3
两个线程分别加了 2 和 3 到 count 变量上，两个线程执行结束后 count 变量的值应该等于 5。然而由于两个线程是交叉执行的，两个线程从内存中读出的初始值都是 0。然后各自加了 2 和 3，并分别写回内存。最终的值并不是期望的 5，而是最后写回内存的那个线程的值，上面例子中最后写回内存的是线程 A，但实际中也可能是线程 B。如果没有采用合适的同步机制，线程间的交叉执行情况就无法预料。

竞态条件 & 临界区
当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。导致竞态条件发生的代码区称作临界区。上例中 add()方法就是一个临界区,它会产生竞态条件。在临界区中使用适当的同步就可以避免竞态条件。






如何创建并运行 java 线程

Java 线程类也是一个 object 类，它的实例都继承自 java.lang.Thread 或其子类。 可以用如下方式用 java 中创建一个线程：

Tread thread = new Thread();
执行该线程可以调用该线程的 start()方法:

thread.start();
在上面的例子中，我们并没有为线程编写运行代码，因此调用该方法后线程就终止了。

编写线程运行时执行的代码有两种方式：一种是创建 Thread 子类的一个实例并重写 run 方法，第二种是创建类的时候实现 Runnable 接口。接下来我们会具体讲解这两种方法：

创建 Thread 的子类
创建 Thread 子类的一个实例并重写 run 方法，run 方法会在调用 start()方法之后被执行。例子如下：

public class MyThread extends Thread {
   public void run(){
     System.out.println("MyThread running");
   }
}
可以用如下方式创建并运行上述 Thread 子类

MyThread myThread = new MyThread();
myTread.start();
一旦线程启动后 start 方法就会立即返回，而不会等待到 run 方法执行完毕才返回。就好像 run 方法是在另外一个 cpu 上执行一样。当 run 方法执行后，将会打印出字符串 MyThread running。

你也可以如下创建一个 Thread 的匿名子类：

Thread thread = new Thread(){
   public void run(){
     System.out.println("Thread Running");
   }
};
thread.start();
当新的线程的 run 方法执行以后，计算机将会打印出字符串”Thread Running”。

实现 Runnable 接口
第二种编写线程执行代码的方式是新建一个实现了 java.lang.Runnable 接口的类的实例，实例中的方法可以被线程调用。下面给出例子：

public class MyRunnable implements Runnable {
   public void run(){
    System.out.println("MyRunnable running");
   }
}
为了使线程能够执行 run()方法，需要在 Thread 类的构造函数中传入 MyRunnable 的实例对象。示例如下：

Thread thread = new Thread(new MyRunnable());
thread.start();
当线程运行时，它将会调用实现了 Runnable 接口的 run 方法。上例中将会打印出”MyRunnable running”。

同样，也可以创建一个实现了 Runnable 接口的匿名类，如下所示：

Runnable myRunnable = new Runnable(){
   public void run(){
     System.out.println("Runnable running");
   }
}
Thread thread = new Thread(myRunnable);
thread.start();
创建子类还是实现 Runnable 接口？
对于这两种方式哪种好并没有一个确定的答案，它们都能满足要求。就我个人意见，我更倾向于实现 Runnable 接口这种方法。因为线程池可以有效的管理实现了 Runnable 接口的线程，如果线程池满了，新的线程就会排队等候执行，直到线程池空闲出来为止。而如果线程是通过实现 Thread 子类实现的，这将会复杂一些。

有时我们要同时融合实现 Runnable 接口和 Thread 子类两种方式。例如，实现了 Thread 子类的实例可以执行多个实现了 Runnable 接口的线程。一个典型的应用就是线程池。

常见错误：调用 run()方法而非 start()方法
创建并运行一个线程所犯的常见错误是调用线程的 run()方法而非 start()方法，如下所示：

Thread newThread = new Thread(MyRunnable());
newThread.run();  //should be start();
起初你并不会感觉到有什么不妥，因为 run()方法的确如你所愿的被调用了。但是，事实上,run()方法并非是由刚创建的新线程所执行的，而是被创建新线程的当前线程所执行了。也就是被执行上面两行代码的线程所执行的。想要让创建的新线程执行 run()方法，必须调用新线程的 start 方法。

线程名
当创建一个线程的时候，可以给线程起一个名字。它有助于我们区分不同的线程。例如：如果有多个线程写入 System.out，我们就能够通过线程名容易的找出是哪个线程正在输出。例子如下：

MyRunnable runnable = new MyRunnable();
Thread thread = new Thread(runnable, "New Thread");
thread.start();
System.out.println(thread.getName());
需要注意的是，因为 MyRunnable 并非 Thread 的子类，所以 MyRunnable 类并没有 getName()方法。可以通过以下方式得到当前线程的引用：

Thread.currentThread();
因此，通过如下代码可以得到当前线程的名字：

String threadName = Thread.currentThread().getName();
线程代码举例：
这里是一个小小的例子。首先输出执行main()方法线程名字。这个线程 JVM 分配的。然后开启 10 个线程，命名为 1~10。每个线程输出自己的名字后就退出。

public class ThreadExample {
  public static void main(String[] args){
     System.out.println(Thread.currentThread().getName());
      for(int i=0; i<10; i++){
         new Thread("" + i){
            public void run(){
             System.out.println("Thread: " + getName() + "running");
            }
         }.start();
      }
  }
}
需要注意的是，尽管启动线程的顺序是有序的，但是执行的顺序并非是有序的。也就是说，1 号线程并不一定是第一个将自己名字输出到控制台的线程。这是因为线程是并行执行而非顺序的。Jvm 和操作系统一起决定了线程的执行顺序，他和线程的启动顺序并非一定是一致的。








多线程的实现方法

Java 中实现多线程有两种方法：继承 Thread 类、实现 Runnable 接口，在程序开发中只要是多线程，肯定永远以实现 Runnable 接口为主，因为实现 Runnable 接口相比继承 Thread 类有如下优势：

可以避免由于 Java 的单继承特性而带来的局限；
增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的；
适合多个相同程序代码的线程区处理同一资源的情况。
下面以典型的买票程序（基本都是以这个为例子）为例，来说明二者的区别。

首先通过继承 Thread 类实现，代码如下：

class MyThread extends Thread{  
    private int ticket = 5;  
    public void run(){  
        for (int i=0;i<10;i++)  
        {  
            if(ticket > 0){  
                System.out.println("ticket = " + ticket--);  
            }  
        }  
    }  
}  

public class ThreadDemo{  
    public static void main(String[] args){  
        new MyThread().start();  
        new MyThread().start();  
        new MyThread().start();  
    }  
} 
执行结果如下：



从结果中可以看出，每个线程单独卖了 5 张票，即独立地完成了买票的任务，但实际应用中，比如火车站售票，需要多个线程去共同完成任务，在本例中，即多个线程共同买 5 张票。

下面是通过实现 Runnable 接口实现的多线程程序，代码如下：

class MyThread implements Runnable{  
    private int ticket = 5;  
    public void run(){  
        for (int i=0;i<10;i++)  
        {  
            if(ticket > 0){  
                System.out.println("ticket = " + ticket--);  
            }  
        }  
    }  
}  

public class RunnableDemo{  
    public static void main(String[] args){  
        MyThread my = new MyThread();  
        new Thread(my).start();  
        new Thread(my).start();  
        new Thread(my).start();  
    }  
}
执行结果如下：



从结果中可以看出，三个线程一共卖了 5 张票，即它们共同完成了买票的任务，实现了资源的共享。

针对以上代码补充三点：

在第二种方法（Runnable）中，ticket 输出的顺序并不是 54321，这是因为线程执行的时机难以预测，ticket--并不是原子操作。
在第一种方法中，我们 new 了 3 个 Thread 对象，即三个线程分别执行三个对象中的代码，因此便是三个线程去独立地完成卖票的任务；而在第二种方法中，我们同样也 new 了 3 个 Thread 对象，但只有一个 Runnable 对象，3 个 Thread 对象共享这个 Runnable 对象中的代码，因此，便会出现 3 个线程共同完成卖票任务的结果。如果我们 new 出 3 个 Runnable 对象，作为参数分别传入 3 个 Thread 对象中，那么 3 个线程便会独立执行各自 Runnable 对象中的代码，即 3 个线程各自卖 5 张票。
在第二种方法中，由于 3 个 Thread 对象共同执行一个 Runnable 对象中的代码，因此可能会造成线程的不安全，比如可能 ticket 会输出 -1（如果我们 System.out....语句前加上线程休眠操作，该情况将很有可能出现），这种情况的出现是由于，一个线程在判断 ticket 为 1>0 后，还没有来得及减 1，另一个线程已经将 ticket 减 1，变为了 0，那么接下来之前的线程再将 ticket 减 1，便得到了 -1。这就需要加入同步操作（即互斥锁），确保同一时刻只有一个线程在执行每次 for 循环中的操作。而在第一种方法中，并不需要加入同步操作，因为每个线程执行自己 Thread 对象中的代码，不存在多个线程共同执行同一个方法的情况。



线程中断

使用 interrupt()中断线程
当一个线程运行时，另一个线程可以调用对应的 Thread 对象的 interrupt()方法来中断它，该方法只是在目标线程中设置一个标志，表示它已经被中断，并立即返回。这里需要注意的是，如果只是单纯的调用 interrupt()方法，线程并没有实际被中断，会继续往下执行。

下面一段代码演示了休眠线程的中断:

public class SleepInterrupt extends Object implements Runnable{  
    public void run(){  
        try{  
            System.out.println("in run() - about to sleep for 20 seconds");  
            Thread.sleep(20000);  
            System.out.println("in run() - woke up");  
        }catch(InterruptedException e){  
            System.out.println("in run() - interrupted while sleeping");  
            //处理完中断异常后，返回到run（）方法人口，  
            //如果没有return，线程不会实际被中断，它会继续打印下面的信息  
            return;    
        }  
        System.out.println("in run() - leaving normally");  
    }  

    public static void main(String[] args) {  
        SleepInterrupt si = new SleepInterrupt();  
        Thread t = new Thread(si);  
        t.start();  
        //主线程休眠2秒，从而确保刚才启动的线程有机会执行一段时间  
        try {  
            Thread.sleep(2000);   
        }catch(InterruptedException e){  
            e.printStackTrace();  
        }  
        System.out.println("in main() - interrupting other thread");  
        //中断线程t  
        t.interrupt();  
        System.out.println("in main() - leaving");  
    }  
} 
运行结果如下：



主线程启动新线程后，自身休眠 2 秒钟，允许新线程获得运行时间。新线程打印信息about to sleep for 20 seconds后，继而休眠 20 秒钟，大约 2 秒钟后，main 线程通知新线程中断，那么新线程的 20 秒的休眠将被打断，从而抛出 InterruptException 异常，执行跳转到 catch 块，打印出interrupted while sleeping信息，并立即从 run（）方法返回，然后消亡，而不会打印出 catch 块后面的leaving normally信息。

请注意：由于不确定的线程规划，上图运行结果的后两行可能顺序相反，这取决于主线程和新线程哪个先消亡。但前两行信息的顺序必定如上图所示。

另外，如果将 catch 块中的 return 语句注释掉，则线程在抛出异常后，会继续往下执行，而不会被中断，从而会打印出leaving normally信息。

待决中断
在上面的例子中，sleep()方法的实现检查到休眠线程被中断，它会相当友好地终止线程，并抛出 InterruptedException 异常。另外一种情况，如果线程在调用 sleep()方法前被中断，那么该中断称为待决中断，它会在刚调用 sleep()方法时，立即抛出 InterruptedException 异常。

下面的代码演示了待决中断:

public class PendingInterrupt extends Object {  
    public static void main(String[] args){  
        //如果输入了参数，则在mian线程中中断当前线程（亦即main线程）  
        if( args.length > 0 ){  
            Thread.currentThread().interrupt();  
        }   
        //获取当前时间  
        long startTime = System.currentTimeMillis();  
        try{  
            Thread.sleep(2000);  
            System.out.println("was NOT interrupted");  
        }catch(InterruptedException x){  
            System.out.println("was interrupted");  
        }  
        //计算中间代码执行的时间  
        System.out.println("elapsedTime=" + ( System.currentTimeMillis() - startTime));  
    }  
}
如果 PendingInterrupt 不带任何命令行参数，那么线程不会被中断，最终输出的时间差距应该在 2000 附近（具体时间由系统决定，不精确），如果 PendingInterrupt 带有命令行参数，则调用中断当前线程的代码，但 main 线程仍然运行，最终输出的时间差距应该远小于 2000，因为线程尚未休眠，便被中断，因此，一旦调用 sleep()方法，会立即打印出 catch 块中的信息。

执行结果如下:



这种模式下，main 线程中断它自身。除了将中断标志（它是 Thread 的内部标志）设置为 true 外，没有其他任何影响。线程被中断了，但 main 线程仍然运行，main 线程继续监视实时时钟，并进入 try 块，一旦调用 sleep（）方法，它就会注意到待决中断的存在，并抛出 InterruptException。于是执行跳转到 catch 块，并打印出线程被中断的信息。最后，计算并打印出时间差。

使用 isInterrupted()方法判断中断状态
可以在 Thread 对象上调用 isInterrupted()方法来检查任何线程的中断状态。这里需要注意：线程一旦被中断，isInterrupted()方法便会返回 true，而一旦 sleep()方法抛出异常，它将清空中断标志，此时isInterrupted()方法将返回 false。

下面的代码演示了 isInterrupted()方法的使用：

public class InterruptCheck extends Object{  
    public static void main(String[] args){  
        Thread t = Thread.currentThread();  
        System.out.println("Point A: t.isInterrupted()=" + t.isInterrupted());  
        //待决中断，中断自身  
        t.interrupt();  
        System.out.println("Point B: t.isInterrupted()=" + t.isInterrupted());  
        System.out.println("Point C: t.isInterrupted()=" + t.isInterrupted());  

        try{  
            Thread.sleep(2000);  
            System.out.println("was NOT interrupted");  
        }catch( InterruptedException x){  
            System.out.println("was interrupted");  
        }  
        //抛出异常后，会清除中断标志，这里会返回false  
        System.out.println("Point D: t.isInterrupted()=" + t.isInterrupted());  
    }  
}  
运行结果如下：



使用 Thread.interrupted()方法判断中断状态
可以使用 Thread.interrupted()方法来检查当前线程的中断状态（并隐式重置为 false）。又由于它是静态方法，因此不能在特定的线程上使用，而只能报告调用它的线程的中断状态，如果线程被中断，而且中断状态尚不清楚，那么，这个方法返回 true。与 isInterrupted()不同，它将自动重置中断状态为 false，第二次调用 Thread.interrupted()方法，总是返回 false，除非中断了线程。

如下代码演示了 Thread.interrupted()方法的使用：

public class InterruptReset extends Object {  
    public static void main(String[] args) {  
        System.out.println(  
            "Point X: Thread.interrupted()=" + Thread.interrupted());  
        Thread.currentThread().interrupt();  
        System.out.println(  
            "Point Y: Thread.interrupted()=" + Thread.interrupted());  
        System.out.println(  
            "Point Z: Thread.interrupted()=" + Thread.interrupted());  
    }  
}
运行结果如下：



从结果中可以看出，当前线程中断自身后，在 Y 点，中断状态为 true，并由 Thread.interrupted()自动重置为 false，那么下次调用该方法得到的结果便是 false。

补充
这里补充下 yield 和 join 方法的使用。

join 方法用线程对象调用，如果在一个线程 A 中调用另一个线程 B 的 join 方法，线程 A 将会等待线程 B 执行完毕后再执行。
yield 可以直接用 Thread 类调用，yield 让出 CPU 执行权给同等级的线程，如果没有相同级别的线程在等待 CPU 的执行权，则该线程继续执行。



线程挂起、恢复与终止

挂起和恢复线程
Thread 的 API 中包含两个被淘汰的方法，它们用于临时挂起和重启某个线程，这些方法已经被淘汰，因为它们是不安全的，不稳定的。如果在不合适的时候挂起线程（比如，锁定共享资源时），此时便可能会发生死锁条件——其他线程在等待该线程释放锁，但该线程却被挂起了，便会发生死锁。另外，在长时间计算期间挂起线程也可能导致问题。

下面的代码演示了通过休眠来延缓运行，模拟长时间运行的情况，使线程更可能在不适当的时候被挂起：

public class DeprecatedSuspendResume extends Object implements Runnable{  

    //volatile关键字，表示该变量可能在被一个线程使用的同时，被另一个线程修改  
    private volatile int firstVal;  
    private volatile int secondVal;  

    //判断二者是否相等  
    public boolean areValuesEqual(){  
        return ( firstVal == secondVal);  
    }  

    public void run() {  
        try{  
            firstVal = 0;  
            secondVal = 0;  
            workMethod();  
        }catch(InterruptedException x){  
            System.out.println("interrupted while in workMethod()");  
        }  
    }  

    private void workMethod() throws InterruptedException {  
        int val = 1;  
        while (true){  
            stepOne(val);  
            stepTwo(val);  
            val++;  
            Thread.sleep(200);  //再次循环钱休眠200毫秒  
        }  
    }  

    //赋值后，休眠300毫秒，从而使线程有机会在stepOne操作和stepTwo操作之间被挂起  
    private void stepOne(int newVal) throws InterruptedException{  
        firstVal = newVal;  
        Thread.sleep(300);  //模拟长时间运行的情况  
    }  

    private void stepTwo(int newVal){  
        secondVal = newVal;  
    }  

    public static void main(String[] args){  
        DeprecatedSuspendResume dsr = new DeprecatedSuspendResume();  
        Thread t = new Thread(dsr);  
        t.start();  

        //休眠1秒，让其他线程有机会获得执行  
        try {  
            Thread.sleep(1000);}   
        catch(InterruptedException x){}  
        for (int i = 0; i < 10; i++){  
            //挂起线程  
            t.suspend();  
            System.out.println("dsr.areValuesEqual()=" + dsr.areValuesEqual());  
            //恢复线程  
            t.resume();  
            try{   
                //线程随机休眠0~2秒  
                Thread.sleep((long)(Math.random()*2000.0));  
            }catch(InterruptedException x){  
                //略  
            }  
        }  
        System.exit(0); //中断应用程序  
    }  
} 
运行结果如下：



从 areValuesEqual()返回的值有时为 true，有时为 false。以上代码中，在设置 firstVal 之后，但在设置 secondVal 之前，挂起新线程会产生麻烦，此时输出的结果会为 false（情况 1），这段时间不适宜挂起线程，但因为线程不能控制何时调用它的 suspend 方法，所以这种情况是不可避免的。

当然，即使线程不被挂起（注释掉挂起和恢复线程的两行代码），如果在 main 线程中执行 asr.areValuesEqual()进行比较时，恰逢 stepOne 操作执行完，而 stepTwo 操作还没执行，那么得到的结果同样可能是 false（情况 2）。

下面我们给出不用上述两个方法来实现线程挂起和恢复的策略——设置标志位。通过该方法实现线程的挂起和恢复有一个很好的地方，就是可以在线程的指定位置实现线程的挂起和恢复，而不用担心其不确定性。

对于上述代码的改进代码如下：

public class AlternateSuspendResume extends Object implements Runnable {  

    private volatile int firstVal;  
    private volatile int secondVal;  
    //增加标志位，用来实现线程的挂起和恢复  
    private volatile boolean suspended;  

    public boolean areValuesEqual() {  
        return ( firstVal == secondVal );  
    }  

    public void run() {  
        try {  
            suspended = false;  
            firstVal = 0;  
            secondVal = 0;  
            workMethod();  
        } catch ( InterruptedException x ) {  
            System.out.println("interrupted while in workMethod()");  
        }  
    }  

    private void workMethod() throws InterruptedException {  
        int val = 1;  

        while ( true ) {  
            //仅当贤臣挂起时，才运行这行代码  
            waitWhileSuspended();   

            stepOne(val);  
            stepTwo(val);  
            val++;  

            //仅当线程挂起时，才运行这行代码  
            waitWhileSuspended();   

            Thread.sleep(200);    
        }  
    }  

    private void stepOne(int newVal)   
                    throws InterruptedException {  

        firstVal = newVal;  
        Thread.sleep(300);    
    }  

    private void stepTwo(int newVal) {  
        secondVal = newVal;  
    }  

    public void suspendRequest() {  
        suspended = true;  
    }  

    public void resumeRequest() {  
        suspended = false;  
    }  

    private void waitWhileSuspended()   
                throws InterruptedException {  

        //这是一个“繁忙等待”技术的示例。  
        //它是非等待条件改变的最佳途径，因为它会不断请求处理器周期地执行检查，   
        //更佳的技术是：使用Java的内置“通知-等待”机制  
        while ( suspended ) {  
            Thread.sleep(200);  
        }  
    }  

    public static void main(String[] args) {  
        AlternateSuspendResume asr =   
                new AlternateSuspendResume();  

        Thread t = new Thread(asr);  
        t.start();  

        //休眠1秒，让其他线程有机会获得执行  
        try { Thread.sleep(1000); }   
        catch ( InterruptedException x ) { }  

        for ( int i = 0; i < 10; i++ ) {  
            asr.suspendRequest();  

            //让线程有机会注意到挂起请求  
            //注意：这里休眠时间一定要大于  
            //stepOne操作对firstVal赋值后的休眠时间，即300ms，  
            //目的是为了防止在执行asr.areValuesEqual（）进行比较时,  
            //恰逢stepOne操作执行完，而stepTwo操作还没执行  
            try { Thread.sleep(350); }   
            catch ( InterruptedException x ) { }  

            System.out.println("dsr.areValuesEqual()=" +   
                    asr.areValuesEqual());  

            asr.resumeRequest();  

            try {   
                //线程随机休眠0~2秒  
                Thread.sleep(  
                        ( long ) (Math.random() * 2000.0) );  
            } catch ( InterruptedException x ) {  
                //略  
            }  
        }  

        System.exit(0); //退出应用程序  
    }  
} 
运行结果如下：



由结果可以看出，输出的所有结果均为 true。首先，针对情况 1（线程挂起的位置不确定），这里确定了线程挂起的位置，不会出现线程在 stepOne 操作和 stepTwo 操作之间挂起的情况；针对情况 2（main 线程中执行asr.areValuesEqual()进行比较时，恰逢 stepOne 操作执行完，而 stepTwo 操作还没执行），在发出挂起请求后，还没有执行 asr.areValuesEqual()操作前，让 main 线程休眠 450ms（>300ms），如果挂起请求发出时，新线程正执行到或即将执行到 stepOne 操作（如果在其前面的话，就会响应挂起请求，从而挂起线程），那么在 stepTwo 操作执行前，main 线程的休眠还没结束，从而 main 线程休眠结束后执行 asr.areValuesEqualv操作进行比较时，stepTwo 操作已经执行完，因此也不会出现输出结果为 false 的情况。

可以将 ars.suspendRequest()代码后的 sleep 代码去掉，或将休眠时间改为 200（明显小于 300 即可）后，查看执行结果，会发现结果中依然会有出现 false 的情况。如下图所示：



总结：线程的挂起和恢复实现的正确方法是：通过设置标志位，让线程在安全的位置挂起。

终止线程
当调用 Thread 的 start()方法，执行完 run()方法后，或在 run()方法中 return，线程便会自然消亡。另外 Thread API 中包含了一个 stop()方法，可以突然终止线程。但它在 JDK1.2 后便被淘汰了，因为它可能导致数据对象的崩溃。一个问题是，当线程终止时，很少有机会执行清理工作；另一个问题是，当在某个线程上调用 stop()方法时，线程释放它当前持有的所有锁，持有这些锁必定有某种合适的理由——也许是阻止其他线程访问尚未处于一致性状态的数据，突然释放锁可能使某些对象中的数据处于不一致状态，而且不会出现数据可能崩溃的任何警告。

终止线程的替代方法：同样是使用标志位，通过控制标志位来终止线程。




守护线程与线程阻塞

守护线程
Java 中有两类线程：User Thread(用户线程)、Daemon Thread(守护线程)

用户线程即运行在前台的线程，而守护线程是运行在后台的线程。 守护线程作用是为其他前台线程的运行提供便利服务，而且仅在普通、非守护线程仍然运行时才需要，比如垃圾回收线程就是一个守护线程。当 VM 检测仅剩一个守护线程，而用户线程都已经退出运行时，VM就会退出，因为没有如果没有了被守护这，也就没有继续运行程序的必要了。如果有非守护线程仍然存活，VM 就不会退出。

守护线程并非只有虚拟机内部提供，用户在编写程序时也可以自己设置守护线程。用户可以用 Thread 的 setDaemon（true）方法设置当前线程为守护线程。

虽然守护线程可能非常有用，但必须小心确保其他所有非守护线程消亡时，不会由于它的终止而产生任何危害。因为你不可能知道在所有的用户线程退出运行前，守护线程是否已经完成了预期的服务任务。一旦所有的用户线程退出了，虚拟机也就退出运行了。 因此，不要在守护线程中执行业务逻辑操作（比如对数据的读写等）。

另外有几点需要注意：

setDaemon(true)必须在调用线程的 start()方法之前设置，否则会跑出 IllegalThreadStateException 异常。
在守护线程中产生的新线程也是守护线程。
不要认为所有的应用都可以分配给守护线程来进行服务，比如读写操作或者计算逻辑。
线程阻塞
线程可以阻塞于四种状态：

当线程执行 Thread.sleep()时，它一直阻塞到指定的毫秒时间之后，或者阻塞被另一个线程打断；
当线程碰到一条 wait()语句时，它会一直阻塞到接到通知（notify()）、被中断或经过了指定毫秒时间为止（若制定了超时值的话）
线程阻塞与不同 I/O 的方式有多种。常见的一种方式是 InputStream的read()方法，该方法一直阻塞到从流中读取一个字节的数据为止，它可以无限阻塞，因此不能指定超时时间；
线程也可以阻塞等待获取某个对象锁的排他性访问权限（即等待获得 synchronized 语句必须的锁时阻塞）。
注意，并非所有的阻塞状态都是可中断的，以上阻塞状态的前两种可以被中断，后两种不会对中断做出反应




Volatile 关键字（上）

volatile 用处说明
在 JDK1.2 之前，Java 的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而随着 JVM 的成熟和优化，现在在多线程环境下 volatile 关键字的使用变得非常重要。

在当前的 Java 内存模型下，线程可以把变量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。

要解决这个问题，就需要把变量声明为 volatile，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。一般说来，多任务环境下，各任务间共享的变量都应该加 volatile 修饰符。

Volatile 修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。

Java 语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而且只当线程进入或者离开同步代码块时才将私有拷贝与共享内存中的原始值进行比较。

这样当多个线程同时与某个对象交互时，就必须注意到要让线程及时的得到共享成员变量的变化。而 volatile 关键字就是提示 JVM：对于这个成员变量，不能保存它的私有拷贝，而应直接与共享成员变量交互。

volatile 是一种稍弱的同步机制，在访问 volatile 变量时不会执行加锁操作，也就不会执行线程阻塞，因此 volatilei 变量是一种比 synchronized 关键字更轻量级的同步机制。

使用建议：在两个或者更多的线程需要访问的成员变量上使用 volatile。当要访问的变量已在 synchronized 代码块中，或者为常量时，没必要使用 volatile。

由于使用 volatile 屏蔽掉了 JVM 中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。

示例程序
下面给出一段代码，通过其运行结果来说明使用关键字 volatile 产生的差异，但实际上遇到了意料之外的问题：

public class Volatile extends Object implements Runnable {  
    //value变量没有被标记为volatile  
    private int value;    
    //missedIt变量被标记为volatile  
    private volatile boolean missedIt;  
    //creationTime不需要声明为volatile，因为代码执行中它没有发生变化  
    private long creationTime;   

    public Volatile() {  
        value = 10;  
        missedIt = false;  
        //获取当前时间，亦即调用Volatile构造函数时的时间  
        creationTime = System.currentTimeMillis();  
    }  

    public void run() {  
        print("entering run()");  

        //循环检查value的值是否不同  
        while ( value < 20 ) {  
            //如果missedIt的值被修改为true，则通过break退出循环  
            if  ( missedIt ) {  
                //进入同步代码块前，将value的值赋给currValue  
                int currValue = value;  
                //在一个任意对象上执行同步语句，目的是为了让该线程在进入和离开同步代码块时，  
                //将该线程中的所有变量的私有拷贝与共享内存中的原始值进行比较，  
                //从而发现没有用volatile标记的变量所发生的变化  
                Object lock = new Object();  
                synchronized ( lock ) {  
                    //不做任何事  
                }  
                //离开同步代码块后，将此时value的值赋给valueAfterSync  
                int valueAfterSync = value;  
                print("in run() - see value=" + currValue +", but rumor has it that it changed!");  
                print("in run() - valueAfterSync=" + valueAfterSync);  
                break;   
            }  
        }  
        print("leaving run()");  
    }  

    public void workMethod() throws InterruptedException {  
        print("entering workMethod()");  
        print("in workMethod() - about to sleep for 2 seconds");  
        Thread.sleep(2000);  
        //仅在此改变value的值  
        value = 50;  
        print("in workMethod() - just set value=" + value);  
        print("in workMethod() - about to sleep for 5 seconds");  
        Thread.sleep(5000);  
        //仅在此改变missedIt的值  
        missedIt = true;  
        print("in workMethod() - just set missedIt=" + missedIt);  
        print("in workMethod() - about to sleep for 3 seconds");  
        Thread.sleep(3000);  
        print("leaving workMethod()");  
    }  

/* 
*该方法的功能是在要打印的msg信息前打印出程序执行到此所化去的时间，以及打印msg的代码所在的线程 
*/  
    private void print(String msg) {  
        //使用java.text包的功能，可以简化这个方法，但是这里没有利用这一点  
        long interval = System.currentTimeMillis() - creationTime;  
        String tmpStr = "    " + ( interval / 1000.0 ) + "000";       
        int pos = tmpStr.indexOf(".");  
        String secStr = tmpStr.substring(pos - 2, pos + 4);  
        String nameStr = "        " + Thread.currentThread().getName();  
        nameStr = nameStr.substring(nameStr.length() - 8, nameStr.length());      
        System.out.println(secStr + " " + nameStr + ": " + msg);  
    }  

    public static void main(String[] args) {  
        try {  
            //通过该构造函数可以获取实时时钟的当前时间  
            Volatile vol = new Volatile();  

            //稍停100ms，以让实时时钟稍稍超前获取时间，使print（）中创建的消息打印的时间值大于0  
            Thread.sleep(100);    

            Thread t = new Thread(vol);  
            t.start();  

            //休眠100ms，让刚刚启动的线程有时间运行  
            Thread.sleep(100);    
            //workMethod方法在main线程中运行  
            vol.workMethod();  
        } catch ( InterruptedException x ) {  
            System.err.println("one of the sleeps was interrupted");  
        }  
    }  
}  
按照以上的理论来分析，由于 value 变量不是 volatile 的，因此它在 main 线程中的改变不会被 Thread-0 线程（在 main 线程中新开启的线程）马上看到，因此 Thread-0 线程中的 while 循环不会直接退出，它会继续判断 missedIt 的值，由于 missedIt 是 volatile 的，当 main 线程中改变了 missedIt 时，Thread-0 线程会立即看到该变化，那么 if 语句中的代码便得到了执行的机会，由于此时 Thread-0 依然没有看到 value 值的变化，因此，currValue 的值为 10，继续向下执行，进入同步代码块，因为进入前后要将该线程内的变量值与共享内存中的原始值对比，进行校准，因此离开同步代码块后，Thread-0 便会察觉到 value 的值变为了 50，那么后面的 valueAfterSync 的值便为 50，最后从 break 跳出循环，结束 Thread-0 线程。

意料之外的问题
但实际的执行结果如下：



从结果中可以看出，Thread-0 线程并没有进入 while 循环，说明 Thread-0 线程在 value 的值发生变化后，missedIt 的值发生变化前，便察觉到了 value 值的变化，从而退出了 while 循环。这与理论上的分析不符，我便尝试注释掉 value 值发生改变与 missedIt 值发生改变之间的线程休眠代码 Thread.sleep(5000)，以确保Thread-0 线程在 missedIt 的值发生改变前，没有时间察觉到 value 值的变化。但执行的结果与上面大同小异（可能有一两行顺序不同，但依然不会打印出 if 语句中的输出信息）。

问题分析
在 JDK1.7~JDK1.3 之间的版本上输出结果与上面基本大同小异，只有在 JDK1.2 上才得到了预期的结果，即Thread-0 线程中的 while 循环是从 if 语句中退出的，这说明 Thread-0 线程没有及时察觉到 value 值的变化。

这里需要注意：volatile 是针对 JIT 带来的优化，因此 JDK1.2 以前的版本基本不用考虑，另外，在 JDK1.3.1 开始，开始运用 HotSpot 虚拟机，用来代替 JIT。因此，是不是 HotSpot 的问题呢？这里需要再补充一点：

JIT 或 HotSpot 编译器在 server 模式和 client 模式编译不同，server 模式为了使线程运行更快，如果其中一个线程更改了变量 boolean flag 的值，那么另外一个线程会看不到，因为另外一个线程为了使得运行更快所以从寄存器或者本地 cache 中取值，而不是从内存中取值，那么使用 volatile 后，就告诉不论是什么线程，被volatile修饰的变量都要从内存中取值。

对于非 volatile 修饰的变量，尽管 jvm 的优化，会导致变量的可见性问题，但这种可见性的问题也只是在短时间内高并发的情况下发生，CPU 执行时会很快刷新 Cache，一般的情况下很难出现，而且出现这种问题是不可预测的，与 jvm, 机器配置环境等都有关。



Volatile 关键字（下）

在《Volatile 关键字（上）》一文中遗留了一个问题，就是 volatile 只修饰了 missedIt 变量，而没修饰value 变量，但是在线程读取 value 的值的时候，也读到的是最新的数据。

下面讲解问题出现的原因。

首先明确一点：假如有两个线程分别读写 volatile 变量时，线程 A 写入了某 volatile 变量，线程 B 在读取该 volatile 变量时，便能看到线程 A 对该 volatile 变量的写入操作，关键在这里，它不仅会看到对该 volatile 变量的写入操作，A 线程在写 volatile 变量之前所有可见的共享变量，在 B 线程读同一个 volatile 变量后，都将立即变得对 B 线程可见。

回过头来看文章中出现的问题，由于程序中 volatile 变量 missedIt 的写入操作在 value 变量写入操作之后，而且根据 volatile 规则，又不能重排序，因此，在线程 B 读取由线程 A 改变后的 missedIt 之后，它之前的 value 变量在线程 A 的改变也对线程 B 变得可见了。

我们颠倒一下 value=50 和 missedIt=true 这两行代码试下，即 missedIt=true 在前，value=50 在后，这样便会得到我们想要的结果：value 值的改变不会被看到。

这应该是 JDK1.2 之后对 volatile 规则做了一些修订的结果。

修改后的代码如下：

public class Volatile extends Object implements Runnable {  
    //value变量没有被标记为volatile  
    private int value;    
    //missedIt变量被标记为volatile  
    private volatile boolean missedIt;  
    //creationTime不需要声明为volatile，因为代码执行中它没有发生变化  
    private long creationTime;   

    public Volatile() {  
        value = 10;  
        missedIt = false;  
        //获取当前时间，亦即调用Volatile构造函数时的时间  
        creationTime = System.currentTimeMillis();  
    }  

    public void run() {  
        print("entering run()");  

        //循环检查value的值是否不同  
        while ( value < 20 ) {  
            //如果missedIt的值被修改为true，则通过break退出循环  
            if  ( missedIt ) {  
                //进入同步代码块前，将value的值赋给currValue  
                int currValue = value;  
                //在一个任意对象上执行同步语句，目的是为了让该线程在进入和离开同步代码块时，  
                //将该线程中的所有变量的私有拷贝与共享内存中的原始值进行比较，  
                //从而发现没有用volatile标记的变量所发生的变化  
                Object lock = new Object();  
                synchronized ( lock ) {  
                    //不做任何事  
                }  
                //离开同步代码块后，将此时value的值赋给valueAfterSync  
                int valueAfterSync = value;  
                print("in run() - see value=" + currValue +", but rumor has it that it changed!");  
                print("in run() - valueAfterSync=" + valueAfterSync);  
                break;   
            }  
        }  
        print("leaving run()");  
    }  

    public void workMethod() throws InterruptedException {  
        print("entering workMethod()");  
        print("in workMethod() - about to sleep for 2 seconds");  
        Thread.sleep(2000);  
        //仅在此改变value的值  
        missedIt = true;  
//      value = 50;  
        print("in workMethod() - just set value=" + value);  
        print("in workMethod() - about to sleep for 5 seconds");  
        Thread.sleep(5000);  
        //仅在此改变missedIt的值  
//      missedIt = true;  
        value = 50;  
        print("in workMethod() - just set missedIt=" + missedIt);  
        print("in workMethod() - about to sleep for 3 seconds");  
        Thread.sleep(3000);  
        print("leaving workMethod()");  
    }  

/* 
*该方法的功能是在要打印的msg信息前打印出程序执行到此所化去的时间，以及打印msg的代码所在的线程 
*/  
    private void print(String msg) {  
        //使用java.text包的功能，可以简化这个方法，但是这里没有利用这一点  
        long interval = System.currentTimeMillis() - creationTime;  
        String tmpStr = "    " + ( interval / 1000.0 ) + "000";       
        int pos = tmpStr.indexOf(".");  
        String secStr = tmpStr.substring(pos - 2, pos + 4);  
        String nameStr = "        " + Thread.currentThread().getName();  
        nameStr = nameStr.substring(nameStr.length() - 8, nameStr.length());      
        System.out.println(secStr + " " + nameStr + ": " + msg);  
    }  

    public static void main(String[] args) {  
        try {  
            //通过该构造函数可以获取实时时钟的当前时间  
            Volatile vol = new Volatile();  

            //稍停100ms，以让实时时钟稍稍超前获取时间，使print（）中创建的消息打印的时间值大于0  
            Thread.sleep(100);    

            Thread t = new Thread(vol);  
            t.start();  

            //休眠100ms，让刚刚启动的线程有时间运行  
            Thread.sleep(100);    
            //workMethod方法在main线程中运行  
            vol.workMethod();  
        } catch ( InterruptedException x ) {  
            System.err.println("one of the sleeps was interrupted");  
        }  
    }  
}  
运行结果如下：



很明显，这其实并不符合使用 volatile 的第二个条件：该变量要没有包含在具有其他变量的不变式中。因此，在这里使用 volatile 是不安全的。



synchronized 关键字

在并发编程中，多线程同时并发访问的资源叫做临界资源，当多个线程同时访问对象并要求操作相同资源时，分割了原子操作就有可能出现数据的不一致或数据不完整的情况，为避免这种情况的发生，我们会采取同步机制，以确保在某一时刻，方法内只允许有一个线程。

采用 synchronized 修饰符实现的同步机制叫做互斥锁机制，它所获得的锁叫做互斥锁。每个对象都有一个 monitor (锁标记)，当线程拥有这个锁标记时才能访问这个资源，没有锁标记便进入锁池。任何一个对象系统都会为其创建一个互斥锁，这个锁是为了分配给线程的，防止打断原子操作。每个对象的锁只能分配给一个线程，因此叫做互斥锁。

这里就使用同步机制获取互斥锁的情况，进行几点说明：

如果同一个方法内同时有两个或更多线程，则每个线程有自己的局部变量拷贝。

类的每个实例都有自己的对象级别锁。当一个线程访问实例对象中的 synchronized 同步代码块或同步方法时，该线程便获取了该实例的对象级别锁，其他线程这时如果要访问 synchronized 同步代码块或同步方法，便需要阻塞等待，直到前面的线程从同步代码块或方法中退出，释放掉了该对象级别锁。

访问同一个类的不同实例对象中的同步代码块，不存在阻塞等待获取对象锁的问题，因为它们获取的是各自实例的对象级别锁，相互之间没有影响。

持有一个对象级别锁不会阻止该线程被交换出来，也不会阻塞其他线程访问同一示例对象中的非 synchronized 代码。当一个线程 A 持有一个对象级别锁（即进入了 synchronized 修饰的代码块或方法中）时，线程也有可能被交换出去，此时线程 B 有可能获取执行该对象中代码的时间，但它只能执行非同步代码（没有用 synchronized 修饰），当执行到同步代码时，便会被阻塞，此时可能线程规划器又让 A 线程运行，A 线程继续持有对象级别锁，当 A 线程退出同步代码时（即释放了对象级别锁），如果 B 线程此时再运行，便会获得该对象级别锁，从而执行 synchronized 中的代码。

持有对象级别锁的线程会让其他线程阻塞在所有的 synchronized 代码外。例如，在一个类中有三个synchronized 方法 a，b，c，当线程 A 正在执行一个实例对象 M 中的方法 a 时，它便获得了该对象级别锁，那么其他的线程在执行同一实例对象（即对象 M）中的代码时，便会在所有的 synchronized 方法处阻塞，即在方法 a，b，c 处都要被阻塞，等线程 A 释放掉对象级别锁时，其他的线程才可以去执行方法 a，b 或者 c 中的代码，从而获得该对象级别锁。

使用 synchronized（obj）同步语句块，可以获取指定对象上的对象级别锁。obj 为对象的引用，如果获取了 obj 对象上的对象级别锁，在并发访问 obj 对象时时，便会在其 synchronized 代码处阻塞等待，直到获取到该 obj对象的对象级别锁。当 obj 为 this 时，便是获取当前对象的对象级别锁。

类级别锁被特定类的所有示例共享，它用于控制对 static 成员变量以及 static 方法的并发访问。具体用法与对象级别锁相似。

互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。synchronized 关键字经过编译后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这两个字节码指令。根据虚拟机规范的要求，在执行 monitorenter 指令时，首先要尝试获取对象的锁，如果获得了锁，把锁的计数器加 1，相应地，在执行 monitorexit 指令时会将锁计数器减 1，当计数器为 0 时，锁便被释放了。由于 synchronized 同步块对同一个线程是可重入的，因此一个线程可以多次获得同一个对象的互斥锁，同样，要释放相应次数的该互斥锁，才能最终释放掉该锁。



synchronized 的另个一重要作用：内存可见性

加锁（synchronized 同步）的功能不仅仅局限于互斥行为，同时还存在另外一个重要的方面：内存可见性。我们不仅希望防止某个线程正在使用对象状态而另一个线程在同时修改该状态，而且还希望确保当一个线程修改了对象状态后，其他线程能够看到该变化。而线程的同步恰恰也能够实现这一点。

内置锁可以用于确保某个线程以一种可预测的方式来查看另一个线程的执行结果。为了确保所有的线程都能看到共享变量的最新值，可以在所有执行读操作或写操作的线程上加上同一把锁。下图示例了同步的可见性保证。



当线程 A 执行某个同步代码块时，线程 B 随后进入由同一个锁保护的同步代码块，这种情况下可以保证，当锁被释放前，A 看到的所有变量值（锁释放前，A 看到的变量包括 y 和 x）在 B 获得同一个锁后同样可以由 B 看到。换句话说，当线程 B 执行由锁保护的同步代码块时，可以看到线程 A 之前在同一个锁保护的同步代码块中的所有操作结果。如果在线程 A unlock M 之后，线程 B 才进入 lock M，那么线程 B 都可以看到线程 A unlock M 之前的操作，可以得到 i=1，j=1。如果在线程 B unlock M 之后，线程 A 才进入 lock M，那么线程 B 就不一定能看到线程 A 中的操作，因此 j 的值就不一定是 1。

现在考虑如下代码：

public class  MutableInteger  
{  
    private int value;  

    public int get(){  
        return value;  
    }  
    public void set(int value){  
        this.value = value;  
    }  
} 
以上代码中，get 和 set 方法都在没有同步的情况下访问 value。如果 value 被多个线程共享，假如某个线程调用了 set，那么另一个正在调用 get 的线程可能会看到更新后的 value 值，也可能看不到。

通过对 set 和 get 方法进行同步，可以使 MutableInteger 成为一个线程安全的类，如下：

public class  SynchronizedInteger  
{  
    private int value;  

    public synchronized int get(){  
        return value;  
    }  
    public synchronized void set(int value){  
        this.value = value;  
    }  
} 
对 set 和 get 方法进行了同步，加上了同一把对象锁，这样 get 方法可以看到 set 方法中 value 值的变化，从而每次通过 get 方法取得的 value 的值都是最新的 value 值。



实现内存可见性的两种方法比较：synchronized 和 Volatile

在《synchronized 的另个一重要作用：内存可见性》这篇文中，讲述了通过同步实现内存可见性的方法，在《Volatile 关键字（上）》这篇文中，讲述了通过 volatile 变量实现内存可见性的方法，这里比较下二者的区别。

volatile 变量是一种稍弱的同步机制在访问 volatile 变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此 volatile 变量是一种比 synchronized 关键字更轻量级的同步机制。
从内存可见性的角度看，写入 volatile 变量相当于退出同步代码块，而读取 volatile 变量相当于进入同步代码块。
在代码中如果过度依赖 volatile 变量来控制状态的可见性，通常会比使用锁的代码更脆弱，也更难以理解。仅当 volatile 变量能简化代码的实现以及对同步策略的验证时，才应该使用它。一般来说，用同步机制会更安全些。
加锁机制（即同步机制）既可以确保可见性又可以确保原子性，而 volatile 变量只能确保可见性，原因是声明为 volatile 的简单变量如果当前值与该变量以前的值相关，那么 volatile 关键字不起作用，也就是说如下的表达式都不是原子操作：count++、count = count+1。
当且仅当满足以下所有条件时，才应该使用 volatile 变量：

对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。
该变量没有包含在具有其他变量的不变式中。
总结：在需要同步的时候，第一选择应该是 synchronized 关键字，这是最安全的方式，尝试其他任何方式都是有风险的。尤其在、jdK1.5 之后，对 synchronized 同步机制做了很多优化，如：自适应的自旋锁、锁粗化、锁消除、轻量级锁等，使得它的性能明显有了很大的提升。



多线程环境下安全使用集合 API

在集合 API 中，最初设计的 Vector 和 Hashtable 是多线程安全的。例如：对于 Vector 来说，用来添加和删除元素的方法是同步的。如果只有一个线程与 Vector 的实例交互，那么，要求获取和释放对象锁便是一种浪费，另外在不必要的时候如果滥用同步化，也有可能会带来死锁。因此，对于更改集合内容的方法，没有一个是同步化的。集合本质上是非多线程安全的，当多个线程与集合交互时，为了使它多线程安全，必须采取额外的措施。

在 Collections 类中有多个静态方法，它们可以获取通过同步方法封装非同步集合而得到的集合：

public static Collection synchronizedCollention(Collection c)

public static List synchronizedList(list l)

public static Map synchronizedMap(Map m)

public static Set synchronizedSet(Set s)

public static SortedMap synchronizedSortedMap(SortedMap sm)

public static SortedSet synchronizedSortedSet(SortedSet ss)
这些方法基本上返回具有同步集合方法版本的新类。比如，为了创建多线程安全且由 ArrayList 支持的 List，可以使用如下代码：

List list = Collection.synchronizedList(new ArrayList());
注意，ArrayList 实例马上封装起来，不存在对未同步化 ArrayList 的直接引用（即直接封装匿名实例）。这是一种最安全的途径。如果另一个线程要直接引用 ArrayList 实例，它可以执行非同步修改。

下面给出一段多线程中安全遍历集合元素的示例。我们使用 Iterator 逐个扫描 List 中的元素，在多线程环境中，当遍历当前集合中的元素时，一般希望阻止其他线程添加或删除元素。安全遍历的实现方法如下：

import java.util.*;  

public class SafeCollectionIteration extends Object {  
    public static void main(String[] args) {  
        //为了安全起见，仅使用同步列表的一个引用，这样可以确保控制了所有访问  
        //集合必须同步化，这里是一个List  
        List wordList = Collections.synchronizedList(new ArrayList());  

        //wordList中的add方法是同步方法，会获取wordList实例的对象锁  
        wordList.add("Iterators");  
        wordList.add("require");  
        wordList.add("special");  
        wordList.add("handling");  

        //获取wordList实例的对象锁，  
        //迭代时，阻塞其他线程调用add或remove等方法修改元素  
        synchronized ( wordList ) {  
            Iterator iter = wordList.iterator();  
            while ( iter.hasNext() ) {  
                String s = (String) iter.next();  
                System.out.println("found string: " + s + ", length=" + s.length());  
            }  
        }  
    }  
}  
这里需要注意的是：在 Java 语言中，大部分的线程安全类都是相对线程安全的，它能保证对这个对象单独的操作时线程安全的，我们在调用的时候不需要额外的保障措施，但是对于一些特定的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。例如 Vector、HashTable、Collections的synchronizedXxxx()方法包装的集合等。



死锁

当线程需要同时持有多个锁时，有可能产生死锁。考虑如下情形：

线程 A 当前持有互斥所锁 lock1，线程 B 当前持有互斥锁 lock2。接下来，当线程 A 仍然持有 lock1 时，它试图获取 lock2，因为线程 B 正持有 lock2，因此线程 A 会阻塞等待线程 B 对 lock2 的释放。如果此时线程 B 在持有 lock2 的时候，也在试图获取 lock1，因为线程 A 正持有 lock1，因此线程 B 会阻塞等待 A 对 lock1 的释放。二者都在等待对方所持有锁的释放，而二者却又都没释放自己所持有的锁，这时二者便会一直阻塞下去。这种情形称为死锁。

下面给出一个两个线程间产生死锁的示例，如下：

public class Deadlock extends Object {  
    private String objID;  

    public Deadlock(String id) {  
        objID = id;  
    }  

    public synchronized void checkOther(Deadlock other) {  
        print("entering checkOther()");  
        try { Thread.sleep(2000); }   
        catch ( InterruptedException x ) { }  
        print("in checkOther() - about to " + "invoke 'other.action()'");  

        //调用other对象的action方法，由于该方法是同步方法，因此会试图获取other对象的对象锁  
        other.action();  
        print("leaving checkOther()");  
    }  

    public synchronized void action() {  
        print("entering action()");  
        try { Thread.sleep(500); }   
        catch ( InterruptedException x ) { }  
        print("leaving action()");  
    }  

    public void print(String msg) {  
        threadPrint("objID=" + objID + " - " + msg);  
    }  

    public static void threadPrint(String msg) {  
        String threadName = Thread.currentThread().getName();  
        System.out.println(threadName + ": " + msg);  
    }  

    public static void main(String[] args) {  
        final Deadlock obj1 = new Deadlock("obj1");  
        final Deadlock obj2 = new Deadlock("obj2");  

        Runnable runA = new Runnable() {  
                public void run() {  
                    obj1.checkOther(obj2);  
                }  
            };  

        Thread threadA = new Thread(runA, "threadA");  
        threadA.start();  

        try { Thread.sleep(200); }   
        catch ( InterruptedException x ) { }  

        Runnable runB = new Runnable() {  
                public void run() {  
                    obj2.checkOther(obj1);  
                }  
            };  

        Thread threadB = new Thread(runB, "threadB");  
        threadB.start();  

        try { Thread.sleep(5000); }   
        catch ( InterruptedException x ) { }  

        threadPrint("finished sleeping");  

        threadPrint("about to interrupt() threadA");  
        threadA.interrupt();  

        try { Thread.sleep(1000); }   
        catch ( InterruptedException x ) { }  

        threadPrint("about to interrupt() threadB");  
        threadB.interrupt();  

        try { Thread.sleep(1000); }   
        catch ( InterruptedException x ) { }  

        threadPrint("did that break the deadlock?");  
    }  
} 
运行结果如下：



从结果中可以看出，在执行到 other.action() 时，由于两个线程都在试图获取对方的锁，但对方都没有释放自己的锁，因而便产生了死锁，在主线程中试图中断两个线程，但都无果。

大部分代码并不容易产生死锁，死锁可能在代码中隐藏相当长的时间，等待不常见的条件地发生，但即使是很小的概率，一旦发生，便可能造成毁灭性的破坏。避免死锁是一件困难的事，遵循以下原则有助于规避死锁：

只在必要的最短时间内持有锁，考虑使用同步语句块代替整个同步方法；
尽量编写不在同一时刻需要持有多个锁的代码，如果不可避免，则确保线程持有第二个锁的时间尽量短暂；
创建和使用一个大锁来代替若干小锁，并把这个锁用于互斥，而不是用作单个对象的对象级别锁。



可重入内置锁

每个 Java 对象都可以用做一个实现同步的锁，这些锁被称为内置锁或监视器锁。线程在进入同步代码块之前会自动获取锁，并且在退出同步代码块时会自动释放锁。获得内置锁的唯一途径就是进入由这个锁保护的同步代码块或方法。

当某个线程请求一个由其他线程持有的锁时，发出请求的线程就会阻塞。然而，由于内置锁是可重入的，因此如果摸个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。“重入”意味着获取锁的操作的粒度是“线程”，而不是调用。重入的一种实现方法是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为 0 时，这个锁就被认为是没有被任何线程所持有，当线程请求一个未被持有的锁时，JVM 将记下锁的持有者，并且将获取计数值置为 1，如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码块时，计数器会相应地递减。当计数值为 0 时，这个锁将被释放。

重入进一步提升了加锁行为的封装性，因此简化了面向对象并发代码的开发。分析如下程序：

public class Father  
{  
    public synchronized void doSomething(){  
        ......  
    }  
}  

public class Child extends Father  
{  
    public synchronized void doSomething(){  
        ......  
        super.doSomething();  
    }  
} 
子类覆写了父类的同步方法，然后调用父类中的方法，此时如果没有可重入的锁，那么这段代码件产生死锁。

由于 Fither 和 Child 中的 doSomething 方法都是 synchronized 方法，因此每个 doSomething 方法在执行前都会获取 Child 对象实例上的锁。如果内置锁不是可重入的，那么在调用 super.doSomething 时将无法获得该 Child 对象上的互斥锁，因为这个锁已经被持有，从而线程会永远阻塞下去，一直在等待一个永远也无法获取的锁。重入则避免了这种死锁情况的发生。

同一个线程在调用本类中其他 synchronized 方法/块或父类中的 synchronized 方法/块时，都不会阻碍该线程地执行，因为互斥锁时可重入的。



线程间协作：wait、notify、notifyAll

在 Java 中，可以通过配合调用 Object 对象的 wait() 方法和 notify()方法或 notifyAll() 方法来实现线程间的通信。在线程中调用 wait() 方法，将阻塞等待其他线程的通知（其他线程调用 notify() 方法或 notifyAll() 方法），在线程中调用 notify() 方法或 notifyAll() 方法，将通知其他线程从 wait() 方法处返回。

Object 是所有类的超类，它有 5 个方法组成了等待/通知机制的核心：notify()、notifyAll()、wait()、wait(long)和 wait(long，int)。在 Java 中，所有的类都从 Object 继承而来，因此，所有的类都拥有这些共有方法可供使用。而且，由于他们都被声明为 final，因此在子类中不能覆写任何一个方法。

这里详细说明一下各个方法在使用中需要注意的几点。

wait()
public final void wait() throws InterruptedException,IllegalMonitorStateException

该方法用来将当前线程置入休眠状态，直到接到通知或被中断为止。在调用 wait()之前，线程必须要获得该对象的对象级别锁，即只能在同步方法或同步块中调用 wait()方法。进入 wait()方法后，当前线程释放锁。在从 wait()返回前，线程与其他线程竞争重新获得锁。如果调用 wait()时，没有持有适当的锁，则抛出 IllegalMonitorStateException，它是 RuntimeException 的一个子类，因此，不需要 try-catch 结构。

notify()
public final native void notify() throws IllegalMonitorStateException

该方法也要在同步方法或同步块中调用，即在调用前，线程也必须要获得该对象的对象级别锁，的如果调用 notify()时没有持有适当的锁，也会抛出 IllegalMonitorStateException。

该方法用来通知那些可能等待该对象的对象锁的其他线程。如果有多个线程等待，则线程规划器任意挑选出其中一个 wait()状态的线程来发出通知，并使它等待获取该对象的对象锁（notify 后，当前线程不会马上释放该对象锁，wait 所在的线程并不能马上获取该对象锁，要等到程序退出 synchronized 代码块后，当前线程才会释放锁，wait所在的线程也才可以获取该对象锁），但不惊动其他同样在等待被该对象notify的线程们。当第一个获得了该对象锁的 wait 线程运行完毕以后，它会释放掉该对象锁，此时如果该对象没有再次使用 notify 语句，则即便该对象已经空闲，其他 wait 状态等待的线程由于没有得到该对象的通知，会继续阻塞在 wait 状态，直到这个对象发出一个 notify 或 notifyAll。这里需要注意：它们等待的是被 notify 或 notifyAll，而不是锁。这与下面的 notifyAll()方法执行后的情况不同。

notifyAll()
public final native void notifyAll() throws IllegalMonitorStateException

该方法与 notify ()方法的工作方式相同，重要的一点差异是：

notifyAll 使所有原来在该对象上 wait 的线程统统退出 wait 的状态（即全部被唤醒，不再等待 notify 或 notifyAll，但由于此时还没有获取到该对象锁，因此还不能继续往下执行），变成等待获取该对象上的锁，一旦该对象锁被释放（notifyAll 线程退出调用了 notifyAll 的 synchronized 代码块的时候），他们就会去竞争。如果其中一个线程获得了该对象锁，它就会继续往下执行，在它退出 synchronized 代码块，释放锁后，其他的已经被唤醒的线程将会继续竞争获取该锁，一直进行下去，直到所有被唤醒的线程都执行完毕。

深入理解
如果线程调用了对象的 wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。

当有线程调用了对象的 notifyAll()方法（唤醒所有 wait 线程）或 notify()方法（只随机唤醒一个 wait 线程），被唤醒的的线程便会进入该对象的锁池中，锁池中的线程会去竞争该对象锁。

优先级高的线程竞争到对象锁的概率大，假若某线程没有竞争到该对象锁，它还会留在锁池中，唯有线程再次调用 wait()方法，它才会重新回到等待池中。而竞争到对象锁的线程则继续往下执行，直到执行完了 synchronized 代码块，它会释放掉该对象锁，这时锁池中的线程会继续竞争该对象锁。



notify 通知的遗漏

notify 通知的遗漏很容易理解，即 threadA 还没开始 wait 的时候，threadB 已经 notify 了，这样，threadB 通知是没有任何响应的，当 threadB 退出 synchronized 代码块后，threadA 再开始 wait，便会一直阻塞等待，直到被别的线程打断。

遗漏通知的代码
下面给出一段代码演示通知是如何遗漏的，如下：

public class MissedNotify extends Object {  
    private Object proceedLock;  

    public MissedNotify() {  
        print("in MissedNotify()");  
        proceedLock = new Object();  
    }  

    public void waitToProceed() throws InterruptedException {  
        print("in waitToProceed() - entered");  

        synchronized ( proceedLock ) {  
            print("in waitToProceed() - about to wait()");  
            proceedLock.wait();  
            print("in waitToProceed() - back from wait()");  
        }  

        print("in waitToProceed() - leaving");  
    }  

    public void proceed() {  
        print("in proceed() - entered");  

        synchronized ( proceedLock ) {  
            print("in proceed() - about to notifyAll()");  
            proceedLock.notifyAll();  
            print("in proceed() - back from notifyAll()");  
        }  

        print("in proceed() - leaving");  
    }  

    private static void print(String msg) {  
        String name = Thread.currentThread().getName();  
        System.out.println(name + ": " + msg);  
    }  

    public static void main(String[] args) {  
        final MissedNotify mn = new MissedNotify();  

        Runnable runA = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠1000ms，大于runB中的500ms，  
                        //是为了后调用waitToProceed，从而先notifyAll，后wait，  
                        //从而造成通知的遗漏  
                        Thread.sleep(1000);  
                        mn.waitToProceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  

        Thread threadA = new Thread(runA, "threadA");  
        threadA.start();  

        Runnable runB = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠500ms，小于runA中的1000ms，  
                        //是为了先调用proceed，从而先notifyAll，后wait，  
                        //从而造成通知的遗漏  
                        Thread.sleep(500);  
                        mn.proceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  

        Thread threadB = new Thread(runB, "threadB");  
        threadB.start();  

        try {   
            Thread.sleep(10000);  
        } catch ( InterruptedException x ) {}  

        //试图打断wait阻塞  
        print("about to invoke interrupt() on threadA");  
        threadA.interrupt();  
    }  
}  
执行结果如下：



分析：由于 threadB 在执行 mn.proceed()之前只休眠了 500ms，而 threadA 在执行 mn.waitToProceed()之前休眠了 1000ms，因此，threadB 会先苏醒，继而执行 mn.proceed()，获取到 proceedLock 的对象锁，继而执行其中的 notifyAll()，当退出 proceed()方法中的 synchronized 代码块时，threadA 才有机会获取 proceedLock 的对象锁，继而执行其中的 wait()方法，但此时 notifyAll()方法已经执行完毕，threadA 便漏掉了 threadB 的通知，便会阻塞下去。后面主线程休眠 10 秒后，尝试中断 threadA 线程，使其抛出 InterruptedException。

修正后的代码
为了修正 MissedNotify，需要添加一个 boolean 指示变量，该变量只能在同步代码块内部访问和修改。修改后的代码如下：

public class MissedNotifyFix extends Object {  
    private Object proceedLock;  
    //该标志位用来指示线程是否需要等待  
    private boolean okToProceed;  

    public MissedNotifyFix() {  
        print("in MissedNotify()");  
        proceedLock = new Object();  
        //先设置为false  
        okToProceed = false;  
    }  

    public void waitToProceed() throws InterruptedException {  
        print("in waitToProceed() - entered");  

        synchronized ( proceedLock ) {  
            print("in waitToProceed() - entered sync block");  
            //while循环判断，这里不用if的原因是为了防止早期通知  
            while ( okToProceed == false ) {  
                print("in waitToProceed() - about to wait()");  
                proceedLock.wait();  
                print("in waitToProceed() - back from wait()");  
            }  

            print("in waitToProceed() - leaving sync block");  
        }  

        print("in waitToProceed() - leaving");  
    }  

    public void proceed() {  
        print("in proceed() - entered");  

        synchronized ( proceedLock ) {  
            print("in proceed() - entered sync block");  
            //通知之前，将其设置为true，这样即使出现通知遗漏的情况，也不会使线程在wait出阻塞  
            okToProceed = true;  
            print("in proceed() - changed okToProceed to true");  
            proceedLock.notifyAll();  
            print("in proceed() - just did notifyAll()");  

            print("in proceed() - leaving sync block");  
        }  

        print("in proceed() - leaving");  
    }  

    private static void print(String msg) {  
        String name = Thread.currentThread().getName();  
        System.out.println(name + ": " + msg);  
    }  

    public static void main(String[] args) {  
        final MissedNotifyFix mnf = new MissedNotifyFix();  

        Runnable runA = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠1000ms，大于runB中的500ms，  
                        //是为了后调用waitToProceed，从而先notifyAll，后wait，  
                        Thread.sleep(1000);  
                        mnf.waitToProceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  

        Thread threadA = new Thread(runA, "threadA");  
        threadA.start();  

        Runnable runB = new Runnable() {  
                public void run() {  
                    try {  
                        //休眠500ms，小于runA中的1000ms，  
                        //是为了先调用proceed，从而先notifyAll，后wait，  
                        Thread.sleep(500);  
                        mnf.proceed();  
                    } catch ( InterruptedException x ) {  
                        x.printStackTrace();  
                    }  
                }  
            };  

        Thread threadB = new Thread(runB, "threadB");  
        threadB.start();  

        try {   
            Thread.sleep(10000);  
        } catch ( InterruptedException x ) {}  

        print("about to invoke interrupt() on threadA");  
        threadA.interrupt();  
    }  
}  
执行结果如下：



注意代码中加了注释的部分，在 threadB 进行通知之前，先将 okToProceed 置为 true，这样如果 threadA 将通知遗漏，那么就不会进入 while 循环，也便不会执行 wait 方法，线程也就不会阻塞。如果通知没有被遗漏，wait 方法返回后，okToProceed 已经被置为 true，下次 while 循环判断条件不成立，便会退出循环。

这样，通过标志位和 wait、notifyAll 的配合使用，便避免了通知遗漏而造成的阻塞问题。

总结：在使用线程的等待/通知机制时，一般都要配合一个 boolean 变量值（或者其他能够判断真假的条件），在 notify 之前改变该 boolean 变量的值，让 wait 返回后能够退出 while 循环（一般都要在 wait 方法外围加一层 while 循环，以防止早期通知），或在通知被遗漏后，不会被阻塞在 wait 方法处。这样便保证了程序的正确性。




notifyAll 造成的早期通知问题

如果线程在等待时接到通知，但线程等待的条件还不满足，此时，线程接到的就是早期通知，如果条件满足的时间很短，但很快又改变了，而变得不再满足，这时也将发生早期通知。这种现象听起来很奇怪，下面通过一个示例程序来说明问题。

很简单，两个线程等待删除 List 中的元素，同时另外一个线程正要向其中添加项目。代码如下：

import java.util.*;  

public class EarlyNotify extends Object {  
    private List list;  

    public EarlyNotify() {  
        list = Collections.synchronizedList(new LinkedList());  
    }  

    public String removeItem() throws InterruptedException {  
        print("in removeItem() - entering");  

        synchronized ( list ) {  
            if ( list.isEmpty() ) {  //这里用if语句会发生危险  
                print("in removeItem() - about to wait()");  
                list.wait();  
                print("in removeItem() - done with wait()");  
            }  

            //删除元素  
            String item = (String) list.remove(0);  

            print("in removeItem() - leaving");  
            return item;  
        }  
    }  

    public void addItem(String item) {  
        print("in addItem() - entering");  
        synchronized ( list ) {  
            //添加元素  
            list.add(item);  
            print("in addItem() - just added: '" + item + "'");  

            //添加后，通知所有线程  
            list.notifyAll();  
            print("in addItem() - just notified");  
        }  
        print("in addItem() - leaving");  
    }  

    private static void print(String msg) {  
        String name = Thread.currentThread().getName();  
        System.out.println(name + ": " + msg);  
    }  

    public static void main(String[] args) {  
        final EarlyNotify en = new EarlyNotify();  

        Runnable runA = new Runnable() {  
                public void run() {  
                    try {  
                        String item = en.removeItem();  
                        print("in run() - returned: '" +   
                                item + "'");  
                    } catch ( InterruptedException ix ) {  
                        print("interrupted!");  
                    } catch ( Exception x ) {  
                        print("threw an Exception!!!\n" + x);  
                    }  
                }  
            };  

        Runnable runB = new Runnable() {  
                public void run() {  
                    en.addItem("Hello!");  
                }  
            };  

        try {  
            //启动第一个删除元素的线程  
            Thread threadA1 = new Thread(runA, "threadA1");  
            threadA1.start();  

            Thread.sleep(500);  

            //启动第二个删除元素的线程  
            Thread threadA2 = new Thread(runA, "threadA2");  
            threadA2.start();  

            Thread.sleep(500);  
            //启动增加元素的线程  
            Thread threadB = new Thread(runB, "threadB");  
            threadB.start();  

            Thread.sleep(10000); // wait 10 seconds  

            threadA1.interrupt();  
            threadA2.interrupt();  
        } catch ( InterruptedException x ) {}  
    }  
}  
执行结果如下：



分析：首先启动 threadA1，threadA1 在 removeItem()中调用 wait()，从而释放 list 上的对象锁。再过 500ms，启动 threadA2，threadA2 调用 removeItem()，获取 list 上的对象锁，也发现列表为空，从而在 wait()方法处阻塞，释放 list 上的对象锁。再过 500ms 后，启动 threadB，并调用 addItem，获得 list 上的对象锁，并在 list 中添加一个元素，同时用 notifyAll 通知所有线程。

threadA1 和 threadA2 都从 wait()返回，等待获取 list 对象上的对象锁，并试图从列表中删除添加的元素，这就会产生麻烦，只有其中一个操作能成功。假设 threadA1 获取了 list 上的对象锁，并删除元素成功，在退出 synchronized 代码块时，它便会释放 list 上的对象锁，此时 threadA2 便会获取 list 上的对象锁，会继续删除 list 中的元素，但是 list 已经为空了，这便会抛出 IndexOutOfBoundsException。

要避免以上问题只需将 wait 外围的 if 语句改为 while 循环即可，这样当 list 为空时，线程便会继续等待，而不会继续去执行删除 list 中元素的代码。

修改后的执行结果如下：



总结：在使用线程的等待/通知机制时，一般都要在 while 循环中调用 wait()方法，满足条件时，才让 while循环退出，这样一般也要配合使用一个 boolean 变量（或其他能判断真假的条件，如本文中的 list.isEmpty()），满足 while 循环的条件时，进入 while 循环，执行 wait()方法，不满足 while 循环的条件时，跳出循环，执行后面的代码。



生产者—消费者模型

生产者消费者问题是线程模型中的经典问题：生产者和消费者在同一时间段内共用同一存储空间，生产者向空间里生产数据，而消费者取走数据。

这里实现如下情况的生产--消费模型：

生产者不断交替地生产两组数据“姓名--1 --> 内容--1”，“姓名--2--> 内容--2”，消费者不断交替地取得这两组数据，这里的“姓名--1”和“姓名--2”模拟为数据的名称，“内容--1 ”和“内容--2 ”模拟为数据的内容。

由于本程序中牵扯到线程运行的不确定性，因此可能会出现以下问题：

假设生产者线程刚向数据存储空间添加了数据的名称，还没有加入该信息的内容，程序就切换到了消费者线程，消费者线程将把信息的名称和上一个信息的内容联系在一起；
生产者生产了若干次数据，消费者才开始取数据，或者是，消费者取完一次数据后，还没等生产者放入新的数据，又重复取出了已取过的数据。
问题 1 很明显要靠同步来解决，问题 2 则需要线程间通信，生产者线程放入数据后，通知消费者线程取出数据，消费者线程取出数据后，通知生产者线程生产数据，这里用 wait/notify 机制来实现。

详细的实现代码如下：

class Info{ // 定义信息类  
    private String name = "name";//定义name属性，为了与下面set的name属性区别开  
    private String content = "content" ;// 定义content属性，为了与下面set的content属性区别开  
    private boolean flag = true ;   // 设置标志位,初始时先生产  
    public synchronized void set(String name,String content){  
        while(!flag){  
            try{  
                super.wait() ;  
            }catch(InterruptedException e){  
                e.printStackTrace() ;  
            }  
        }  
        this.setName(name) ;    // 设置名称  
        try{  
            Thread.sleep(300) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  
        this.setContent(content) ;  // 设置内容  
        flag  = false ; // 改变标志位，表示可以取走  
        super.notify();  
    }  
    public synchronized void get(){  
        while(flag){  
            try{  
                super.wait() ;  
            }catch(InterruptedException e){  
                e.printStackTrace() ;  
            }  
        }  
        try{  
            Thread.sleep(300) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  
        System.out.println(this.getName() +   
            " --> " + this.getContent()) ;  
        flag  = true ;  // 改变标志位，表示可以生产  
        super.notify();  
    }  
    public void setName(String name){  
        this.name = name ;  
    }  
    public void setContent(String content){  
        this.content = content ;  
    }  
    public String getName(){  
        return this.name ;  
    }  
    public String getContent(){  
        return this.content ;  
    }  
}  
class Producer implements Runnable{ // 通过Runnable实现多线程  
    private Info info = null ;      // 保存Info引用  
    public Producer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        boolean flag = true ;   // 定义标记位  
        for(int i=0;i<10;i++){  
            if(flag){  
                this.info.set("姓名--1","内容--1") ;    // 设置名称  
                flag = false ;  
            }else{  
                this.info.set("姓名--2","内容--2") ;    // 设置名称  
                flag = true ;  
            }  
        }  
    }  
}  
class Consumer implements Runnable{  
    private Info info = null ;  
    public Consumer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        for(int i=0;i<10;i++){  
            this.info.get() ;  
        }  
    }  
}  
public class ThreadCaseDemo03{  
    public static void main(String args[]){  
        Info info = new Info(); // 实例化Info对象  
        Producer pro = new Producer(info) ; // 生产者  
        Consumer con = new Consumer(info) ; // 消费者  
        new Thread(pro).start() ;  
        //启动了生产者线程后，再启动消费者线程  
        try{  
            Thread.sleep(500) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  

        new Thread(con).start() ;  
    }  
}  
执行结果如下：



另外，在 run 方法中，二者循环的次数要相同，否则，当一方的循环结束时，另一方的循环依然继续，它会阻塞在 wait()方法处，而等不到对方的 notify 通知。



深入 Java 内存模型（1）

happen—before 规则介绍
Java 语言中有一个“先行发生”（happen—before）的规则，它是 Java 内存模型中定义的两项操作之间的偏序关系，如果操作 A 先行发生于操作 B，其意思就是说，在发生操作 B 之前，操作A产生的影响都能被操作 B 观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等，它与时间上的先后发生基本没有太大关系。这个原则特别重要，它是判断数据是否存在竞争、线程是否安全的主要依据。

举例来说，假设存在如下三个线程，分别执行对应的操作:

线程 A 中执行如下操作：i=1

线程 B 中执行如下操作：j=i

线程 C 中执行如下操作：i=2
假设线程 A 中的操作”i=1“ happen—before 线程 B 中的操作“j=i”，那么就可以保证在线程 B 的操作执行后，变量 j 的值一定为 1，即线程 B 观察到了线程 A 中操作“i=1”所产生的影响；现在，我们依然保持线程 A 和线程 B 之间的 happen—before 关系，同时线程 C 出现在了线程 A 和线程 B 的操作之间，但是 C 与 B 并没有 happen—before 关系，那么 j 的值就不确定了，线程 C 对变量 i 的影响可能会被线程 B 观察到，也可能不会，这时线程 B 就存在读取到不是最新数据的风险，不具备线程安全性。

下面是 Java 内存模型中的八条可保证 happen—before 的规则，它们无需任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们进行随机地重排序。

程序次序规则：在一个单独的线程中，按照程序代码的执行流顺序，（时间上）先执行的操作 happen—before（时间上）后执行的操作。

管理锁定规则：一个 unlock 操作 happen—before 后面（时间上的先后顺序，下同）对同一个锁的 lock 操作。

volatile变量规则：对一个 volatile 变量的写操作 happen—before 后面对该变量的读操作。

线程启动规则：Thread 对象的 start()方法 happen—before 此线程的每一个动作。

线程终止规则：线程的所有操作都 happen—before 对此线程的终止检测，可以通过 Thread.join()方法结束 Thread.isAlive()的返回值等手段检测到线程已经终止执行。

线程中断规则：对线程 interrupt()方法的调用 happen—before 发生于被中断线程的代码检测到中断时事件的发生。

对象终结规则：一个对象的初始化完成（构造函数执行结束）happen—before 它的 finalize()方法的开始。

传递性：如果操作 A happen—before 操作 B，操作 B happen—before 操作 C，那么可以得出 A happen—before 操作 C。
时间上先后顺序和 happen—before 原则
”时间上执行的先后顺序“与”happen—before“之间有何不同呢？

首先来看操作 A 在时间上先与操作 B 发生，是否意味着操作 A happen—before 操作 B？

一个常用来分析的例子如下：

private int value = 0;  

public int get(){  
    return value;  
}  
public void set(int value){  
    this.value = value;  
}
假设存在线程 A 和线程 B，线程 A 先（时间上的先）调用了 setValue(3)操作，然后（时间上的后）线程B调用了同一对象的 getValue()方法，那么线程B得到的返回值一定是3吗？

对照以上八条 happen—before 规则，发现没有一条规则适合于这里的 value 变量，从而我们可以判定线程 A 中的 setValue(3)操作与线程 B 中的 getValue()操作不存在 happen—before 关系。因此，尽管线程 A 的 setValue(3)在操作时间上先于操作 B 的 getvalue()，但无法保证线程 B 的 getValue()操作一定观察到了线程 A 的 setValue(3)操作所产生的结果，也即是 getValue()的返回值不一定为 3（有可能是之前 setValue 所设置的值）。这里的操作不是线程安全的。

因此，”一个操作时间上先发生于另一个操作“并不代表”一个操作 happen—before 另一个操作“。

解决方法：可以将 setValue（int）方法和 getValue()方法均定义为 synchronized 方法，也可以把 value 定义为 volatile 变量（value 的修改并不依赖 value 的原值，符合 volatile 的使用场景），分别对应 happen—before 规则的第 2 和第 3 条。注意，只将 setValue（int）方法和 getvalue()方法中的一个定义为 synchronized 方法是不行的，必须对同一个变量的所有读写同步，才能保证不读取到陈旧的数据，仅仅同步读或写是不够的 。

其次来看，操作 A happen—before 操作 B，是否意味着操作 A 在时间上先与操作 B 发生？

看有如下代码：

x = 1；  
y = 2; 
假设同一个线程执行上面两个操作：操作 A：x=1 和操作 B：y=2。根据 happen—before 规则的第 1 条，操作 A happen—before 操作 B，但是由于编译器的指令重排序（Java 语言规范规定了 JVM 线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重排序存在的意义在于：JVM 能够根据处理器的特性（CPU 的多级缓存系统、多核处理器等）适当的重新排序机器指令，使机器指令更符合 CPU 的执行特点，最大限度的发挥机器的性能。在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整）等原因，操作 A 在时间上有可能后于操作 B 被处理器执行，但这并不影响 happen—before 原则的正确性。

因此，”一个操作 happen—before 另一个操作“并不代表”一个操作时间上先发生于另一个操作“。

最后，一个操作和另一个操作必定存在某个顺序，要么一个操作或者是先于或者是后于另一个操作，或者与两个操作同时发生。同时发生是完全可能存在的，特别是在多 CPU 的情况下。而两个操作之间却可能没有 happen-before 关系，也就是说有可能发生这样的情况，操作 A 不 happen-before 操作 B，操作 B 也不 happen-before 操作 A，用数学上的术语 happen-before 关系是个偏序关系。两个存在 happen-before 关系的操作不可能同时发生，一个操作 A happen-before 操作 B，它们必定在时间上是完全错开的，这实际上也是同步的语义之一（独占访问）。

利用 happen—before 规则分析 DCL
DCL 即双重检查加锁，下面是一个典型的在单例模式中使用 DCL 的例子：

public class LazySingleton {  
    private int someField;  

    private static LazySingleton instance;  

    private LazySingleton() {  
        this.someField = new Random().nextInt(200)+1;         // (1)  
    }  

    public static LazySingleton getInstance() {  
        if (instance == null) {                               // (2)  
            synchronized(LazySingleton.class) {               // (3)  
                if (instance == null) {                       // (4)  
                    instance = new LazySingleton();           // (5)  
                }  
            }  
        }  
        return instance;                                      // (6)  
    }  

    public int getSomeField() {  
        return this.someField;                                // (7)  
    }  
}  
这里得到单一的 instance 实例是没有问题的，问题的关键在于尽管得到了 Singleton 的正确引用，但是却有可能访问到其成员变量的不正确值。具体来说 Singleton.getInstance().getSomeField() 有可能返回 someField 的默认值 0。如果程序行为正确的话，这应当是不可能发生的事，因为在构造函数里设置的 someField 的值不可能为 0。为也说明这种情况理论上有可能发生，我们只需要说明语句(1)和语句(7)并不存在 happen-before 关系。

假设线程Ⅰ是初次调用 getInstance()方法，紧接着线程Ⅱ也调用了 getInstance()方法和 getSomeField()方法，我们要说明的是线程Ⅰ的语句(1)并不 happen-before 线程Ⅱ的语句(7)。线程Ⅱ在执行 getInstance()方法的语句(2)时，由于对 instance 的访问并没有处于同步块中，因此线程Ⅱ可能观察到也可能观察不到线程Ⅰ在语句(5)时对 instance 的写入，也就是说 instance 的值可能为空也可能为非空。我们先假设 instance 的值非空，也就观察到了线程Ⅰ对 instance 的写入，这时线程Ⅱ就会执行语句(6)直接返回这个 instance 的值，然后对这个 instance 调用 getSomeField()方法，该方法也是在没有任何同步情况被调用，因此整个线程Ⅱ的操作都是在没有同步的情况下调用 ，这时我们便无法利用上述 8 条 happen-before 规则得到线程Ⅰ的操作和线程Ⅱ的操作之间的任何有效的 happen-before 关系（主要考虑规则的第 2 条，但由于线程Ⅱ没有在进入 synchronized 块，因此不存在 lock 与 unlock 锁的问题），这说明线程Ⅰ的语句(1)和线程Ⅱ的语句(7)之间并不存在 happen-before 关系，这就意味着线程Ⅱ在执行语句(7)完全有可能观测不到线程Ⅰ在语句(1)处对 someFiled 写入的值，这就是 DCL 的问题所在。很荒谬，是吧？DCL 原本是为了逃避同步，它达到了这个目的，也正是因为如此，它最终受到惩罚，这样的程序存在严重的 bug，虽然这种 bug 被发现的概率绝对比中彩票的概率还要低得多，而且是转瞬即逝，更可怕的是，即使发生了你也不会想到是 DCL 所引起的。

前面我们说了，线程Ⅱ在执行语句(2)时也有可能观察空值，如果是种情况，那么它需要进入同步块，并执行语句(4)。在语句(4)处线程Ⅱ还能够读到 instance 的空值吗？不可能。这里因为这时对 instance 的写和读都是发生在同一个锁确定的同步块中，这时读到的数据是最新的数据。为也加深印象，我再用 happen-before 规则分析一遍。线程Ⅱ在语句(3)处会执行一个 lock 操作，而线程Ⅰ在语句(5)后会执行一个 unlock 操作，这两个操作都是针对同一个锁--Singleton.class，因此根据第 2 条 happen-before 规则，线程Ⅰ的 unlock 操作 happen-before 线程Ⅱ的 lock 操作，再利用单线程规则，线程Ⅰ的语句(5) -> 线程Ⅰ的 unlock 操作，线程Ⅱ的 lock 操作 -> 线程Ⅱ的语句(4)，再根据传递规则，就有线程Ⅰ的语句(5) -> 线程Ⅱ的语句(4)，也就是说线程Ⅱ在执行语句(4)时能够观测到线程Ⅰ在语句(5)时对 Singleton 的写入值。接着对返回的 instance 调用 getSomeField()方法时，我们也能得到线程Ⅰ的语句(1) -> 线程Ⅱ的语句(7)（由于线程Ⅱ有进入 synchronized 块，根据规则 2 可得），这表明这时 getSomeField 能够得到正确的值。但是仅仅是这种情况的正确性并不妨碍 DCL 的不正确性，一个程序的正确性必须在所有的情况下的行为都是正确的，而不能有时正确，有时不正确。

对 DCL 的分析也告诉我们一条经验原则：对引用（包括对象引用和数组引用）的非同步访问，即使得到该引用的最新值，却并不能保证也能得到其成员变量（对数组而言就是每个数组元素）的最新值。

解决方案
最简单而且安全的解决方法是使用 static 内部类的思想，它利用的思想是：一个类直到被使用时才被初始化，而类初始化的过程是非并行的，这些都有 JLS 保证。

如下述代码：

public class Singleton {  

  private Singleton() {}  

  // Lazy initialization holder class idiom for static fields  
  private static class InstanceHolder {  
   private static final Singleton instance = new Singleton();  
  }  

  public static Singleton getSingleton() {   
    return InstanceHolder.instance;   
  }  
}  
另外，可以将 instance 声明为 volatile，即

private volatile static LazySingleton instance;

这样我们便可以得到，线程Ⅰ的语句(5) -> 语线程Ⅱ的句(2)，根据单线程规则，线程Ⅰ的语句(1) -> 线程Ⅰ的语句(5)和语线程Ⅱ的句(2) -> 语线程Ⅱ的句(7)，再根据传递规则就有线程Ⅰ的语句(1) -> 语线程Ⅱ的句(7)，这表示线程Ⅱ能够观察到线程Ⅰ在语句(1)时对 someFiled 的写入值，程序能够得到正确的行为。

注： 1、volatile 屏蔽指令重排序的语义在 JDK1.5 中才被完全修复，此前的 JDK 中及时将变量声明为 volatile，也仍然不能完全避免重排序所导致的问题（主要是 volatile 变量前后的代码仍然存在重排序问题），这点也是在 JDK1.5 之前的 Java 中无法安全使用 DCL 来实现单例模式的原因。

2、把 volatile 写和 volatile 读这两个操作综合起来看，在读线程 B 读一个 volatile 变量后，写线程 A 在写这个 volatile 变量之前，所有可见的共享变量的值都将立即变得对读线程 B 可见。

3、 在 java5 之前对 final 字段的同步语义和其它变量没有什么区别，在 java5 中，final 变量一旦在构造函数中设置完成（前提是在构造函数中没有泄露 this 引用)，其它线程必定会看到在构造函数中设置的值。而 DCL 的问题正好在于看到对象的成员变量的默认值，因此我们可以将 LazySingleton的someField 变量设置成 final，这样在 java5 中就能够正确运行了。




深入 Java 内存模型（2）

主内存与工作内存
Java 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量主要是指共享变量，存在竞争问题的变量。Java 内存模型规定所有的变量都存储在主内存中，而每条线程还有自己的工作内存，线程的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量（根据 Java 虚拟机规范的规定，volatile 变量依然有共享内存的拷贝，但是由于它特殊的操作顺序性规定——从工作内存中读写数据前，必须先将主内存中的数据同步到工作内存中，所有看起来如同直接在主内存中读写访问一般，因此这里的描述对于 volatile 也不例外）。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值得传递均需要通过主内存来完成。

内存间交互操作
Java 内存模型中定义了以下 8 种操作来完成主内存与工作内存之间交互的实现细节：

luck（锁定）：作用于主内存的变量，它把一个变量标示为一条线程独占的状态。

unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。

read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到工作内存中，以便随后的 load 动作使用。

load（载入）：作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。

use（使用）：作用于工作内存的变量，它把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值得字节码指令时将会执行这个操作。

assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。

store（存储）：作用于工作内存的变量，它把工作内存中的一个变量的值传递到主内存中，以便随后的 write 操作使用。

write（写入）：作用于主内存的变量，它把 store 操作从工作内存中得到的变量值放入主内存的变量中。
Java 内存模型还规定了执行上述 8 种基本操作时必须满足如下规则：

不允许 read 和 load、store 和 write 操作之一单独出现，以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read 与 load 之间、store 与 write 之间是可插入其他指令的。

不允许一个线程丢弃它的最近的 assign 操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。

不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从线程的工作内存同步回主内存中。

一个新的变量只能从主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load 或 assign）的变量，换句话说就是对一个变量实施 use 和 store 操作之前，必须先执行过了 assign 和 load 操作。

一个变量在同一个时刻只允许一条线程对其执行 lock 操作，但 lock 操作可以被同一个条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。

如果对一个变量执行 lock 操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行 load 或 assign 操作初始化变量的值。

如果一个变量实现没有被 lock 操作锁定，则不允许对它执行 unlock 操作，也不允许去 unlock 一个被其他线程锁定的变量。

对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存（执行 store 和 write 操作）。
volatile 型变量的特殊规则
Java 内存模型对 volatile 专门定义了一些特殊的访问规则，当一个变量被定义成 volatile 之后，他将具备两种特性：

保证此变量对所有线程的可见性。这里不具体解释了。需要注意，volatile 变量的写操作除了对它本身的读操作可见外，volatile 写操作之前的所有共享变量均对 volatile 读操作之后的操作可见，另外注意其适用场景。

禁止指令重排序优化。普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获得正确的结果，而不能保证变量赋值操作的顺序与程序中的执行顺序一致，在单线程中，我们是无法感知这一点的。

补充：Java 语言规范规定了 JVM 线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致，这个过程通过叫做指令的重排序。指令重排序存在的意义在于：JVM 能够根据处理器的特性（CPU 的多级缓存系统、多核处理器等）适当的重新排序机器指令，使机器指令更符合 CPU 的执行特点，最大限度的发挥机器的性能。在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整。
final 域
final 类型的域是不能修改的，除了这一点外，在 Java 内存模型中，final 域还有着特殊的语义，final 域能确保初始化过程的安全性，从而可以不受限制地访问不可变对象，并在共享这些对象时无须同步。具体而言，就是被 final 修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去（this 引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那么在其他线程中就能看到 final 字段的值，而且其外、外部可见状态永远也不会改变。它所带来的安全性是最简单最纯粹的。

long 和 double 型变量的特殊规则
Java 内存模型要求 lock、unlock、read、load、assign、use、store 和 write 这 8 个操作都具有原子性，但是对于 64 位的数据类型 long 和 double，在模型中特别定义了一条宽松的规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行。这样，如果有多个线程共享一个未被声明为 volatile 的 long 或 double 类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读到一个既非原值，也非其他线程修改值得代表了“半个变量”的数值。不过这种读取到“半个变量”的情况非常罕见，因为 Java 内存模型虽然允许虚拟机不把 long 和 double 变量的读写实现成原子操作，但允许迅疾选择把这些操作实现为具有原子性的操作，而且还“强烈建议”虚拟机这样实现。目前各种平台下的商用虚拟机几乎都选择把 64 位数据的读写操作作为原子操作来对待，因此在编码时，不需要将 long 和 double 变量专门声明为 volatile。




并发新特性—Executor 框架与线程池

Executor 框架简介
在 Java 5 之后，并发编程引入了一堆新的启动、调度和管理线程的API。Executor 框架便是 Java 5 中引入的，其内部使用了线程池机制，它在 java.util.cocurrent 包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。因此，在 Java 5之后，通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题——如果我们在构造器中启动一个线程，因为另一个任务可能会在构造器结束之前开始执行，此时可能会访问到初始化了一半的对象用 Executor 在构造器中。

Executor 框架包括：线程池，Executor，Executors，ExecutorService，CompletionService，Future，Callable 等。

Executor 接口中之定义了一个方法 execute（Runnable command），该方法接收一个 Runable 实例，它用来执行一个任务，任务即一个实现了 Runnable 接口的类。ExecutorService 接口继承自 Executor 接口，它提供了更丰富的实现多线程的方法，比如，ExecutorService 提供了关闭自己的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。 可以调用 ExecutorService 的 shutdown（）方法来平滑地关闭 ExecutorService，调用该方法后，将导致 ExecutorService 停止接受任何新的任务且等待已经提交的任务执行完成(已经提交的任务会分两类：一类是已经在执行的，另一类是还没有开始执行的)，当所有已经提交的任务执行完毕后将会关闭 ExecutorService。因此我们一般用该接口来实现和管理多线程。

ExecutorService 的生命周期包括三种状态：运行、关闭、终止。创建后便进入运行状态，当调用了 shutdown（）方法时，便进入关闭状态，此时意味着 ExecutorService 不再接受新的任务，但它还在执行已经提交了的任务，当素有已经提交了的任务执行完后，便到达终止状态。如果不调用 shutdown（）方法，ExecutorService 会一直处在运行状态，不断接收新的任务，执行新的任务，服务器端一般不需要关闭它，保持一直运行即可。

Executors 提供了一系列工厂方法用于创先线程池，返回的线程池都实现了 ExecutorService 接口。

public static ExecutorService newFixedThreadPool(int nThreads)
创建固定数目线程的线程池。

public static ExecutorService newCachedThreadPool()
创建一个可缓存的线程池，调用execute将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线 程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。

public static ExecutorService newSingleThreadExecutor()
创建一个单线程化的Executor。

public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize)
创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代Timer类。

这四种方法都是用的 Executors 中的 ThreadFactory 建立的线程，下面就以上四个方法做个比较：

newCachedThreadPool()

缓存型池子，先查看池中有没有以前建立的线程，如果有，就 reuse 如果没有，就建一个新的线程加入池中
缓存型池子通常用于执行一些生存期很短的异步型任务 因此在一些面向连接的 daemon 型 SERVER 中用得不多。但对于生存期短的异步任务，它是 Executor 的首选。
能 reuse 的线程，必须是 timeout IDLE 内的池中线程，缺省 timeout 是 60s,超过这个 IDLE 时长，线程实例将被终止及移出池。

注意，放入 CachedThreadPool 的线程不必担心其结束，超过 TIMEOUT 不活动，其会自动被终止。
newFixedThreadPool(int)

newFixedThreadPool 与 cacheThreadPool 差不多，也是能 reuse 就用，但不能随时建新的线程。
其独特之处:任意时间点，最多只能有固定数目的活动线程存在，此时如果有新的线程要建立，只能放在另外的队列中等待，直到当前的线程中某个线程终止直接被移出池子。
和 cacheThreadPool 不同，FixedThreadPool 没有 IDLE 机制（可能也有，但既然文档没提，肯定非常长，类似依赖上层的 TCP 或 UDP IDLE 机制之类的），所以 FixedThreadPool 多数针对一些很稳定很固定的正规并发线程，多用于服务器。
从方法的源代码看，cache池和fixed 池调用的是同一个底层 池，只不过参数不同:
fixed 池线程数固定，并且是0秒IDLE（无IDLE）。
cache 池线程数支持 0-Integer.MAX_VALUE(显然完全没考虑主机的资源承受能力），60 秒 IDLE 。
newScheduledThreadPool(int)

调度型线程池
这个池子里的线程可以按 schedule 依次 delay 执行，或周期执行
SingleThreadExecutor()

单例线程，任意时间池中只能有一个线程
用的是和 cache 池和 fixed 池相同的底层池，但线程数目是 1-1,0 秒 IDLE（无 IDLE）
一般来说，CachedTheadPool 在程序执行过程中通常会创建与所需数量相同的线程，然后在它回收旧线程时停止创建新线程，因此它是合理的 Executor 的首选，只有当这种方式会引发问题时（比如需要大量长时间面向连接的线程时），才需要考虑用 FixedThreadPool。（该段话摘自《Thinking in Java》第四版）

Executor 执行 Runnable 任务
通过 Executors 的以上四个静态工厂方法获得 ExecutorService 实例，而后调用该实例的 execute（Runnable command）方法即可。一旦 Runnable 任务传递到 execute（）方法，该方法便会自动在一个线程上执行。下面是 Executor 执行 Runnable 任务的示例代码：

import java.util.concurrent.ExecutorService;   
import java.util.concurrent.Executors;   

public class TestCachedThreadPool{   
    public static void main(String[] args){   
        ExecutorService executorService = Executors.newCachedThreadPool();   
//      ExecutorService executorService = Executors.newFixedThreadPool(5);  
//      ExecutorService executorService = Executors.newSingleThreadExecutor();  
        for (int i = 0; i < 5; i++){   
            executorService.execute(new TestRunnable());   
            System.out.println("************* a" + i + " *************");   
        }   
        executorService.shutdown();   
    }   
}   

class TestRunnable implements Runnable{   
    public void run(){   
        System.out.println(Thread.currentThread().getName() + "线程被调用了。");   
    }   
}  
执行后的结果如下：



从结果中可以看出，pool-1-thread-1 和 pool-1-thread-2 均被调用了两次，这是随机的，execute 会首先在线程池中选择一个已有空闲线程来执行任务，如果线程池中没有空闲线程，它便会创建一个新的线程来执行任务。

Executor 执行 Callable 任务
在 Java 5 之后，任务分两类：一类是实现了 Runnable 接口的类，一类是实现了 Callable 接口的类。两者都可以被 ExecutorService 执行，但是 Runnable 任务没有返回值，而 Callable 任务有返回值。并且 Callable 的 call()方法只能通过 ExecutorService 的 submit(Callable task) 方法来执行，并且返回一个 Future，是表示任务等待完成的 Future。

Callable 接口类似于 Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常而 Callable 又返回结果，而且当获取返回结果时可能会抛出异常。Callable 中的 call()方法类似 Runnable 的 run()方法，区别同样是有返回值，后者没有。

当将一个 Callable 的对象传递给 ExecutorService 的 submit 方法，则该 call 方法自动在一个线程上执行，并且会返回执行结果 Future 对象。同样，将 Runnable 的对象传递给 ExecutorService 的 submit 方法，则该 run 方法自动在一个线程上执行，并且会返回执行结果 Future 对象，但是在该 Future 对象上调用 get 方法，将返回 null。

下面给出一个 Executor 执行 Callable 任务的示例代码：

import java.util.ArrayList;   
import java.util.List;   
import java.util.concurrent.*;   

public class CallableDemo{   
    public static void main(String[] args){   
        ExecutorService executorService = Executors.newCachedThreadPool();   
        List<Future<String>> resultList = new ArrayList<Future<String>>();   

        //创建10个任务并执行   
        for (int i = 0; i < 10; i++){   
            //使用ExecutorService执行Callable类型的任务，并将结果保存在future变量中   
            Future<String> future = executorService.submit(new TaskWithResult(i));   
            //将任务执行结果存储到List中   
            resultList.add(future);   
        }   

        //遍历任务的结果   
        for (Future<String> fs : resultList){   
                try{   
                    while(!fs.isDone);//Future返回如果没有完成，则一直循环等待，直到Future返回完成  
                    System.out.println(fs.get());     //打印各个线程（任务）执行的结果   
                }catch(InterruptedException e){   
                    e.printStackTrace();   
                }catch(ExecutionException e){   
                    e.printStackTrace();   
                }finally{   
                    //启动一次顺序关闭，执行以前提交的任务，但不接受新任务  
                    executorService.shutdown();   
                }   
        }   
    }   
}   

class TaskWithResult implements Callable<String>{   
    private int id;   

    public TaskWithResult(int id){   
        this.id = id;   
    }   

    /**  
     * 任务的具体过程，一旦任务传给ExecutorService的submit方法， 
     * 则该方法自动在一个线程上执行 
     */   
    public String call() throws Exception {  
        System.out.println("call()方法被自动调用！！！    " + Thread.currentThread().getName());   
        //该返回结果将被Future的get方法得到  
        return "call()方法被自动调用，任务返回的结果是：" + id + "    " + Thread.currentThread().getName();   
    }   
}  
执行结果如下：



从结果中可以同样可以看出，submit 也是首先选择空闲线程来执行任务，如果没有，才会创建新的线程来执行任务。另外，需要注意：如果 Future 的返回尚未完成，则 get（）方法会阻塞等待，直到 Future 完成返回，可以通过调用 isDone（）方法判断 Future 是否完成了返回。

自定义线程池
自定义线程池，可以用 ThreadPoolExecutor 类创建，它有多个构造方法来创建线程池，用该类很容易实现自定义的线程池，这里先贴上示例程序：

import java.util.concurrent.ArrayBlockingQueue;   
import java.util.concurrent.BlockingQueue;   
import java.util.concurrent.ThreadPoolExecutor;   
import java.util.concurrent.TimeUnit;   

public class ThreadPoolTest{   
    public static void main(String[] args){   
        //创建等待队列   
        BlockingQueue<Runnable> bqueue = new ArrayBlockingQueue<Runnable>(20);   
        //创建线程池，池中保存的线程数为3，允许的最大线程数为5  
        ThreadPoolExecutor pool = new ThreadPoolExecutor(3,5,50,TimeUnit.MILLISECONDS,bqueue);   
        //创建七个任务   
        Runnable t1 = new MyThread();   
        Runnable t2 = new MyThread();   
        Runnable t3 = new MyThread();   
        Runnable t4 = new MyThread();   
        Runnable t5 = new MyThread();   
        Runnable t6 = new MyThread();   
        Runnable t7 = new MyThread();   
        //每个任务会在一个线程上执行  
        pool.execute(t1);   
        pool.execute(t2);   
        pool.execute(t3);   
        pool.execute(t4);   
        pool.execute(t5);   
        pool.execute(t6);   
        pool.execute(t7);   
        //关闭线程池   
        pool.shutdown();   
    }   
}   

class MyThread implements Runnable{   
    @Override   
    public void run(){   
        System.out.println(Thread.currentThread().getName() + "正在执行。。。");   
        try{   
            Thread.sleep(100);   
        }catch(InterruptedException e){   
            e.printStackTrace();   
        }   
    }   
}  
运行结果如下：



从结果中可以看出，七个任务是在线程池的三个线程上执行的。这里简要说明下用到的 ThreadPoolExecuror 类的构造方法中各个参数的含义。

public ThreadPoolExecutor (int corePoolSize, int maximumPoolSize, long         keepAliveTime, TimeUnit unit,BlockingQueue<Runnable> workQueue)
corePoolSize：线程池中所保存的核心线程数，包括空闲线程。

maximumPoolSize：池中允许的最大线程数。

keepAliveTime：线程池中的空闲线程所能持续的最长时间。

unit：持续时间的单位。

workQueue：任务执行前保存任务的队列，仅保存由 execute 方法提交的 Runnable 任务。
根据 ThreadPoolExecutor 源码前面大段的注释，我们可以看出，当试图通过 excute 方法讲一个 Runnable 任务添加到线程池中时，按照如下顺序来处理：

如果线程池中的线程数量少于 corePoolSize，即使线程池中有空闲线程，也会创建一个新的线程来执行新添加的任务；

如果线程池中的线程数量大于等于 corePoolSize，但缓冲队列 workQueue 未满，则将新添加的任务放到 workQueue 中，按照 FIFO 的原则依次等待执行（线程池中有线程空闲出来后依次将缓冲队列中的任务交付给空闲的线程执行）；

如果线程池中的线程数量大于等于 corePoolSize，且缓冲队列 workQueue 已满，但线程池中的线程数量小于 maximumPoolSize，则会创建新的线程来处理被添加的任务；

如果线程池中的线程数量等于了 maximumPoolSize，有 4 种才处理方式（该构造方法调用了含有 5 个参数的构造方法，并将最后一个构造方法为 RejectedExecutionHandler 类型，它在处理线程溢出时有 4 种方式，这里不再细说，要了解的，自己可以阅读下源码）。
总结起来，也即是说，当有新的任务要处理时，先看线程池中的线程数量是否大于 corePoolSize，再看缓冲队列 workQueue 是否满，最后看线程池中的线程数量是否大于 maximumPoolSize。

另外，当线程池中的线程数量大于 corePoolSize 时，如果里面有线程的空闲时间超过了 keepAliveTime，就将其移除线程池，这样，可以动态地调整线程池中线程的数量。

我们大致来看下 Executors 的源码，newCachedThreadPool 的不带 RejectedExecutionHandler 参数（即第五个参数，线程数量超过 maximumPoolSize 时，指定处理方式）的构造方法如下：

public static ExecutorService newCachedThreadPool() {  
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,  
                                  60L, TimeUnit.SECONDS,  
                                  new SynchronousQueue<Runnable>());  
}
它将 corePoolSize 设定为 0，而将 maximumPoolSize 设定为了 Integer 的最大值，线程空闲超过 60 秒，将会从线程池中移除。由于核心线程数为 0，因此每次添加任务，都会先从线程池中找空闲线程，如果没有就会创建一个线程（SynchronousQueue决定的，后面会说）来执行新的任务，并将该线程加入到线程池中，而最大允许的线程数为 Integer 的最大值，因此这个线程池理论上可以不断扩大。

再来看 newFixedThreadPool 的不带 RejectedExecutionHandler 参数的构造方法，如下：

public static ExecutorService newFixedThreadPool(int nThreads) {  
    return new ThreadPoolExecutor(nThreads, nThreads,  
                                  0L, TimeUnit.MILLISECONDS,  
                                  new LinkedBlockingQueue<Runnable>());  
}  
它将 corePoolSize 和 maximumPoolSize 都设定为了 nThreads，这样便实现了线程池的大小的固定，不会动态地扩大，另外，keepAliveTime 设定为了 0，也就是说线程只要空闲下来，就会被移除线程池，敢于 LinkedBlockingQueue 下面会说。

几种排队的策略
直接提交。缓冲队列采用 SynchronousQueue，它将任务直接交给线程处理而不保持它们。如果不存在可用于立即运行任务的线程（即线程池中的线程都在工作），则试图把任务加入缓冲队列将会失败，因此会构造一个新的线程来处理新添加的任务，并将其加入到线程池中。直接提交通常要求无界 maximumPoolSizes（Integer.MAX_VALUE） 以避免拒绝新提交的任务。newCachedThreadPool 采用的便是这种策略。

无界队列。使用无界队列（典型的便是采用预定义容量的 LinkedBlockingQueue，理论上是该缓冲队列可以对无限多的任务排队）将导致在所有 corePoolSize 线程都工作的情况下将新任务加入到缓冲队列中。这样，创建的线程就不会超过 corePoolSize，也因此，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列。newFixedThreadPool采用的便是这种策略。

有界队列。当使用有限的 maximumPoolSizes 时，有界队列（一般缓冲队列使用 ArrayBlockingQueue，并制定队列的最大长度）有助于防止资源耗尽，但是可能较难调整和控制，队列大小和最大池大小需要相互折衷，需要设定合理的参数。





并发新特性—Lock 锁与条件变量

简单使用 Lock 锁
Java 5 中引入了新的锁机制——java.util.concurrent.locks 中的显式的互斥锁：Lock 接口，它提供了比synchronized 更加广泛的锁定操作。Lock 接口有 3 个实现它的类：ReentrantLock、ReetrantReadWriteLock.ReadLock 和 ReetrantReadWriteLock.WriteLock，即重入锁、读锁和写锁。lock 必须被显式地创建、锁定和释放，为了可以使用更多的功能，一般用 ReentrantLock 为其实例化。为了保证锁最终一定会被释放（可能会有异常发生），要把互斥区放在 try 语句块内，并在 finally 语句块中释放锁，尤其当有 return 语句时，return 语句必须放在 try 字句中，以确保 unlock()不会过早发生，从而将数据暴露给第二个任务。因此，采用 lock 加锁和释放锁的一般形式如下：

Lock lock = new ReentrantLock();//默认使用非公平锁，如果要使用公平锁，需要传入参数true  
........  
lock.lock();  
try {  
     //更新对象的状态  
    //捕获异常，必要时恢复到原来的不变约束  
   //如果有return语句，放在这里  
 finally {  
       lock.unlock();        //锁必须在finally块中释放  
ReetrankLock 与 synchronized 比较
性能比较

在 JDK1.5 中，synchronized 是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞的是实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java 提供的 Lock 对象，性能更高一些。Brian Goetz 对这两种锁在 JDK1.5、单核处理器及双 Xeon 处理器环境下做了一组吞吐量对比的实验，发现多线程环境下，synchronized的吞吐量下降的非常严重，而ReentrankLock 则能基本保持在同一个比较稳定的水平上。但与其说 ReetrantLock 性能好，倒不如说 synchronized 还有非常大的优化余地，于是到了 JDK1.6，发生了变化，对 synchronize 加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在 JDK1.6 上 synchronize 的性能并不比 Lock 差。官方也表示，他们也更支持 synchronize，在未来的版本中还有优化余地，所以还是提倡在 synchronized 能实现需求的情况下，优先考虑使用 synchronized 来进行同步。

下面浅析以下两种锁机制的底层的实现策略。

互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在 CPU 转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起 CPU 频繁的上下文切换导致效率很低。synchronized 采用的便是这种并发策略。

随着指令集的发展，我们有了另一种选择：基于冲突检测的乐观并发策略，通俗地讲就是先进性操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施（最常见的补偿措施就是不断地重拾，直到试成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock 采用的便是这种并发策略。

在乐观的并发策略中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是 CAS 操作（Compare and Swap）。JDK1.5 之后，Java 程序才可以使用CAS操作。我们可以进一步研究 ReentrantLock 的源代码，会发现其中比较重要的获得锁的一个方法是 compareAndSetState，这里其实就是调用的 CPU 提供的特殊指令。现代的 CPU 提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。

Java 5 中引入了注入 AutomicInteger、AutomicLong、AutomicReference 等特殊的原子性变量类，它们提供的如：compareAndSet()、incrementAndSet()和getAndIncrement()等方法都使用了 CAS 操作。因此，它们都是由硬件指令来保证的原子方法。

用途比较

基本语法上，ReentrantLock 与 synchronized 很相似，它们都具备一样的线程重入特性，只是代码写法上有点区别而已，一个表现为 API 层面的互斥锁（Lock），一个表现为原生语法层面的互斥锁（synchronized）。ReentrantLock 相对 synchronized 而言还是增加了一些高级功能，主要有以下三项：

等待可中断：当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情，它对处理执行时间非常上的同步块很有帮助。而在等待由 synchronized 产生的互斥锁时，会一直阻塞，是不能被中断的。
可实现公平锁：多个线程在等待同一个锁时，必须按照申请锁的时间顺序排队等待，而非公平锁则不保证这点，在锁释放时，任何一个等待锁的线程都有机会获得锁。synchronized 中的锁时非公平锁，ReentrantLock 默认情况下也是非公平锁，但可以通过构造方法 ReentrantLock（ture）来要求使用公平锁。
锁可以绑定多个条件：ReentrantLock 对象可以同时绑定多个 Condition 对象（名曰：条件变量或条件队列），而在 synchronized 中，锁对象的 wait()和 notify()或 notifyAll()方法可以实现一个隐含条件，但如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无需这么做，只需要多次调用 newCondition()方法即可。而且我们还可以通过绑定 Condition 对象来判断当前线程通知的是哪些线程（即与 Condition 对象绑定在一起的其他线程）。
可中断锁
ReetrantLock 有两种锁：忽略中断锁和响应中断锁。忽略中断锁与 synchronized 实现的互斥锁一样，不能响应中断，而响应中断锁可以响应中断。

如果某一线程 A 正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程 B 不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，如果此时 ReetrantLock 提供的是忽略中断锁，则它不会去理会该中断，而是让线程B继续等待，而如果此时 ReetrantLock 提供的是响应中断锁，那么它便会处理中断，让线程 B 放弃等待，转而去处理其他事情。

获得响应中断锁的一般形式如下：

ReentrantLock lock = new ReentrantLock();  
...........  
lock.lockInterruptibly();//获取响应中断锁  
try {  
      //更新对象的状态  
      //捕获异常，必要时恢复到原来的不变约束  
      //如果有return语句，放在这里  
}finally{  
    lock.unlock();        //锁必须在finally块中释放  
} 
这里有一个不错的分析中断的示例代码（摘自网上）。

当用 synchronized 中断对互斥锁的等待时，并不起作用，该线程依然会一直等待，如下面的实例：

public class Buffer {  

    private Object lock;  

    public Buffer() {  
        lock = this;  
    }  

    public void write() {  
        synchronized (lock) {  
            long startTime = System.currentTimeMillis();  
            System.out.println("开始往这个buff写入数据…");  
            for (;;)// 模拟要处理很长时间      
            {  
                if (System.currentTimeMillis()  
                        - startTime > Integer.MAX_VALUE) {  
                    break;  
                }  
            }  
            System.out.println("终于写完了");  
        }  
    }  

    public void read() {  
        synchronized (lock) {  
            System.out.println("从这个buff读数据");  
        }  
    }  

    public static void main(String[] args) {  
        Buffer buff = new Buffer();  

        final Writer writer = new Writer(buff);  
        final Reader reader = new Reader(buff);  

        writer.start();  
        reader.start();  

        new Thread(new Runnable() {  

            @Override  
            public void run() {  
                long start = System.currentTimeMillis();  
                for (;;) {  
                    //等5秒钟去中断读      
                    if (System.currentTimeMillis()  
                            - start > 5000) {  
                        System.out.println("不等了，尝试中断");  
                        reader.interrupt();  //尝试中断读线程  
                        break;  
                    }  

                }  

            }  
        }).start();  
        // 我们期待“读”这个线程能退出等待锁，可是事与愿违，一旦读这个线程发现自己得不到锁，  
        // 就一直开始等待了，就算它等死，也得不到锁，因为写线程要21亿秒才能完成 T_T ，即使我们中断它，  
        // 它都不来响应下，看来真的要等死了。这个时候，ReentrantLock给了一种机制让我们来响应中断，  
        // 让“读”能伸能屈，勇敢放弃对这个锁的等待。我们来改写Buffer这个类，就叫BufferInterruptibly吧，可中断缓存。  
    }  
}  

class Writer extends Thread {  

    private Buffer buff;  

    public Writer(Buffer buff) {  
        this.buff = buff;  
    }  

    @Override  
    public void run() {  
        buff.write();  
    }  
}  

class Reader extends Thread {  

    private Buffer buff;  

    public Reader(Buffer buff) {  
        this.buff = buff;  
    }  

    @Override  
    public void run() {  

        buff.read();//这里估计会一直阻塞      

        System.out.println("读结束");  

    }  
}  
执行结果如下：



我们等待了很久，后面依然没有输出，说明读线程对互斥锁的等待并没有被中断，也就是该户吃锁没有响应对读线程的中断。

我们再将上面代码中 synchronized 的互斥锁改为 ReentrantLock 的响应中断锁，即改为如下代码：

import java.util.concurrent.locks.ReentrantLock;  

public class BufferInterruptibly {  

    private ReentrantLock lock = new ReentrantLock();  

    public void write() {  
        lock.lock();  
        try {  
            long startTime = System.currentTimeMillis();  
            System.out.println("开始往这个buff写入数据…");  
            for (;;)// 模拟要处理很长时间      
            {  
                if (System.currentTimeMillis()  
                        - startTime > Integer.MAX_VALUE) {  
                    break;  
                }  
            }  
            System.out.println("终于写完了");  
        } finally {  
            lock.unlock();  
        }  
    }  

    public void read() throws InterruptedException {  
        lock.lockInterruptibly();// 注意这里，可以响应中断      
        try {  
            System.out.println("从这个buff读数据");  
        } finally {  
            lock.unlock();  
        }  
    }  

    public static void main(String args[]) {  
        BufferInterruptibly buff = new BufferInterruptibly();  

        final Writer2 writer = new Writer2(buff);  
        final Reader2 reader = new Reader2(buff);  

        writer.start();  
        reader.start();  

        new Thread(new Runnable() {  

            @Override  
            public void run() {  
                long start = System.currentTimeMillis();  
                for (;;) {  
                    if (System.currentTimeMillis()  
                            - start > 5000) {  
                        System.out.println("不等了，尝试中断");  
                        reader.interrupt();  //此处中断读操作  
                        break;  
                    }  
                }  
            }  
        }).start();  

    }  
}  

class Reader2 extends Thread {  

    private BufferInterruptibly buff;  

    public Reader2(BufferInterruptibly buff) {  
        this.buff = buff;  
    }  

    @Override  
    public void run() {  

        try {  
            buff.read();//可以收到中断的异常，从而有效退出      
        } catch (InterruptedException e) {  
            System.out.println("我不读了");  
        }  

        System.out.println("读结束");  

    }  
}  

class Writer2 extends Thread {  

    private BufferInterruptibly buff;  

    public Writer2(BufferInterruptibly buff) {  
        this.buff = buff;  
    }  

    @Override  
    public void run() {  
        buff.write();  
    }  

}  
执行结果如下：



从结果中可以看出，尝试中断后输出了 catch 语句块中的内容，也输出了后面的“读结束”，说明线程对互斥锁的等待被中断了，也就是该互斥锁响应了对读线程的中断。

条件变量实现线程间协作
在生产者——消费者模型一文中，我们用 synchronized 实现互斥，并配合使用 Object 对象的 wait（）和 notify()或 notifyAll()方法来实现线程间协作。Java 5 之后，我们可以用 Reentrantlock 锁配合 Condition 对象上的 await()和 signal()或 signalAll()方法来实现线程间协作。在 ReentrantLock 对象上 newCondition()可以得到一个 Condition 对象，可以通过在 Condition 上调用 await()方法来挂起一个任务（线程），通过在 Condition 上调用 signal()来通知任务，从而唤醒一个任务，或者调用 signalAll()来唤醒所有在这个 Condition 上被其自身挂起的任务。另外，如果使用了公平锁，signalAll()的与 Condition 关联的所有任务将以 FIFO 队列的形式获取锁，如果没有使用公平锁，则获取锁的任务是随机的，这样我们便可以更好地控制处在 await 状态的任务获取锁的顺序。与 notifyAll()相比，signalAll()是更安全的方式。另外，它可以指定唤醒与自身 Condition 对象绑定在一起的任务。

下面将生产者——消费者模型一文中的代码改为用条件变量实现，如下：

import java.util.concurrent.*;  
import java.util.concurrent.locks.*;  

class Info{ // 定义信息类  
    private String name = "name";//定义name属性，为了与下面set的name属性区别开  
    private String content = "content" ;// 定义content属性，为了与下面set的content属性区别开  
    private boolean flag = true ;   // 设置标志位,初始时先生产  
    private Lock lock = new ReentrantLock();    
    private Condition condition = lock.newCondition(); //产生一个Condition对象  
    public  void set(String name,String content){  
        lock.lock();  
        try{  
            while(!flag){  
                condition.await() ;  
            }  
            this.setName(name) ;    // 设置名称  
            Thread.sleep(300) ;  
            this.setContent(content) ;  // 设置内容  
            flag  = false ; // 改变标志位，表示可以取走  
            condition.signal();  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }finally{  
            lock.unlock();  
        }  
    }  

    public void get(){  
        lock.lock();  
        try{  
            while(flag){  
                condition.await() ;  
            }     
            Thread.sleep(300) ;  
            System.out.println(this.getName() +   
                " --> " + this.getContent()) ;  
            flag  = true ;  // 改变标志位，表示可以生产  
            condition.signal();  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }finally{  
            lock.unlock();  
        }  
    }  

    public void setName(String name){  
        this.name = name ;  
    }  
    public void setContent(String content){  
        this.content = content ;  
    }  
    public String getName(){  
        return this.name ;  
    }  
    public String getContent(){  
        return this.content ;  
    }  
}  
class Producer implements Runnable{ // 通过Runnable实现多线程  
    private Info info = null ;      // 保存Info引用  
    public Producer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        boolean flag = true ;   // 定义标记位  
        for(int i=0;i<10;i++){  
            if(flag){  
                this.info.set("姓名--1","内容--1") ;    // 设置名称  
                flag = false ;  
            }else{  
                this.info.set("姓名--2","内容--2") ;    // 设置名称  
                flag = true ;  
            }  
        }  
    }  
}  
class Consumer implements Runnable{  
    private Info info = null ;  
    public Consumer(Info info){  
        this.info = info ;  
    }  
    public void run(){  
        for(int i=0;i<10;i++){  
            this.info.get() ;  
        }  
    }  
}  
public class ThreadCaseDemo{  
    public static void main(String args[]){  
        Info info = new Info(); // 实例化Info对象  
        Producer pro = new Producer(info) ; // 生产者  
        Consumer con = new Consumer(info) ; // 消费者  
        new Thread(pro).start() ;  
        //启动了生产者线程后，再启动消费者线程  
        try{  
            Thread.sleep(500) ;  
        }catch(InterruptedException e){  
            e.printStackTrace() ;  
        }  

        new Thread(con).start() ;  
    }  
}  
执行后，同样可以得到如下的结果：

姓名--1 --> 内容--1
姓名--2 --> 内容--2
姓名--1 --> 内容--1
姓名--2 --> 内容--2
姓名--1 --> 内容--1
姓名--2 --> 内容--2
姓名--1 --> 内容--1
姓名--2 --> 内容--2
姓名--1 --> 内容--1
姓名--2 --> 内容--2
从以上并不能看出用条件变量的 await()、signal()、signalAll()方法比用 Object 对象的 wait()、notify()、notifyAll()方法实现线程间协作有多少优点，但它在处理更复杂的多线程问题时，会有明显的优势。所以，Lock 和 Condition 对象只有在更加困难的多线程问题中才是必须的。

读写锁
另外，synchronized 获取的互斥锁不仅互斥读写操作、写写操作，还互斥读读操作，而读读操作时不会带来数据竞争的，因此对对读读操作也互斥的话，会降低性能。Java 5 中提供了读写锁，它将读锁和写锁分离，使得读读操作不互斥，获取读锁和写锁的一般形式如下：

ReadWriteLock rwl = new ReentrantReadWriteLock();      
rwl.writeLock().lock()  //获取写锁  
rwl.readLock().lock()  //获取读锁  
用读锁来锁定读操作，用写锁来锁定写操作，这样写操作和写操作之间会互斥，读操作和写操作之间会互斥，但读操作和读操作就不会互斥。

《Java 并发编程实践》一书给出了使用 ReentrantLock 的最佳时机：

当你需要以下高级特性时，才应该使用：可定时的、可轮询的与可中断的锁获取操作，公平队列，或者非块结构的锁。否则，请使用 synchronized。





并发新特性—阻塞队列与阻塞栈

阻塞队列
阻塞队列是 Java 5 并发新特性中的内容，阻塞队列的接口是 java.util.concurrent.BlockingQueue，它有多个实现类：ArrayBlockingQueue、DelayQueue、LinkedBlockingQueue、PriorityBlockingQueue、SynchronousQueue 等，用法大同小异，具体可查看 JDK 文档，这里简单举例看下 ArrayBlockingQueue，它实现了一个有界队列，当队列满时，便会阻塞等待，直到有元素出队，后续的元素才可以被加入队列。

看下面的例子：

import java.util.concurrent.BlockingQueue;   
import java.util.concurrent.ArrayBlockingQueue;   

public class BlockingQueueTest{   
        public static void main(String[] args) throws InterruptedException {   
                BlockingQueue<String> bqueue = new ArrayBlockingQueue<String>(20);   
                for (int i = 0; i < 30; i++) {   
                        //将指定元素添加到此队列中   
                        bqueue.put("加入元素" + i);   
                        System.out.println("向阻塞队列中添加了元素:" + i);   
                }   
                System.out.println("程序到此运行结束，即将退出----");   
        }   
}  
输出结果如下：



从执行结果中可以看出，由于队列中元素的数量限制在了 20 个，因此添加 20 个元素后，其他元素便在队列外阻塞等待，程序并没有终止。

如果队列已满后，我们将队首元素移出，并可以继续向阻塞队列中添加元素，修改代码如下：

import java.util.concurrent.BlockingQueue;   
import java.util.concurrent.ArrayBlockingQueue;   

public class BlockingQueueTest{   
        public static void main(String[] args) throws InterruptedException {   
                BlockingQueue<String> bqueue = new ArrayBlockingQueue<String>(20);   
                for (int i = 0; i < 30; i++) {   
                        //将指定元素添加到此队列中   
                        bqueue.put("" + i);   
                        System.out.println("向阻塞队列中添加了元素:" + i);   
                        if(i > 18){  
                            //从队列中获取队头元素，并将其移出队列  
                            System.out.println("从阻塞队列中移除元素：" + bqueue.take());  
                        }  
                }   
                System.out.println("程序到此运行结束，即将退出----");   
        }   
}  
执行结果如下：



从结果中可以看出，当添加了第 20 个元素后，我们从队首移出一个元素，这样便可以继续向队列中添加元素，之后每添加一个元素，便从将队首元素移除，这样程序便可以执行结束。

阻塞栈
阻塞栈与阻塞队列相似，只是它是 Java 6 中加入的新特性，阻塞栈的接口java.util.concurrent.BlockingDeque 也有很多实现类，使用方法也比较相似，具体查看 JDK 文档。

下面同样给出一个简单的例子：

import java.util.concurrent.BlockingDeque;   
import java.util.concurrent.LinkedBlockingDeque;   

public class BlockingDequeTest {   
    public static void main(String[] args) throws InterruptedException {   
            BlockingDeque<String> bDeque = new LinkedBlockingDeque<String>(20);   
            for (int i = 0; i < 30; i++) {   
                //将指定元素添加到此阻塞栈中  
                bDeque.putFirst("" + i);   
                System.out.println("向阻塞栈中添加了元素:" + i);   
            }   
            System.out.println("程序到此运行结束，即将退出----");   
    }   
}  
执行结果如下：



程序依然会阻塞等待，我们改为如下代码：

import java.util.concurrent.BlockingDeque;   
import java.util.concurrent.LinkedBlockingDeque;   

public class BlockingDequeTest {   
    public static void main(String[] args) throws InterruptedException {   
            BlockingDeque<String> bDeque = new LinkedBlockingDeque<String>(20);   
            for (int i = 0; i < 30; i++) {   
                //将指定元素添加到此阻塞栈中  
                bDeque.putFirst("" + i);   
                System.out.println("向阻塞栈中添加了元素:" + i);   
                if(i > 18){  
                    //从阻塞栈中取出栈顶元素，并将其移出  
                    System.out.println("从阻塞栈中移出了元素：" + bDeque.pollFirst());  
                }  
            }   
            System.out.println("程序到此运行结束，即将退出----");   
    }   
}  
执行结果如下：



从结果中可以看出，当添加了第 20 个元素后，我们从将栈顶元素移处，这样便可以继续向栈中添加元素，之后每添加一个元素，便将栈顶元素移出，这样程序便可以执行结束。




并发新特性—障碍器 CyclicBarrier

CyclicBarrier（又叫障碍器）同样是 Java 5 中加入的新特性，使用时需要导入java.util.concurrent.CylicBarrier。它适用于这样一种情况：你希望创建一组任务，它们并发地执行工作，另外的一个任务在这一组任务并发执行结束前一直阻塞等待，直到该组任务全部执行结束，这个任务才得以执行。这非常像 CountDownLatch，只是 CountDownLatch 是只触发一次的事件，而 CyclicBarrier 可以多次重用。

下面给出一个简单的实例来说明其用法：

import java.util.concurrent.BrokenBarrierException;   
import java.util.concurrent.CyclicBarrier;   

public class CyclicBarrierTest {   
        public static void main(String[] args) {   
                //创建CyclicBarrier对象，  
                //并设置执行完一组5个线程的并发任务后，再执行MainTask任务  
                CyclicBarrier cb = new CyclicBarrier(5, new MainTask());   
                new SubTask("A", cb).start();   
                new SubTask("B", cb).start();   
                new SubTask("C", cb).start();   
                new SubTask("D", cb).start();   
                new SubTask("E", cb).start();  
        }   
}   

/**  
* 最后执行的任务 
*/   
class MainTask implements Runnable {   
        public void run() {   
                System.out.println("......终于要执行最后的任务了......");   
        }   
}   

/**  
* 一组并发任务  
*/   
class SubTask extends Thread {   
        private String name;   
        private CyclicBarrier cb;   

        SubTask(String name, CyclicBarrier cb) {   
                this.name = name;   
                this.cb = cb;   
        }   

        public void run() {   
                System.out.println("[并发任务" + name + "]  开始执行");   
                for (int i = 0; i < 999999; i++) ;    //模拟耗时的任务   
                System.out.println("[并发任务" + name + "]  开始执行完毕，通知障碍器");   
                try {   
                        //每执行完一项任务就通知障碍器   
                        cb.await();   
                } catch (InterruptedException e) {   
                        e.printStackTrace();   
                } catch (BrokenBarrierException e) {   
                        e.printStackTrace();   
                }   
        }   
}  
某次执行的结果如下：

[并发任务A]  开始执行
[并发任务B]  开始执行
[并发任务D]  开始执行
[并发任务E]  开始执行
[并发任务A]  开始执行完毕，通知障碍器
[并发任务E]  开始执行完毕，通知障碍器
[并发任务D]  开始执行完毕，通知障碍器
[并发任务C]  开始执行
[并发任务B]  开始执行完毕，通知障碍器
[并发任务C]  开始执行完毕，通知障碍器
......终于要执行最后的任务了......
从结果可以看出：MainTask 任务在一组中的 5 个任务执行完后才开始执行。





并发新特性—信号量 Semaphore

在操作系统中，信号量是个很重要的概念，它在控制进程间的协作方面有着非常重要的作用，通过对信号量的不同操作，可以分别实现进程间的互斥与同步。当然它也可以用于多线程的控制，我们完全可以通过使用信号量来自定义实现类似 Java 中的 synchronized、wait、notify 机制。

Java 并发包中的信号量 Semaphore 实际上是一个功能完毕的计数信号量，从概念上讲，它维护了一个许可集合，对控制一定资源的消费与回收有着很重要的意义。Semaphore 可以控制某个资源被同时访问的任务数，它通过acquire()获取一个许可，release()释放一个许可。如果被同时访问的任务数已满，则其他 acquire 的任务进入等待状态，直到有一个任务被 release 掉，它才能得到许可。

下面给出一个采用 Semaphore 控制并发访问数量的示例程序：

import java.util.concurrent.ExecutorService;  
import java.util.concurrent.Executors;  
import java.util.concurrent.Semaphore;  
public class SemaphoreTest{  
    public static void main(String[] args) {  
    //采用新特性来启动和管理线程——内部使用线程池  
    ExecutorService exec = Executors.newCachedThreadPool();  
    //只允许5个线程同时访问  
    final Semaphore semp = new Semaphore(5);  
    //模拟10个客户端访问  
    for (int index = 0; index < 10; index++){  
        final int num = index;  
        Runnable run = new Runnable() {  
            public void run() {  
                try {  
                    //获取许可  
                    semp.acquire();  
                    System.out.println("线程" +   
                        Thread.currentThread().getName() + "获得许可："  + num);  
                    //模拟耗时的任务  
                    for (int i = 0; i < 999999; i++) ;  
                    //释放许可  
                    semp.release();  
                    System.out.println("线程" +   
                        Thread.currentThread().getName() + "释放许可："  + num);  
                    System.out.println("当前允许进入的任务个数：" +  
                        semp.availablePermits());  
                }catch(InterruptedException e){  
                    e.printStackTrace();  
                }  
            }  
        };  
          exec.execute(run);  
    }  
    //关闭线程池  
    exec.shutdown();  
    }  
}  
某次执行的结果如下：

线程pool-1-thread-1获得许可：0
线程pool-1-thread-1释放许可：0
当前允许进入的任务个数：5
线程pool-1-thread-2获得许可：1
线程pool-1-thread-6获得许可：5
线程pool-1-thread-4获得许可：3
线程pool-1-thread-8获得许可：7
线程pool-1-thread-2释放许可：1
当前允许进入的任务个数：2
线程pool-1-thread-5获得许可：4
线程pool-1-thread-8释放许可：7
线程pool-1-thread-3获得许可：2
线程pool-1-thread-4释放许可：3
线程pool-1-thread-10获得许可：9 
线程pool-1-thread-6释放许可：5
线程pool-1-thread-10释放许可：9
当前允许进入的任务个数：2
线程pool-1-thread-3释放许可：2
当前允许进入的任务个数：1
线程pool-1-thread-5释放许可：4
当前允许进入的任务个数：3
线程pool-1-thread-7获得许可：6
线程pool-1-thread-9获得许可：8
线程pool-1-thread-7释放许可：6
当前允许进入的任务个数：5
当前允许进入的任务个数：3
当前允许进入的任务个数：3
当前允许进入的任务个数：3
线程pool-1-thread-9释放许可：8
当前允许进入的任务个数：5
可以看出，Semaphore 允许并发访问的任务数一直为 5，当然，这里还很容易看出一点，就是 Semaphore 仅仅是对资源的并发访问的任务数进行监控，而不会保证线程安全，因此，在访问的时候，要自己控制线程的安全访问。









线程安全与共享资源

允许被多个线程同时执行的代码称作线程安全的代码。线程安全的代码不包含竞态条件。当多个线程同时更新共享资源时会引发竞态条件。因此，了解 Java 线程执行时共享了什么资源很重要。

局部变量
局部变量存储在线程自己的栈中。也就是说，局部变量永远也不会被多个线程共享。所以，基础类型的局部变量是线程安全的。下面是基础类型的局部变量的一个例子：

public void someMethod(){

  long threadSafeInt = 0;

  threadSafeInt++;
}
局部的对象引用
对象的局部引用和基础类型的局部变量不太一样。尽管引用本身没有被共享，但引用所指的对象并没有存储在线程的栈内。所有的对象都存在共享堆中。如果在某个方法中创建的对象不会逃逸出（译者注：即该对象不会被其它方法获得，也不会被非局部变量引用到）该方法，那么它就是线程安全的。实际上，哪怕将这个对象作为参数传给其它方法，只要别的线程获取不到这个对象，那它仍是线程安全的。下面是一个线程安全的局部引用样例：

public void someMethod(){

  LocalObject localObject = new LocalObject();

  localObject.callMethod();
  method2(localObject);
}

public void method2(LocalObject localObject){
  localObject.setValue("value");
}
样例中 LocalObject 对象没有被方法返回，也没有被传递给 someMethod()方法外的对象。每个执行 someMethod()的线程都会创建自己的 LocalObject 对象，并赋值给 localObject 引用。因此，这里的 LocalObject 是线程安全的。事实上，整个 someMethod()都是线程安全的。即使将 LocalObject 作为参数传给同一个类的其它方法或其它类的方法时，它仍然是线程安全的。当然，如果 LocalObject 通过某些方法被传给了别的线程，那它就不再是线程安全的了。

对象成员
对象成员存储在堆上。如果两个线程同时更新同一个对象的同一个成员，那这个代码就不是线程安全的。下面是一个样例：

public class NotThreadSafe{
    StringBuilder builder = new StringBuilder();

    public add(String text){
        this.builder.append(text);
    }    
}
如果两个线程同时调用同一个 NotThreadSafe 实例上的 add()方法，就会有竞态条件问题。例如：

NotThreadSafe sharedInstance = new NotThreadSafe();

new Thread(new MyRunnable(sharedInstance)).start();
new Thread(new MyRunnable(sharedInstance)).start();

public class MyRunnable implements Runnable{
  NotThreadSafe instance = null;

  public MyRunnable(NotThreadSafe instance){
    this.instance = instance;
  }

  public void run(){
    this.instance.add("some text");
  }
}
注意两个 MyRunnable 共享了同一个 NotThreadSafe 对象。因此，当它们调用 add()方法时会造成竞态条件。

当然，如果这两个线程在不同的 NotThreadSafe 实例上调用 call()方法，就不会导致竞态条件。下面是稍微修改后的例子：

new Thread(new MyRunnable(new NotThreadSafe())).start();
new Thread(new MyRunnable(new NotThreadSafe())).start();
现在两个线程都有自己单独的 NotThreadSafe 对象，调用 add()方法时就会互不干扰，再也不会有竞态条件问题了。所以非线程安全的对象仍可以通过某种方式来消除竞态条件。

线程控制逃逸规则
线程控制逃逸规则可以帮助你判断代码中对某些资源的访问是否是线程安全的。

如果一个资源的创建，使用，销毁都在同一个线程内完成，
且永远不会脱离该线程的控制，则该资源的使用就是线程安全的。
资源可以是对象，数组，文件，数据库连接，套接字等等。Java 中你无需主动销毁对象，所以“销毁”指不再有引用指向对象。

即使对象本身线程安全，但如果该对象中包含其他资源（文件，数据库连接），整个应用也许就不再是线程安全的了。比如 2 个线程都创建了各自的数据库连接，每个连接自身是线程安全的，但它们所连接到的同一个数据库也许不是线程安全的。比如，2 个线程执行如下代码：

检查记录 X 是否存在，如果不存在，插入 X
如果两个线程同时执行，而且碰巧检查的是同一个记录，那么两个线程最终可能都插入了记录：

线程 1 检查记录 X 是否存在。检查结果：不存在
线程 2 检查记录 X 是否存在。检查结果：不存在
线程 1 插入记录 X
线程 2 插入记录 X
同样的问题也会发生在文件或其他共享资源上。因此，区分某个线程控制的对象是资源本身，还是仅仅到某个资源的引用很重要。



线程安全及不可变性

当多个线程同时访问同一个资源，并且其中的一个或者多个线程对这个资源进行了写操作，才会产生竞态条件。多个线程同时读同一个资源不会产生竞态条件。

我们可以通过创建不可变的共享对象来保证对象在线程间共享时不会被修改，从而实现线程安全。如下示例：

public class ImmutableValue{
    private int value = 0;

    public ImmutableValue(int value){
        this.value = value;
    }

    public int getValue(){
        return this.value;
    }
}
请注意 ImmutableValue 类的成员变量 value 是通过构造函数赋值的，并且在类中没有 set 方法。这意味着一旦 ImmutableValue 实例被创建，value 变量就不能再被修改，这就是不可变性。但你可以通过 getValue()方法读取这个变量的值。

（译者注：注意，“不变”（Immutable）和“只读”（Read Only）是不同的。当一个变量是“只读”时，变量的值不能直接改变，但是可以在其它变量发生改变的时候发生改变。比如，一个人的出生年月日是“不变”属性，而一个人的年龄便是“只读”属性，但是不是“不变”属性。随着时间的变化，一个人的年龄会随之发生变化，而一个人的出生年月日则不会变化。这就是“不变”和“只读”的区别。（摘自《Java 与模式》第 34 章））

如果你需要对 ImmutableValue 类的实例进行操作，可以通过得到 value 变量后创建一个新的实例来实现，下面是一个对 value 变量进行加法操作的示例：

public class ImmutableValue{
    private int value = 0;

    public ImmutableValue(int value){
        this.value = value;
    }

    public int getValue(){
        return this.value;
    }

    public ImmutableValue add(int valueToAdd){
        return new ImmutableValue(this.value + valueToAdd);
    }
}
请注意 add()方法以加法操作的结果作为一个新的 ImmutableValue 类实例返回，而不是直接对它自己的 value 变量进行操作。

引用不是线程安全的！
重要的是要记住，即使一个对象是线程安全的不可变对象，指向这个对象的引用也可能不是线程安全的。看这个例子：

public void Calculator{
    private ImmutableValue currentValue = null;

    public ImmutableValue getValue(){
        return currentValue;
    }

    public void setValue(ImmutableValue newValue){
        this.currentValue = newValue;
    }

    public void add(int newValue){
        this.currentValue = this.currentValue.add(newValue);
    }
}
Calculator 类持有一个指向 ImmutableValue 实例的引用。注意，通过 setValue()方法和 add()方法可能会改变这个引用。因此，即使 Calculator 类内部使用了一个不可变对象，但 Calculator 类本身还是可变的，因此 Calculator 类不是线程安全的。换句话说：ImmutableValue 类是线程安全的，但使用它的类不是。当尝试通过不可变性去获得线程安全时，这点是需要牢记的。

要使 Calculator 类实现线程安全，将 getValue()、setValue()和 add()方法都声明为同步方法即可。




Java 内存模型

Java 内存模型规范了 Java 虚拟机与计算机内存是如何协同工作的。Java 虚拟机是一个完整的计算机的一个模型，因此这个模型自然也包含一个内存模型——又称为 Java 内存模型。

如果你想设计表现良好的并发程序，理解 Java 内存模型是非常重要的。Java 内存模型规定了如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量。

原始的 Java 内存模型存在一些不足，因此 Java 内存模型在 Java1.5 时被重新修订。这个版本的 Java 内存模型在 Java8 中人在使用。

Java 内存模型内部原理
Java 内存模型把 Java 虚拟机内部划分为线程栈和堆。这张图演示了 Java 内存模型的逻辑视图。



每一个运行在 Java 虚拟机里的线程都拥有自己的线程栈。这个线程栈包含了这个线程调用的方法当前执行点相关的信息。一个线程仅能访问自己的线程栈。一个线程创建的本地变量对其它线程不可见，仅自己可见。即使两个线程执行同样的代码，这两个线程任然在在自己的线程栈中的代码来创建本地变量。因此，每个线程拥有每个本地变量的独有版本。

所有原始类型的本地变量都存放在线程栈上，因此对其它线程不可见。一个线程可能向另一个线程传递一个原始类型变量的拷贝，但是它不能共享这个原始类型变量自身。

堆上包含在 Java 程序中创建的所有对象，无论是哪一个对象创建的。这包括原始类型的对象版本。如果一个对象被创建然后赋值给一个局部变量，或者用来作为另一个对象的成员变量，这个对象任然是存放在堆上。

下面这张图演示了调用栈和本地变量存放在线程栈上，对象存放在堆上。



一个本地变量可能是原始类型，在这种情况下，它总是“呆在”线程栈上。

一个本地变量也可能是指向一个对象的一个引用。在这种情况下，引用（这个本地变量）存放在线程栈上，但是对象本身存放在堆上。

一个对象可能包含方法，这些方法可能包含本地变量。这些本地变量任然存放在线程栈上，即使这些方法所属的对象存放在堆上。

一个对象的成员变量可能随着这个对象自身存放在堆上。不管这个成员变量是原始类型还是引用类型。

静态成员变量跟随着类定义一起也存放在堆上。

存放在堆上的对象可以被所有持有对这个对象引用的线程访问。当一个线程可以访问一个对象时，它也可以访问这个对象的成员变量。如果两个线程同时调用同一个对象上的同一个方法，它们将会都访问这个对象的成员变量，但是每一个线程都拥有这个本地变量的私有拷贝。

下图演示了上面提到的点：



两个线程拥有一些列的本地变量。其中一个本地变量（Local Variable 2）执行堆上的一个共享对象（Object 3）。这两个线程分别拥有同一个对象的不同引用。这些引用都是本地变量，因此存放在各自线程的线程栈上。这两个不同的引用指向堆上同一个对象。

注意，这个共享对象（Object 3）持有 Object2 和 Object4 一个引用作为其成员变量（如图中 Object3 指向 Object2 和 Object4 的箭头）。通过在 Object3 中这些成员变量引用，这两个线程就可以访问 Object2 和 Object4。

这张图也展示了指向堆上两个不同对象的一个本地变量。在这种情况下，指向两个不同对象的引用不是同一个对象。理论上，两个线程都可以访问 Object1 和 Object5，如果两个线程都拥有两个对象的引用。但是在上图中，每一个线程仅有一个引用指向两个对象其中之一。

因此，什么类型的 Java 代码会导致上面的内存图呢？如下所示：

public class MyRunnable implements Runnable() {

    public void run() {
        methodOne();
    }

    public void methodOne() {
        int localVariable1 = 45;

        MySharedObject localVariable2 =
            MySharedObject.sharedInstance;

        //... do more with local variables.

        methodTwo();
    }

    public void methodTwo() {
        Integer localVariable1 = new Integer(99);

        //... do more with local variable.
    }
}

public class MySharedObject {

    //static variable pointing to instance of MySharedObject

    public static final MySharedObject sharedInstance =
        new MySharedObject();

    //member variables pointing to two objects on the heap

    public Integer object2 = new Integer(22);
    public Integer object4 = new Integer(44);

    public long member1 = 12345;
    public long member1 = 67890;
}
如果两个线程同时执行 run()方法，就会出现上图所示的情景。run()方法调用 methodOne()方法，methodOne()调用 methodTwo()方法。

methodOne()声明了一个原始类型的本地变量和一个引用类型的本地变量。

每个线程执行 methodOne()都会在它们对应的线程栈上创建 localVariable1 和 localVariable2 的私有拷贝。localVariable1 变量彼此完全独立，仅“生活”在每个线程的线程栈上。一个线程看不到另一个线程对它的 localVariable1 私有拷贝做出的修改。

每个线程执行 methodOne()时也将会创建它们各自的 localVariable2 拷贝。然而，两个 localVariable2 的不同拷贝都指向堆上的同一个对象。代码中通过一个静态变量设置 localVariable2 指向一个对象引用。仅存在一个静态变量的一份拷贝，这份拷贝存放在堆上。因此，localVariable2 的两份拷贝都指向由 MySharedObject 指向的静态变量的同一个实例。MySharedObject 实例也存放在堆上。它对应于上图中的 Object3。

注意，MySharedObject 类也包含两个成员变量。这些成员变量随着这个对象存放在堆上。这两个成员变量指向另外两个 Integer 对象。这些 Integer 对象对应于上图中的 Object2 和 Object4.

注意，methodTwo()创建一个名为 localVariable 的本地变量。这个成员变量是一个指向一个 Integer 对象的对象引用。这个方法设置 localVariable1 引用指向一个新的 Integer 实例。在执行 methodTwo 方法时，localVariable1 引用将会在每个线程中存放一份拷贝。这两个 Integer 对象实例化将会被存储堆上，但是每次执行这个方法时，这个方法都会创建一个新的 Integer 对象，两个线程执行这个方法将会创建两个不同的 Integer 实例。methodTwo 方法创建的 Integer 对象对应于上图中的 Object1 和 Object5。

还有一点，MySharedObject 类中的两个 long 类型的成员变量是原始类型的。因为，这些变量是成员变量，所以它们任然随着该对象存放在堆上，仅有本地变量存放在线程栈上。

硬件内存架构
现代硬件内存模型与 Java 内存模型有一些不同。理解内存模型架构以及 Java 内存模型如何与它协同工作也是非常重要的。这部分描述了通用的硬件内存架构，下面的部分将会描述 Java 内存是如何与它“联手”工作的。

下面是现代计算机硬件架构的简单图示：



一个现代计算机通常由两个或者多个 CPU。其中一些 CPU 还有多核。从这一点可以看出，在一个有两个或者多个 CPU 的现代计算机上同时运行多个线程是可能的。每个 CPU 在某一时刻运行一个线程是没有问题的。这意味着，如果你的 Java 程序是多线程的，在你的 Java 程序中每个 CPU 上一个线程可能同时（并发）执行。

每个 CPU 都包含一系列的寄存器，它们是 CPU 内内存的基础。CPU 在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为 CPU 访问寄存器的速度远大于主存。

每个 CPU 可能还有一个 CPU 缓存层。实际上，绝大多数的现代 CPU 都有一定大小的缓存层。CPU 访问缓存层的速度快于访问主存的速度，但通常比访问内部寄存器的速度还要慢一点。一些 CPU 还有多层缓存，但这些对理解 Java 内存模型如何和内存交互不是那么重要。只要知道 CPU 中可以有一个缓存层就可以了。

一个计算机还包含一个主存。所有的 CPU 都可以访问主存。主存通常比 CPU 中的缓存大得多。

通常情况下，当一个 CPU 需要读取主存时，它会将主存的部分读到 CPU 缓存中。它甚至可能将缓存中的部分内容读到它的内部寄存器中，然后在寄存器中执行操作。当 CPU 需要将结果写回到主存中去时，它会将内部寄存器的值刷新到缓存中，然后在某个时间点将值刷新回主存。

当 CPU 需要在缓存层存放一些东西的时候，存放在缓存中的内容通常会被刷新回主存。CPU 缓存可以在某一时刻将数据局部写到它的内存中，和在某一时刻局部刷新它的内存。它不会再某一时刻读/写整个缓存。通常，在一个被称作“cache lines”的更小的内存块中缓存被更新。一个或者多个缓存行可能被读到缓存，一个或者多个缓存行可能再被刷新回主存。

Java 内存模型和硬件内存架构之间的桥接
上面已经提到，Java 内存模型与硬件内存架构之间存在差异。硬件内存架构没有区分线程栈和堆。对于硬件，所有的线程栈和堆都分布在主内中。部分线程栈和堆可能有时候会出现在 CPU 缓存中和 CPU 内部的寄存器中。如下图所示：



当对象和变量被存放在计算机中各种不同的内存区域中时，就可能会出现一些具体的问题。主要包括如下两个方面：

线程对共享变量修改的可见性
当读，写和检查共享变量时出现 race conditions
下面我们专门来解释以下这两个问题。

共享对象可见性

如果两个或者更多的线程在没有正确的使用 volatile 声明或者同步的情况下共享一个对象，一个线程更新这个共享对象可能对其它线程来说是不接见的。

想象一下，共享对象被初始化在主存中。跑在 CPU 上的一个线程将这个共享对象读到 CPU 缓存中。然后修改了这个对象。只要 CPU 缓存没有被刷新会主存，对象修改后的版本对跑在其它 CPU 上的线程都是不可见的。这种方式可能导致每个线程拥有这个共享对象的私有拷贝，每个拷贝停留在不同的 CPU 缓存中。

下图示意了这种情形。跑在左边 CPU 的线程拷贝这个共享对象到它的 CPU 缓存中，然后将 count 变量的值修改为 2。这个修改对跑在右边 CPU 上的其它线程是不可见的，因为修改后的 count 的值还没有被刷新回主存中去。



解决这个问题你可以使用 Java 中的 volatile 关键字。volatile 关键字可以保证直接从主存中读取一个变量，如果这个变量被修改后，总是会被写回到主存中去。

Race Conditions

如果两个或者更多的线程共享一个对象，多个线程在这个共享对象上更新变量，就有可能发生 race conditions。

想象一下，如果线程 A 读一个共享对象的变量 count 到它的 CPU 缓存中。再想象一下，线程 B 也做了同样的事情，但是往一个不同的 CPU 缓存中。现在线程 A 将 count 加 1，线程 B 也做了同样的事情。现在 count 已经被增在了两个，每个 CPU 缓存中一次。

如果这些增加操作被顺序的执行，变量 count 应该被增加两次，然后原值+2 被写回到主存中去。

然而，两次增加都是在没有适当的同步下并发执行的。无论是线程 A 还是线程 B 将 count 修改后的版本写回到主存中取，修改后的值仅会被原值大 1，尽管增加了两次。

下图演示了上面描述的情况：



解决这个问题可以使用 Java 同步块。一个同步块可以保证在同一时刻仅有一个线程可以进入代码的临界区。同步块还可以保证代码块中所有被访问的变量将会从主存中读入，当线程退出同步代码块时，所有被更新的变量都会被刷新回主存中去，不管这个变量是否被声明为 volatile。






并发编程模型

并发系统可以采用多种并发编程模型来实现。并发模型指定了系统中的线程如何通过协作来完成分配给它们的作业。不同的并发模型采用不同的方式拆分作业，同时线程间的协作和交互方式也不相同。这篇并发模型教程将会较深入地介绍目前（2015 年，本文撰写时间）比较流行的几种并发模型。

并发模型与分布式系统之间的相似性
本文所描述的并发模型类似于分布式系统中使用的很多体系结构。在并发系统中线程之间可以相互通信。在分布式系统中进程之间也可以相互通信（进程有可能在不同的机器中）。线程和进程之间具有很多相似的特性。这也就是为什么很多并发模型通常类似于各种分布式系统架构。

当然，分布式系统在处理网络失效、远程主机或进程宕掉等方面也面临着额外的挑战。但是运行在巨型服务器上的并发系统也可能遇到类似的问题，比如一块 CPU 失效、一块网卡失效或一个磁盘损坏等情况。虽然出现失效的概率可能很低，但是在理论上仍然有可能发生。

由于并发模型类似于分布式系统架构，因此它们通常可以互相借鉴思想。例如，为工作者们（线程）分配作业的模型一般与分布式系统中的负载均衡系统比较相似。同样，它们在日志记录、失效转移、幂等性等错误处理技术上也具有相似性。

【注：幂等性，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同】

并行工作者
第一种并发模型就是我所说的并行工作者模型。传入的作业会被分配到不同的工作者上。下图展示了并行工作者模型：



在并行工作者模型中，委派者（Delegator）将传入的作业分配给不同的工作者。每个工作者完成整个任务。工作者们并行运作在不同的线程上，甚至可能在不同的 CPU 上。

如果在某个汽车厂里实现了并行工作者模型，每台车都会由一个工人来生产。工人们将拿到汽车的生产规格，并且从头到尾负责所有工作。

在 Java 应用系统中，并行工作者模型是最常见的并发模型（即使正在转变）。java.util.concurrent包中的许多并发实用工具都是设计用于这个模型的。你也可以在 Java 企业级（J2EE）应用服务器的设计中看到这个模型的踪迹。

并行工作者模型的优点

并行工作者模式的优点是，它很容易理解。你只需添加更多的工作者来提高系统的并行度。

例如，如果你正在做一个网络爬虫，可以试试使用不同数量的工作者抓取到一定数量的页面，然后看看多少数量的工作者消耗的时间最短（意味着性能最高）。由于网络爬虫是一个 IO 密集型工作，最终结果很有可能是你电脑中的每个 CPU 或核心分配了几个线程。每个 CPU 若只分配一个线程可能有点少，因为在等待数据下载的过程中 CPU 将会空闲大量时间。

并行工作者模型的缺点
并行工作者模型虽然看起来简单，却隐藏着一些缺点。接下来的章节中我会分析一些最明显的弱点。

共享状态可能会很复杂

在实际应用中，并行工作者模型可能比前面所描述的情况要复杂得多。共享的工作者经常需要访问一些共享数据，无论是内存中的或者共享的数据库中的。下图展示了并行工作者模型是如何变得复杂的：



有些共享状态是在像作业队列这样的通信机制下。但也有一些共享状态是业务数据，数据缓存，数据库连接池等。

一旦共享状态潜入到并行工作者模型中，将会使情况变得复杂起来。线程需要以某种方式存取共享数据，以确保某个线程的修改能够对其他线程可见（数据修改需要同步到主存中，不仅仅将数据保存在执行这个线程的CPU的缓存中）。线程需要避免竟态，死锁以及很多其他共享状态的并发性问题。

此外，在等待访问共享数据结构时，线程之间的互相等待将会丢失部分并行性。许多并发数据结构是阻塞的，意味着在任何一个时间只有一个或者很少的线程能够访问。这样会导致在这些共享数据结构上出现竞争状态。在执行需要访问共享数据结构部分的代码时，高竞争基本上会导致执行时出现一定程度的串行化。

现在的非阻塞并发算法也许可以降低竞争并提升性能，但是非阻塞算法的实现比较困难。

可持久化的数据结构是另一种选择。在修改的时候，可持久化的数据结构总是保护它的前一个版本不受影响。因此，如果多个线程指向同一个可持久化的数据结构，并且其中一个线程进行了修改，进行修改的线程会获得一个指向新结构的引用。所有其他线程保持对旧结构的引用，旧结构没有被修改并且因此保证一致性。Scala 编程包含几个持久化数据结构。

【注：这里的可持久化数据结构不是指持久化存储，而是一种数据结构，比如 Java 中的 String 类，以及 CopyOnWriteArrayList 类，具体可参考】

虽然可持久化的数据结构在解决共享数据结构的并发修改时显得很优雅，但是可持久化的数据结构的表现往往不尽人意。

比如说，一个可持久化的链表需要在头部插入一个新的节点，并且返回指向这个新加入的节点的一个引用（这个节点指向了链表的剩余部分）。所有其他现场仍然保留了这个链表之前的第一个节点，对于这些线程来说链表仍然是为改变的。它们无法看到新加入的元素。

这种可持久化的列表采用链表来实现。不幸的是链表在现代硬件上表现的不太好。链表中得每个元素都是一个独立的对象，这些对象可以遍布在整个计算机内存中。现代 CPU 能够更快的进行顺序访问，所以你可以在现代的硬件上用数组实现的列表，以获得更高的性能。数组可以顺序的保存数据。CPU 缓存能够一次加载数组的一大块进行缓存，一旦加载完成 CPU 就可以直接访问缓存中的数据。这对于元素散落在 RAM 中的链表来说，不太可能做得到。

无状态的工作者

共享状态能够被系统中得其他线程修改。所以工作者在每次需要的时候必须重读状态，以确保每次都能访问到最新的副本，不管共享状态是保存在内存中的还是在外部数据库中。工作者无法在内部保存这个状态（但是每次需要的时候可以重读）称为无状态的。

每次都重读需要的数据，将会导致速度变慢，特别是状态保存在外部数据库中的时候。

任务顺序是不确定的

并行工作者模式的另一个缺点是，作业执行顺序是不确定的。无法保证哪个作业最先或者最后被执行。作业 A 可能在作业 B 之前就被分配工作者了，但是作业 B 反而有可能在作业A之前执行。

并行工作者模式的这种非确定性的特性，使得很难在任何特定的时间点推断系统的状态。这也使得它也更难（如果不是不可能的话）保证一个作业在其他作业之前被执行。

流水线模式
第二种并发模型我们称之为流水线并发模型。我之所以选用这个名字，只是为了配合“并行工作者”的隐喻。其他开发者可能会根据平台或社区选择其他称呼（比如说反应器系统，或事件驱动系统）。下图表示一个流水线并发模型：



类似于工厂中生产线上的工人们那样组织工作者。每个工作者只负责作业中的部分工作。当完成了自己的这部分工作时工作者会将作业转发给下一个工作者。每个工作者在自己的线程中运行，并且不会和其他工作者共享状态。有时也被成为无共享并行模型。

通常使用非阻塞的 IO 来设计使用流水线并发模型的系统。非阻塞 IO 意味着，一旦某个工作者开始一个 IO 操作的时候（比如读取文件或从网络连接中读取数据），这个工作者不会一直等待 IO 操作的结束。IO 操作速度很慢，所以等待 IO 操作结束很浪费 CPU 时间。此时 CPU 可以做一些其他事情。当 IO 操作完成的时候，IO 操作的结果（比如读出的数据或者数据写完的状态）被传递给下一个工作者。

有了非阻塞 IO，就可以使用 IO 操作确定工作者之间的边界。工作者会尽可能多运行直到遇到并启动一个 IO 操作。然后交出作业的控制权。当 IO 操作完成的时候，在流水线上的下一个工作者继续进行操作，直到它也遇到并启动一个 IO 操作。



在实际应用中，作业有可能不会沿着单一流水线进行。由于大多数系统可以执行多个作业，作业从一个工作者流向另一个工作者取决于作业需要做的工作。在实际中可能会有多个不同的虚拟流水线同时运行。这是现实当中作业在流水线系统中可能的移动情况：



作业甚至也有可能被转发到超过一个工作者上并发处理。比如说，作业有可能被同时转发到作业执行器和作业日志器。下图说明了三条流水线是如何通过将作业转发给同一个工作者（中间流水线的最后一个工作者）来完成作业:



流水线有时候比这个情况更加复杂。

反应器，事件驱动系统

采用流水线并发模型的系统有时候也称为反应器系统或事件驱动系统。系统内的工作者对系统内出现的事件做出反应，这些事件也有可能来自于外部世界或者发自其他工作者。事件可以是传入的 HTTP 请求，也可以是某个文件成功加载到内存中等。在写这篇文章的时候，已经有很多有趣的反应器/事件驱动平台可以使用了，并且不久的将来会有更多。比较流行的似乎是这几个：

Vert.x
AKKa
Node.JS(JavaScript)
我个人觉得 Vert.x 是相当有趣的（特别是对于我这样使用 Java/JVM 的人来说）

Actors 和 Channels

Actors 和 channels 是两种比较类似的流水线（或反应器/事件驱动）模型。

在 Actor 模型中每个工作者被称为 actor。Actor 之间可以直接异步地发送和处理消息。Actor 可以被用来实现一个或多个像前文描述的那样的作业处理流水线。下图给出了 Actor 模型：



而在 Channel 模型中，工作者之间不直接进行通信。相反，它们在不同的通道中发布自己的消息（事件）。其他工作者们可以在这些通道上监听消息，发送者无需知道谁在监听。下图给出了 Channel 模型：



在写这篇文章的时候，channel 模型对于我来说似乎更加灵活。一个工作者无需知道谁在后面的流水线上处理作业。只需知道作业（或消息等）需要转发给哪个通道。通道上的监听者可以随意订阅或者取消订阅，并不会影响向这个通道发送消息的工作者。这使得工作者之间具有松散的耦合。

流水线模型的优点
相比并行工作者模型，流水线并发模型具有几个优点，在接下来的章节中我会介绍几个最大的优点。

无需共享的状态

工作者之间无需共享状态，意味着实现的时候无需考虑所有因并发访问共享对象而产生的并发性问题。这使得在实现工作者的时候变得非常容易。在实现工作者的时候就好像是单个线程在处理工作-基本上是一个单线程的实现。

有状态的工作者

当工作者知道了没有其他线程可以修改它们的数据，工作者可以变成有状态的。对于有状态，我是指，它们可以在内存中保存它们需要操作的数据，只需在最后将更改写回到外部存储系统。因此，有状态的工作者通常比无状态的工作者具有更高的性能。

较好的硬件整合（Hardware Conformity）

单线程代码在整合底层硬件的时候往往具有更好的优势。首先，当能确定代码只在单线程模式下执行的时候，通常能够创建更优化的数据结构和算法。

其次，像前文描述的那样，单线程有状态的工作者能够在内存中缓存数据。在内存中缓存数据的同时，也意味着数据很有可能也缓存在执行这个线程的 CPU 的缓存中。这使得访问缓存的数据变得更快。

我说的硬件整合是指，以某种方式编写的代码，使得能够自然地受益于底层硬件的工作原理。有些开发者称之为 mechanical sympathy。我更倾向于硬件整合这个术语，因为计算机只有很少的机械部件，并且能够隐喻“更好的匹配（match better）”，相比“同情（sympathy）”这个词在上下文中的意思，我觉得“conform”这个词表达的非常好。当然了，这里有点吹毛求疵了，用自己喜欢的术语就行。

合理的作业顺序

基于流水线并发模型实现的并发系统，在某种程度上是有可能保证作业的顺序的。作业的有序性使得它更容易地推出系统在某个特定时间点的状态。更进一步，你可以将所有到达的作业写入到日志中去。一旦这个系统的某一部分挂掉了，该日志就可以用来重头开始重建系统当时的状态。按照特定的顺序将作业写入日志，并按这个顺序作为有保障的作业顺序。下图展示了一种可能的设计：



实现一个有保障的作业顺序是不容易的，但往往是可行的。如果可以，它将大大简化一些任务，例如备份、数据恢复、数据复制等，这些都可以通过日志文件来完成。

流水线模型的缺点
流水线并发模型最大的缺点是作业的执行往往分布到多个工作者上，并因此分布到项目中的多个类上。这样导致在追踪某个作业到底被什么代码执行时变得困难。

同样，这也加大了代码编写的难度。有时会将工作者的代码写成回调处理的形式。若在代码中嵌入过多的回调处理，往往会出现所谓的回调地狱（callback hell）现象。所谓回调地狱，就是意味着在追踪代码在回调过程中到底做了什么，以及确保每个回调只访问它需要的数据的时候，变得非常困难

使用并行工作者模型可以简化这个问题。你可以打开工作者的代码，从头到尾优美的阅读被执行的代码。当然并行工作者模式的代码也可能同样分布在不同的类中，但往往也能够很容易的从代码中分析执行的顺序。

函数式并行（Functional Parallelism）
第三种并发模型是函数式并行模型，这是也最近（2015）讨论的比较多的一种模型。函数式并行的基本思想是采用函数调用实现程序。函数可以看作是”代理人（agents）“或者”actor“，函数之间可以像流水线模型（AKA 反应器或者事件驱动系统）那样互相发送消息。某个函数调用另一个函数，这个过程类似于消息发送。

函数都是通过拷贝来传递参数的，所以除了接收函数外没有实体可以操作数据。这对于避免共享数据的竞态来说是很有必要的。同样也使得函数的执行类似于原子操作。每个函数调用的执行独立于任何其他函数的调用。

一旦每个函数调用都可以独立的执行，它们就可以分散在不同的 CPU 上执行了。这也就意味着能够在多处理器上并行的执行使用函数式实现的算法。

Java7 中的 java.util.concurrent 包里包含的 ForkAndJoinPool 能够帮助我们实现类似于函数式并行的一些东西。而 Java8 中并行 streams 能够用来帮助我们并行的迭代大型集合。记住有些开发者对 ForkAndJoinPool 进行了批判（你可以在我的 ForkAndJoinPool 教程里面看到批评的链接）。

函数式并行里面最难的是确定需要并行的那个函数调用。跨 CPU 协调函数调用需要一定的开销。某个函数完成的工作单元需要达到某个大小以弥补这个开销。如果函数调用作用非常小，将它并行化可能比单线程、单 CPU 执行还慢。

我个人认为（可能不太正确），你可以使用反应器或者事件驱动模型实现一个算法，像函数式并行那样的方法实现工作的分解。使用事件驱动模型可以更精确的控制如何实现并行化（我的观点）。

此外，将任务拆分给多个 CPU 时协调造成的开销，仅仅在该任务是程序当前执行的唯一任务时才有意义。但是，如果当前系统正在执行多个其他的任务时（比如 web 服务器，数据库服务器或者很多其他类似的系统），将单个任务进行并行化是没有意义的。不管怎样计算机中的其他 CPU 们都在忙于处理其他任务，没有理由用一个慢的、函数式并行的任务去扰乱它们。使用流水线（反应器）并发模型可能会更好一点，因为它开销更小（在单线程模式下顺序执行）同时能更好的与底层硬件整合。

使用那种并发模型最好？
所以，用哪种并发模型更好呢?

通常情况下，这个答案取决于你的系统打算做什么。如果你的作业本身就是并行的、独立的并且没有必要共享状态，你可能会使用并行工作者模型去实现你的系统。虽然许多作业都不是自然并行和独立的。对于这种类型的系统，我相信使用流水线并发模型能够更好的发挥它的优势，而且比并行工作者模型更有优势。

你甚至不用亲自编写所有流水线模型的基础结构。像 Vert.x 这种现代化的平台已经为你实现了很多。我也会去为探索如何设计我的下一个项目，使它运行在像 Vert.x 这样的优秀平台上。我感觉 Java EE 已经没有任何优势了。





线程通信

线程通信的目标是使线程间能够互相发送信号。另一方面，线程通信使线程能够等待其他线程的信号。

例如，线程 B 可以等待线程 A 的一个信号，这个信号会通知线程 B 数据已经准备好了。本文将讲解以下几个 JAVA 线程间通信的主题：

通过共享对象通信
忙等待
wait()，notify()和 notifyAll()
丢失的信号
假唤醒
多线程等待相同信号
不要对常量字符串或全局对象调用 wait()
通过共享对象通信
线程间发送信号的一个简单方式是在共享对象的变量里设置信号值。线程 A 在一个同步块里设置 boolean 型成员变量 hasDataToProcess 为 true，线程 B 也在同步块里读取 hasDataToProcess 这个成员变量。这个简单的例子使用了一个持有信号的对象，并提供了 set 和 check 方法:

public class MySignal{

  protected boolean hasDataToProcess = false;

  public synchronized boolean hasDataToProcess(){
    return this.hasDataToProcess;
  }

  public synchronized void setHasDataToProcess(boolean hasData){
    this.hasDataToProcess = hasData;
  }

}
线程 A 和 B 必须获得指向一个 MySignal 共享实例的引用，以便进行通信。如果它们持有的引用指向不同的 MySingal 实例，那么彼此将不能检测到对方的信号。需要处理的数据可以存放在一个共享缓存区里，它和 MySignal 实例是分开存放的。

忙等待(Busy Wait)
准备处理数据的线程 B 正在等待数据变为可用。换句话说，它在等待线程 A 的一个信号，这个信号使 hasDataToProcess()返回 true。线程 B 运行在一个循环里，以等待这个信号：

protected MySignal sharedSignal = ...

...

while(!sharedSignal.hasDataToProcess()){
  //do nothing... busy waiting
}
wait()，notify()和 notifyAll()
忙等待没有对运行等待线程的 CPU 进行有效的利用，除非平均等待时间非常短。否则，让等待线程进入睡眠或者非运行状态更为明智，直到它接收到它等待的信号。

Java 有一个内建的等待机制来允许线程在等待信号的时候变为非运行状态。java.lang.Object 类定义了三个方法，wait()、notify()和 notifyAll()来实现这个等待机制。

一个线程一旦调用了任意对象的 wait()方法，就会变为非运行状态，直到另一个线程调用了同一个对象的 notify()方法。为了调用 wait()或者 notify()，线程必须先获得那个对象的锁。也就是说，线程必须在同步块里调用 wait()或者 notify()。以下是 MySingal 的修改版本——使用了 wait()和 notify()的 MyWaitNotify：

public class MonitorObject{
}

public class MyWaitNotify{

  MonitorObject myMonitorObject = new MonitorObject();

  public void doWait(){
    synchronized(myMonitorObject){
      try{
        myMonitorObject.wait();
      } catch(InterruptedException e){...}
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      myMonitorObject.notify();
    }
  }
}
等待线程将调用 doWait()，而唤醒线程将调用 doNotify()。当一个线程调用一个对象的 notify()方法，正在等待该对象的所有线程中将有一个线程被唤醒并允许执行（校注：这个将被唤醒的线程是随机的，不可以指定唤醒哪个线程）。同时也提供了一个 notifyAll()方法来唤醒正在等待一个给定对象的所有线程。

如你所见，不管是等待线程还是唤醒线程都在同步块里调用 wait()和 notify()。这是强制性的！一个线程如果没有持有对象锁，将不能调用 wait()，notify()或者 notifyAll()。否则，会抛出 IllegalMonitorStateException 异常。

（校注：JVM 是这么实现的，当你调用 wait 时候它首先要检查下当前线程是否是锁的拥有者，不是则抛出 IllegalMonitorStateExcept。）

但是，这怎么可能？等待线程在同步块里面执行的时候，不是一直持有监视器对象（myMonitor 对象）的锁吗？等待线程不能阻塞唤醒线程进入 doNotify()的同步块吗？答案是：的确不能。一旦线程调用了 wait()方法，它就释放了所持有的监视器对象上的锁。这将允许其他线程也可以调用 wait()或者 notify()。

一旦一个线程被唤醒，不能立刻就退出 wait()的方法调用，直到调用 notify()的线程退出了它自己的同步块。换句话说：被唤醒的线程必须重新获得监视器对象的锁，才可以退出 wait()的方法调用，因为 wait 方法调用运行在同步块里面。如果多个线程被 notifyAll()唤醒，那么在同一时刻将只有一个线程可以退出 wait()方法，因为每个线程在退出 wait()前必须获得监视器对象的锁。

丢失的信号（Missed Signals）
notify()和 notifyAll()方法不会保存调用它们的方法，因为当这两个方法被调用时，有可能没有线程处于等待状态。通知信号过后便丢弃了。因此，如果一个线程先于被通知线程调用 wait()前调用了 notify()，等待的线程将错过这个信号。这可能是也可能不是个问题。不过，在某些情况下，这可能使等待线程永远在等待，不再醒来，因为线程错过了唤醒信号。

为了避免丢失信号，必须把它们保存在信号类里。在 MyWaitNotify 的例子中，通知信号应被存储在 MyWaitNotify 实例的一个成员变量里。以下是 MyWaitNotify 的修改版本：

public class MyWaitNotify2{

  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;

  public void doWait(){
    synchronized(myMonitorObject){
      if(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}
留意 doNotify()方法在调用 notify()前把 wasSignalled 变量设为 true。同时，留意 doWait()方法在调用 wait()前会检查 wasSignalled 变量。事实上，如果没有信号在前一次 doWait()调用和这次 doWait()调用之间的时间段里被接收到，它将只调用 wait()。

（校注：为了避免信号丢失， 用一个变量来保存是否被通知过。在 notify 前，设置自己已经被通知过。在 wait 后，设置自己没有被通知过，需要等待通知。）

假唤醒
由于莫名其妙的原因，线程有可能在没有调用过 notify()和 notifyAll()的情况下醒来。这就是所谓的假唤醒（spurious wakeups）。无端端地醒过来了。

如果在 MyWaitNotify2 的 doWait()方法里发生了假唤醒，等待线程即使没有收到正确的信号，也能够执行后续的操作。这可能导致你的应用程序出现严重问题。

为了防止假唤醒，保存信号的成员变量将在一个 while 循环里接受检查，而不是在 if 表达式里。这样的一个 while 循环叫做自旋锁（校注：这种做法要慎重，目前的 JVM 实现自旋会消耗 CPU，如果长时间不调用 doNotify 方法，doWait 方法会一直自旋，CPU 会消耗太大）。被唤醒的线程会自旋直到自旋锁(while 循环)里的条件变为 false。以下 MyWaitNotify2 的修改版本展示了这点：

public class MyWaitNotify3{

  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;

  public void doWait(){
    synchronized(myMonitorObject){
      while(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}
留意 wait()方法是在 while 循环里，而不在 if 表达式里。如果等待线程没有收到信号就唤醒，wasSignalled 变量将变为 false，while 循环会再执行一次，促使醒来的线程回到等待状态。

多个线程等待相同信号
如果你有多个线程在等待，被 notifyAll()唤醒，但只有一个被允许继续执行，使用 while 循环也是个好方法。每次只有一个线程可以获得监视器对象锁，意味着只有一个线程可以退出 wait()调用并清除 wasSignalled 标志（设为 false）。一旦这个线程退出 doWait()的同步块，其他线程退出 wait()调用，并在 while 循环里检查 wasSignalled 变量值。但是，这个标志已经被第一个唤醒的线程清除了，所以其余醒来的线程将回到等待状态，直到下次信号到来。

不要在字符串常量或全局对象中调用 wait()
（校注：本章说的字符串常量指的是值为常量的变量）

本文早期的一个版本在 MyWaitNotify 例子里使用字符串常量（””）作为管程对象。以下是那个例子：

public class MyWaitNotify{

  String myMonitorObject = "";
  boolean wasSignalled = false;

  public void doWait(){
    synchronized(myMonitorObject){
      while(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }

  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}
在空字符串作为锁的同步块(或者其他常量字符串)里调用 wait()和 notify()产生的问题是，JVM/编译器内部会把常量字符串转换成同一个对象。这意味着，即使你有 2 个不同的 MyWaitNotify 实例，它们都引用了相同的空字符串实例。同时也意味着存在这样的风险：在第一个 MyWaitNotify 实例上调用 doWait()的线程会被在第二个 MyWaitNotify 实例上调用 doNotify()的线程唤醒。这种情况可以画成以下这张图：



起初这可能不像个大问题。毕竟，如果 doNotify()在第二个 MyWaitNotify 实例上被调用，真正发生的事不外乎线程 A 和 B 被错误的唤醒了 。这个被唤醒的线程（A 或者 B）将在 while 循环里检查信号值，然后回到等待状态，因为 doNotify()并没有在第一个 MyWaitNotify 实例上调用，而这个正是它要等待的实例。这种情况相当于引发了一次假唤醒。线程 A 或者 B 在信号值没有更新的情况下唤醒。但是代码处理了这种情况，所以线程回到了等待状态。记住，即使 4 个线程在相同的共享字符串实例上调用 wait()和 notify()，doWait()和 doNotify()里的信号还会被 2 个 MyWaitNotify 实例分别保存。在 MyWaitNotify1 上的一次 doNotify()调用可能唤醒 MyWaitNotify2 的线程，但是信号值只会保存在 MyWaitNotify1 里。

问题在于，由于 doNotify()仅调用了 notify()而不是 notifyAll()，即使有 4 个线程在相同的字符串（空字符串）实例上等待，只能有一个线程被唤醒。所以，如果线程 A 或 B 被发给 C 或 D 的信号唤醒，它会检查自己的信号值，看看有没有信号被接收到，然后回到等待状态。而 C 和 D 都没被唤醒来检查它们实际上接收到的信号值，这样信号便丢失了。这种情况相当于前面所说的丢失信号的问题。C 和 D 被发送过信号，只是都不能对信号作出回应。

如果 doNotify()方法调用 notifyAll()，而非 notify()，所有等待线程都会被唤醒并依次检查信号值。线程 A 和 B 将回到等待状态，但是 C 或 D 只有一个线程注意到信号，并退出 doWait()方法调用。C 或 D 中的另一个将回到等待状态，因为获得信号的线程在退出 doWait()的过程中清除了信号值(置为 false)。

看过上面这段后，你可能会设法使用 notifyAll()来代替 notify()，但是这在性能上是个坏主意。在只有一个线程能对信号进行响应的情况下，没有理由每次都去唤醒所有线程。

所以：在 wait()/notify()机制中，不要使用全局对象，字符串常量等。应该使用对应唯一的对象。例如，每一个 MyWaitNotify3 的实例（前一节的例子）拥有一个属于自己的监视器对象，而不是在空字符串上调用 wait()/notify()。

校注：

管程 (英语：Monitors，也称为监视器) 是对多个工作线程实现互斥访问共享资源的对象或模块。这些共享资源一般是硬件设备或一群变量。管程实现了在一个时间点，最多只有一个线程在执行它的某个子程序。与那些通过修改数据结构实现互斥访问的并发程序设计相比，管程很大程度上简化了程序设计。




饥饿和公平

如果一个线程因为 CPU 时间全部被其他线程抢走而得不到 CPU 运行时间，这种状态被称之为“饥饿”。而该线程被“饥饿致死”正是因为它得不到 CPU 运行时间的机会。解决饥饿的方案被称之为“公平性” – 即所有线程均能公平地获得运行机会。

下面是本文讨论的主题：
Java 中导致饥饿的原因：

高优先级线程吞噬所有的低优先级线程的 CPU 时间。
线程被永久堵塞在一个等待进入同步块的状态。
线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的 wait 方法)。
在 Java 中实现公平性方案，需要:

使用锁，而不是同步块。
公平锁。
注意性能方面。
Java 中导致饥饿的原因
在 Java 中，下面三个常见的原因会导致线程饥饿：

高优先级线程吞噬所有的低优先级线程的 CPU 时间。
线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。
线程在等待一个本身(在其上调用 wait())也处于永久等待完成的对象，因为其他线程总是被持续地获得唤醒。
高优先级线程吞噬所有的低优先级线程的 CPU 时间
你能为每个线程设置独自的线程优先级，优先级越高的线程获得的 CPU 时间越多，线程优先级值设置在 1 到 10 之间，而这些优先级值所表示行为的准确解释则依赖于你的应用运行平台。对大多数应用来说，你最好是不要改变其优先级值。

线程被永久堵塞在一个等待进入同步块的状态
Java 的同步代码区也是一个导致饥饿的因素。Java 的同步代码区对哪个线程允许进入的次序没有任何保障。这就意味着理论上存在一个试图进入该同步区的线程处于被永久堵塞的风险，因为其他线程总是能持续地先于它获得访问，这即是“饥饿”问题，而一个线程被“饥饿致死”正是因为它得不到 CPU 运行时间的机会。

线程在等待一个本身(在其上调用 wait())也处于永久等待完成的对象
如果多个线程处在 wait()方法执行上，而对其调用 notify()不会保证哪一个线程会获得唤醒，任何线程都有可能处于继续等待的状态。因此存在这样一个风险：一个等待线程从来得不到唤醒，因为其他等待线程总是能被获得唤醒。

在 Java 中实现公平性
虽 Java 不可能实现 100% 的公平性，我们依然可以通过同步结构在线程间实现公平性的提高。

首先来学习一段简单的同步态代码：

public class Synchronizer{

    public synchronized void doSynchronized(){

    //do a lot of work which takes a long time

    }
}
如果有一个以上的线程调用 doSynchronized()方法，在第一个获得访问的线程未完成前，其他线程将一直处于阻塞状态，而且在这种多线程被阻塞的场景下，接下来将是哪个线程获得访问是没有保障的。

使用锁方式替代同步块
为了提高等待线程的公平性，我们使用锁方式来替代同步块。

public class Synchronizer{
    Lock lock = new Lock();
    public void doSynchronized() throws InterruptedException{
        this.lock.lock();
        //critical section, do a lot of work which takes a long time
        this.lock.unlock();
    }
}
注意到 doSynchronized()不再声明为 synchronized，而是用 lock.lock()和 lock.unlock()来替代。

下面是用 Lock 类做的一个实现：

public class Lock{

    private boolean isLocked      = false;

    private Thread lockingThread = null;

    public synchronized void lock() throws InterruptedException{

    while(isLocked){

        wait();

    }

    isLocked = true;

    lockingThread = Thread.currentThread();

}

public synchronized void unlock(){

    if(this.lockingThread != Thread.currentThread()){

         throw new IllegalMonitorStateException(

              "Calling thread has not locked this lock");

         }

    isLocked = false;

    lockingThread = null;

    notify();

    }
}
注意到上面对 Lock 的实现，如果存在多线程并发访问 lock()，这些线程将阻塞在对 lock()方法的访问上。另外，如果锁已经锁上（校对注：这里指的是 isLocked 等于 true 时），这些线程将阻塞在 while(isLocked)循环的 wait()调用里面。要记住的是，当线程正在等待进入 lock() 时，可以调用 wait()释放其锁实例对应的同步锁，使得其他多个线程可以进入 lock()方法，并调用 wait()方法。

这回看下 doSynchronized()，你会注意到在 lock()和 unlock()之间的注释：在这两个调用之间的代码将运行很长一段时间。进一步设想，这段代码将长时间运行，和进入 lock()并调用 wait()来比较的话。这意味着大部分时间用在等待进入锁和进入临界区的过程是用在 wait()的等待中，而不是被阻塞在试图进入 lock()方法中。

在早些时候提到过，同步块不会对等待进入的多个线程谁能获得访问做任何保障，同样当调用 notify()时，wait()也不会做保障一定能唤醒线程（至于为什么，请看线程通信）。因此这个版本的 Lock 类和 doSynchronized()那个版本就保障公平性而言，没有任何区别。

但我们能改变这种情况。当前的 Lock 类版本调用自己的 wait()方法，如果每个线程在不同的对象上调用 wait()，那么只有一个线程会在该对象上调用 wait()，Lock 类可以决定哪个对象能对其调用 notify()，因此能做到有效的选择唤醒哪个线程。

公平锁
下面来讲述将上面 Lock 类转变为公平锁 FairLock。你会注意到新的实现和之前的 Lock 类中的同步和 wait()/notify()稍有不同。

准确地说如何从之前的 Lock 类做到公平锁的设计是一个渐进设计的过程，每一步都是在解决上一步的问题而前进的：Nested Monitor Lockout, Slipped Conditions 和 Missed Signals。这些本身的讨论虽已超出本文的范围，但其中每一步的内容都将会专题进行讨论。重要的是，每一个调用 lock()的线程都会进入一个队列，当解锁后，只有队列里的第一个线程被允许锁住 Farlock 实例，所有其它的线程都将处于等待状态，直到他们处于队列头部。

public class FairLock {
    private boolean           isLocked       = false;
    private Thread            lockingThread  = null;
    private List<QueueObject> waitingThreads =
            new ArrayList<QueueObject>();

  public void lock() throws InterruptedException{
    QueueObject queueObject           = new QueueObject();
    boolean     isLockedForThisThread = true;
    synchronized(this){
        waitingThreads.add(queueObject);
    }

    while(isLockedForThisThread){
      synchronized(this){
        isLockedForThisThread =
            isLocked || waitingThreads.get(0) != queueObject;
        if(!isLockedForThisThread){
          isLocked = true;
           waitingThreads.remove(queueObject);
           lockingThread = Thread.currentThread();
           return;
         }
      }
      try{
        queueObject.doWait();
      }catch(InterruptedException e){
        synchronized(this) { waitingThreads.remove(queueObject); }
        throw e;
      }
    }
  }

  public synchronized void unlock(){
    if(this.lockingThread != Thread.currentThread()){
      throw new IllegalMonitorStateException(
        "Calling thread has not locked this lock");
    }
    isLocked      = false;
    lockingThread = null;
    if(waitingThreads.size() > 0){
      waitingThreads.get(0).doNotify();
    }
  }
}
public class QueueObject {

    private boolean isNotified = false;

    public synchronized void doWait() throws InterruptedException {

    while(!isNotified){
        this.wait();
    }

    this.isNotified = false;

}

public synchronized void doNotify() {
    this.isNotified = true;
    this.notify();
}

public boolean equals(Object o) {
    return this == o;
}

}
首先注意到 lock()方法不在声明为 synchronized，取而代之的是对必需同步的代码，在 synchronized 中进行嵌套。

FairLock 新创建了一个 QueueObject 的实例，并对每个调用 lock()的线程进行入队列。调用 unlock()的线程将从队列头部获取 QueueObject，并对其调用 doNotify()，以唤醒在该对象上等待的线程。通过这种方式，在同一时间仅有一个等待线程获得唤醒，而不是所有的等待线程。这也是实现 FairLock 公平性的核心所在。

请注意，在同一个同步块中，锁状态依然被检查和设置，以避免出现滑漏条件。

还需注意到，QueueObject 实际是一个 semaphore。doWait()和 doNotify()方法在 QueueObject 中保存着信号。这样做以避免一个线程在调用 queueObject.doWait()之前被另一个调用 unlock()并随之调用 queueObject.doNotify()的线程重入，从而导致信号丢失。queueObject.doWait()调用放置在 synchronized(this)块之外，以避免被 monitor 嵌套锁死，所以另外的线程可以解锁，只要当没有线程在 lock 方法的 synchronized(this)块中执行即可。

最后，注意到 queueObject.doWait()在 try – catch 块中是怎样调用的。在 InterruptedException 抛出的情况下，线程得以离开 lock()，并需让它从队列中移除。

性能考虑
如果比较 Lock 和 FairLock 类，你会注意到在 FairLock 类中 lock()和 unlock()还有更多需要深入的地方。这些额外的代码会导致 FairLock 的同步机制实现比 Lock 要稍微慢些。究竟存在多少影响，还依赖于应用在 FairLock 临界区执行的时长。执行时长越大，FairLock 带来的负担影响就越小，当然这也和代码执行的频繁度相关。



嵌套管程锁死

嵌套管程锁死类似于死锁， 下面是一个嵌套管程锁死的场景：

线程 1 获得 A 对象的锁。
线程 1 获得对象 B 的锁（同时持有对象 A 的锁）。
线程 1 决定等待另一个线程的信号再继续。
线程 1 调用 B.wait()，从而释放了 B 对象上的锁，但仍然持有对象 A 的锁。

线程 2 需要同时持有对象 A 和对象 B 的锁，才能向线程 1 发信号。
线程 2 无法获得对象 A 上的锁，因为对象 A 上的锁当前正被线程 1 持有。
线程 2 一直被阻塞，等待线程 1 释放对象 A 上的锁。

线程 1 一直阻塞，等待线程 2 的信号，因此，不会释放对象 A 上的锁，
而线程 2 需要对象 A 上的锁才能给线程 1 发信号……
你可以能会说，这是个空想的场景，好吧，让我们来看看下面这个比较挫的 Lock 实现：

//lock implementation with nested monitor lockout problem
public class Lock{
    protected MonitorObject monitorObject = new MonitorObject();
    protected boolean isLocked = false;

    public void lock() throws InterruptedException{
        synchronized(this){
            while(isLocked){
                synchronized(this.monitorObject){
                    this.monitorObject.wait();
                }
            }
            isLocked = true;
        }
    }

    public void unlock(){
        synchronized(this){
            this.isLocked = false;
            synchronized(this.monitorObject){
                this.monitorObject.notify();
            }
        }
    }
}
可以看到，lock()方法首先在”this”上同步，然后在 monitorObject 上同步。如果 isLocked 等于 false，因为线程不会继续调用 monitorObject.wait()，那么一切都没有问题 。但是如果 isLocked 等于 true，调用 lock()方法的线程会在 monitorObject.wait()上阻塞。

这里的问题在于，调用 monitorObject.wait()方法只释放了 monitorObject 上的管程对象，而与”this“关联的管程对象并没有释放。换句话说，这个刚被阻塞的线程仍然持有”this”上的锁。

（校对注：如果一个线程持有这种 Lock 的时候另一个线程执行了 lock 操作）当一个已经持有这种 Lock 的线程想调用 unlock()，就会在 unlock()方法进入 synchronized(this)块时阻塞。这会一直阻塞到在 lock()方法中等待的线程离开 synchronized(this)块。但是，在 unlock 中 isLocked 变为 false，monitorObject.notify()被执行之后，lock()中等待的线程才会离开 synchronized(this)块。

简而言之，在 lock 方法中等待的线程需要其它线程成功调用 unlock 方法来退出 lock 方法，但是，在 lock()方法离开外层同步块之前，没有线程能成功执行 unlock()。

结果就是，任何调用 lock 方法或 unlock 方法的线程都会一直阻塞。这就是嵌套管程锁死。

一个更现实的例子
你可能会说，这么挫的实现方式我怎么可能会做呢？你或许不会在里层的管程对象上调用 wait 或 notify 方法，但完全有可能会在外层的 this 上调。 有很多类似上面例子的情况。例如，如果你准备实现一个公平锁。你可能希望每个线程在它们各自的 QueueObject 上调用 wait()，这样就可以每次唤醒一个线程。

下面是一个比较挫的公平锁实现方式：

//Fair Lock implementation with nested monitor lockout problem
public class FairLock {
    private boolean isLocked = false;
    private Thread lockingThread = null;
    private List waitingThreads =
        new ArrayList();

    public void lock() throws InterruptedException{
        QueueObject queueObject = new QueueObject();

        synchronized(this){
            waitingThreads.add(queueObject);

            while(isLocked ||
                waitingThreads.get(0) != queueObject){

                synchronized(queueObject){
                    try{
                        queueObject.wait();
                    }catch(InterruptedException e){
                        waitingThreads.remove(queueObject);
                        throw e;
                    }
                }
            }
            waitingThreads.remove(queueObject);
            isLocked = true;
            lockingThread = Thread.currentThread();
        }
    }

    public synchronized void unlock(){
        if(this.lockingThread != Thread.currentThread()){
            throw new IllegalMonitorStateException(
                "Calling thread has not locked this lock");
        }
        isLocked = false;
        lockingThread = null;
        if(waitingThreads.size() > 0){
            QueueObject queueObject = waitingThread.get(0);
            synchronized(queueObject){
                queueObject.notify();
            }
        }
    }
}
public class QueueObject {}
乍看之下，嗯，很好，但是请注意 lock 方法是怎么调用 queueObject.wait()的，在方法内部有两个 synchronized 块，一个锁定 this，一个嵌在上一个 synchronized 块内部，它锁定的是局部变量 queueObject。

当一个线程调用 queueObject.wait()方法的时候，它仅仅释放的是在 queueObject 对象实例的锁，并没有释放”this”上面的锁。

现在我们还有一个地方需要特别注意， unlock 方法被声明成了 synchronized，这就相当于一个 synchronized（this）块。这就意味着，如果一个线程在 lock()中等待，该线程将持有与 this 关联的管程对象。所有调用 unlock()的线程将会一直保持阻塞，等待着前面那个已经获得 this 锁的线程释放 this 锁，但这永远也发生不了，因为只有某个线程成功地给 lock()中等待的线程发送了信号，this 上的锁才会释放，但只有执行 unlock()方法才会发送这个信号。

因此，上面的公平锁的实现会导致嵌套管程锁死。更好的公平锁实现方式可以参考 Starvation and Fairness。

嵌套管程锁死 VS 死锁
嵌套管程锁死与死锁很像：都是线程最后被一直阻塞着互相等待。

但是两者又不完全相同。在死锁 中我们已经对死锁有了个大概的解释，死锁通常是因为两个线程获取锁的顺序不一致造成的，线程 1 锁住 A，等待获取 B，线程 2 已经获取了 B，再等待获取 A。如避免死锁中所说的，死锁可以通过总是以相同的顺序获取锁来避免。

但是发生嵌套管程锁死时锁获取的顺序是一致的。线程 1 获得 A 和 B，然后释放 B，等待线程 2 的信号。线程 2 需要同时获得 A 和 B，才能向线程 1 发送信号。所以，一个线程在等待唤醒，另一个线程在等待想要的锁被释放。

不同点归纳如下：

死锁中，二个线程都在等待对方释放锁。

嵌套管程锁死中，线程 1 持有锁 A，同时等待从线程 2 发来的信号，线程 2 需要锁 A 来发信号给线程 1。



Slipped Conditions

所谓 Slipped conditions，就是说， 从一个线程检查某一特定条件到该线程操作此条件期间，这个条件已经被其它线程改变，导致第一个线程在该条件上执行了错误的操作。这里有一个简单的例子：

public class Lock {
    private boolean isLocked = true;

    public void lock(){
      synchronized(this){
        while(isLocked){
          try{
            this.wait();
          } catch(InterruptedException e){
            //do nothing, keep waiting
          }
        }
      }

      synchronized(this){
        isLocked = true;
      }
    }

    public synchronized void unlock(){
      isLocked = false;
      this.notify();
    }
}
我们可以看到，lock()方法包含了两个同步块。第一个同步块执行 wait 操作直到 isLocked 变为 false 才退出，第二个同步块将 isLocked 置为 true，以此来锁住这个 Lock 实例避免其它线程通过 lock()方法。

我们可以设想一下，假如在某个时刻 isLocked 为 false， 这个时候，有两个线程同时访问 lock 方法。如果第一个线程先进入第一个同步块，这个时候它会发现 isLocked 为 false，若此时允许第二个线程执行，它也进入第一个同步块，同样发现 isLocked 是 false。现在两个线程都检查了这个条件为 false，然后它们都会继续进入第二个同步块中并设置 isLocked 为 true。

这个场景就是 slipped conditions 的例子，两个线程检查同一个条件， 然后退出同步块，因此在这两个线程改变条件之前，就允许其它线程来检查这个条件。换句话说，条件被某个线程检查到该条件被此线程改变期间，这个条件已经被其它线程改变过了。

为避免 slipped conditions，条件的检查与设置必须是原子的，也就是说，在第一个线程检查和设置条件期间，不会有其它线程检查这个条件。

解决上面问题的方法很简单，只是简单的把 isLocked = true 这行代码移到第一个同步块中，放在 while 循环后面即可：

public class Lock {
    private boolean isLocked = true;

    public void lock(){
      synchronized(this){
        while(isLocked){
          try{
            this.wait();
          } catch(InterruptedException e){
            //do nothing, keep waiting
          }
        }
        isLocked = true;
      }
    }

    public synchronized void unlock(){
      isLocked = false;
      this.notify();
    }
}
现在检查和设置 isLocked 条件是在同一个同步块中原子地执行了。

一个更现实的例子
也许你会说，我才不可能写这么挫的代码，还觉得 slipped conditions 是个相当理论的问题。但是第一个简单的例子只是用来更好的展示 slipped conditions。

饥饿和公平中实现的公平锁也许是个更现实的例子。再看下嵌套管程锁死中那个幼稚的实现，如果我们试图解决其中的嵌套管程锁死问题，很容易产生 slipped conditions 问题。 首先让我们看下嵌套管程锁死中的例子：

//Fair Lock implementation with nested monitor lockout problem
public class FairLock {
  private boolean isLocked = false;
  private Thread lockingThread = null;
  private List waitingThreads =
            new ArrayList();

  public void lock() throws InterruptedException{
    QueueObject queueObject = new QueueObject();

    synchronized(this){
      waitingThreads.add(queueObject);

      while(isLocked || waitingThreads.get(0) != queueObject){

        synchronized(queueObject){
          try{
            queueObject.wait();
          }catch(InterruptedException e){
            waitingThreads.remove(queueObject);
            throw e;
          }
        }
      }
      waitingThreads.remove(queueObject);
      isLocked = true;
      lockingThread = Thread.currentThread();
    }
  }

  public synchronized void unlock(){
    if(this.lockingThread != Thread.currentThread()){
      throw new IllegalMonitorStateException(
        "Calling thread has not locked this lock");
    }
    isLocked      = false;
    lockingThread = null;
    if(waitingThreads.size() > 0){
      QueueObject queueObject = waitingThread.get(0);
      synchronized(queueObject){
        queueObject.notify();
      }
    }
  }
}
public class QueueObject {}
我们可以看到 synchronized(queueObject)及其中的 queueObject.wait()调用是嵌在 synchronized(this)块里面的，这会导致嵌套管程锁死问题。为避免这个问题，我们必须将 synchronized(queueObject)块移出 synchronized(this)块。移出来之后的代码可能是这样的：

//Fair Lock implementation with slipped conditions problem
public class FairLock {
  private boolean isLocked = false;
  private Thread lockingThread  = null;
  private List waitingThreads =
            new ArrayList();

  public void lock() throws InterruptedException{
    QueueObject queueObject = new QueueObject();

    synchronized(this){
      waitingThreads.add(queueObject);
    }

    boolean mustWait = true;
    while(mustWait){

      synchronized(this){
        mustWait = isLocked || waitingThreads.get(0) != queueObject;
      }

      synchronized(queueObject){
        if(mustWait){
          try{
            queueObject.wait();
          }catch(InterruptedException e){
            waitingThreads.remove(queueObject);
            throw e;
          }
        }
      }
    }

    synchronized(this){
      waitingThreads.remove(queueObject);
      isLocked = true;
      lockingThread = Thread.currentThread();
    }
  }
}
注意：因为我只改动了 lock()方法，这里只展现了 lock 方法。

现在 lock()方法包含了 3 个同步块。

第一个，synchronized(this)块通过 mustWait = isLocked || waitingThreads.get(0) != queueObject 检查内部变量的值。

第二个，synchronized(queueObject)块检查线程是否需要等待。也有可能其它线程在这个时候已经解锁了，但我们暂时不考虑这个问题。我们就假设这个锁处在解锁状态，所以线程会立马退出 synchronized(queueObject)块。

第三个，synchronized(this)块只会在 mustWait 为 false 的时候执行。它将 isLocked 重新设回 true，然后离开 lock()方法。

设想一下，在锁处于解锁状态时，如果有两个线程同时调用 lock()方法会发生什么。首先，线程 1 会检查到 isLocked 为 false，然后线程 2 同样检查到 isLocked 为 false。接着，它们都不会等待，都会去设置 isLocked 为 true。这就是 slipped conditions 的一个最好的例子。

解决 Slipped Conditions 问题
要解决上面例子中的 slipped conditions 问题，最后一个 synchronized(this)块中的代码必须向上移到第一个同步块中。为适应这种变动，代码需要做点小改动。下面是改动过的代码：

//Fair Lock implementation without nested monitor lockout problem,
//but with missed signals problem.
public class FairLock {
  private boolean isLocked = false;
  private Thread lockingThread  = null;
  private List waitingThreads =
            new ArrayList();

  public void lock() throws InterruptedException{
    QueueObject queueObject = new QueueObject();

    synchronized(this){
      waitingThreads.add(queueObject);
    }

    boolean mustWait = true;
    while(mustWait){
      synchronized(this){
        mustWait = isLocked || waitingThreads.get(0) != queueObject;
        if(!mustWait){
          waitingThreads.remove(queueObject);
          isLocked = true;
          lockingThread = Thread.currentThread();
          return;
        }
      }     

      synchronized(queueObject){
        if(mustWait){
          try{
            queueObject.wait();
          }catch(InterruptedException e){
            waitingThreads.remove(queueObject);
            throw e;
          }
        }
      }
    }
  }
}
我们可以看到对局部变量 mustWait 的检查与赋值是在同一个同步块中完成的。还可以看到，即使在 synchronized(this)块外面检查了 mustWait，在 while(mustWait)子句中，mustWait 变量从来没有在 synchronized(this)同步块外被赋值。当一个线程检查到 mustWait 是 false 的时候，它将自动设置内部的条件（isLocked），所以其它线程再来检查这个条件的时候，它们就会发现这个条件的值现在为 true 了。

synchronized(this)块中的 return;语句不是必须的。这只是个小小的优化。如果一个线程肯定不会等待（即 mustWait 为 false），那么就没必要让它进入到 synchronized(queueObject)同步块中和执行 if(mustWait)子句了。

细心的读者可能会注意到上面的公平锁实现仍然有可能丢失信号。设想一下，当该 FairLock 实例处于锁定状态时，有个线程来调用 lock()方法。执行完第一个 synchronized(this)块后，mustWait 变量的值为 true。再设想一下调用 lock()的线程是通过抢占式的，拥有锁的那个线程那个线程此时调用了 unlock()方法，但是看下之前的 unlock()的实现你会发现，它调用了 queueObject.notify()。但是，因为 lock()中的线程还没有来得及调用 queueObject.wait()，所以 queueObject.notify()调用也就没有作用了，信号就丢失掉了。如果调用 lock()的线程在另一个线程调用 queueObject.notify()之后调用 queueObject.wait()，这个线程会一直阻塞到其它线程调用 unlock 方法为止，但这永远也不会发生。

公平锁实现的信号丢失问题在饥饿和公平一文中我们已有过讨论，把 QueueObject 转变成一个信号量，并提供两个方法：doWait()和 doNotify()。这些方法会在 QueueObject 内部对信号进行存储和响应。用这种方式，即使 doNotify()在 doWait()之前调用，信号也不会丢失。





Java 中的锁

锁像 synchronized 同步块一样，是一种线程同步机制，但比 Java 中的 synchronized 同步块更复杂。因为锁（以及其它更高级的线程同步机制）是由 synchronized 同步块的方式实现的，所以我们还不能完全摆脱 synchronized 关键字（译者注：这说的是 Java 5 之前的情况）。

自 Java 5 开始，java.util.concurrent.locks 包中包含了一些锁的实现，因此你不用去实现自己的锁了。但是你仍然需要去了解怎样使用这些锁，且了解这些实现背后的理论也是很有用处的。可以参考我对 java.util.concurrent.locks.Lock 的介绍，以了解更多关于锁的信息。

以下是本文所涵盖的主题：

一个简单的锁
锁的可重入性
锁的公平性
在 finally 语句中调用 unlock()
一个简单的锁
让我们从 java 中的一个同步块开始：

public class Counter{
    private int count = 0;

    public int inc(){
        synchronized(this){
            return ++count;
        }
    }
}
可以看到在 inc()方法中有一个 synchronized(this)代码块。该代码块可以保证在同一时间只有一个线程可以执行 return ++count。虽然在 synchronized 的同步块中的代码可以更加复杂，但是++count 这种简单的操作已经足以表达出线程同步的意思。

以下的 Counter 类用 Lock 代替 synchronized 达到了同样的目的：

public class Counter{
    private Lock lock = new Lock();
    private int count = 0;

    public int inc(){
        lock.lock();
        int newCount = ++count;
        lock.unlock();
        return newCount;
    }
}
lock()方法会对 Lock 实例对象进行加锁，因此所有对该对象调用 lock()方法的线程都会被阻塞，直到该 Lock 对象的 unlock()方法被调用。

这里有一个 Lock 类的简单实现：

public class Counter{
public class Lock{
    private boolean isLocked = false;

    public synchronized void lock()
        throws InterruptedException{
        while(isLocked){
            wait();
        }
        isLocked = true;
    }

    public synchronized void unlock(){
        isLocked = false;
        notify();
    }
}
注意其中的 while(isLocked)循环，它又被叫做“自旋锁”。自旋锁以及 wait()和 notify()方法在线程通信这篇文章中有更加详细的介绍。当 isLocked 为 true 时，调用 lock()的线程在 wait()调用上阻塞等待。为防止该线程没有收到 notify()调用也从 wait()中返回（也称作虚假唤醒），这个线程会重新去检查 isLocked 条件以决定当前是否可以安全地继续执行还是需要重新保持等待，而不是认为线程被唤醒了就可以安全地继续执行了。如果 isLocked 为 false，当前线程会退出 while(isLocked)循环，并将 isLocked 设回 true，让其它正在调用 lock()方法的线程能够在 Lock 实例上加锁。

当线程完成了临界区（位于 lock()和 unlock()之间）中的代码，就会调用 unlock()。执行 unlock()会重新将 isLocked 设置为 false，并且通知（唤醒）其中一个（若有的话）在 lock()方法中调用了 wait()函数而处于等待状态的线程。

锁的可重入性
Java 中的 synchronized 同步块是可重入的。这意味着如果一个 java 线程进入了代码中的 synchronized 同步块，并因此获得了该同步块使用的同步对象对应的管程上的锁，那么这个线程可以进入由同一个管程对象所同步的另一个 java 代码块。下面是一个例子：

public class Reentrant{
    public synchronized outer(){
        inner();
    }

    public synchronized inner(){
        //do something
    }
}
注意 outer()和 inner()都被声明为 synchronized，这在 Java 中和 synchronized(this)块等效。如果一个线程调用了 outer()，在 outer()里调用 inner()就没有什么问题，因为这两个方法（代码块）都由同一个管程对象（”this”)所同步。如果一个线程已经拥有了一个管程对象上的锁，那么它就有权访问被这个管程对象同步的所有代码块。这就是可重入。线程可以进入任何一个它已经拥有的锁所同步着的代码块。

前面给出的锁实现不是可重入的。如果我们像下面这样重写 Reentrant 类，当线程调用 outer()时，会在 inner()方法的 lock.lock()处阻塞住。

public class Reentrant2{
    Lock lock = new Lock();

    public outer(){
        lock.lock();
        inner();
        lock.unlock();
    }

    public synchronized inner(){
        lock.lock();
        //do something
        lock.unlock();
    }
}
调用 outer()的线程首先会锁住 Lock 实例，然后继续调用 inner()。inner()方法中该线程将再一次尝试锁住 Lock 实例，结果该动作会失败（也就是说该线程会被阻塞），因为这个 Lock 实例已经在 outer()方法中被锁住了。

两次 lock()之间没有调用 unlock()，第二次调用 lock 就会阻塞，看过 lock()实现后，会发现原因很明显：

public class Lock{
    boolean isLocked = false;

    public synchronized void lock()
        throws InterruptedException{
        while(isLocked){
            wait();
        }
        isLocked = true;
    }

    ...
}
一个线程是否被允许退出 lock()方法是由 while 循环（自旋锁）中的条件决定的。当前的判断条件是只有当 isLocked 为 false 时 lock 操作才被允许，而没有考虑是哪个线程锁住了它。

为了让这个 Lock 类具有可重入性，我们需要对它做一点小的改动：

public class Lock{
    boolean isLocked = false;
    Thread  lockedBy = null;
    int lockedCount = 0;

    public synchronized void lock()
        throws InterruptedException{
        Thread callingThread =
            Thread.currentThread();
        while(isLocked && lockedBy != callingThread){
            wait();
        }
        isLocked = true;
        lockedCount++;
        lockedBy = callingThread;
  }

    public synchronized void unlock(){
        if(Thread.curentThread() ==
            this.lockedBy){
            lockedCount--;

            if(lockedCount == 0){
                isLocked = false;
                notify();
            }
        }
    }

    ...
}
注意到现在的 while 循环（自旋锁）也考虑到了已锁住该 Lock 实例的线程。如果当前的锁对象没有被加锁(isLocked = false)，或者当前调用线程已经对该 Lock 实例加了锁，那么 while 循环就不会被执行，调用 lock()的线程就可以退出该方法（译者注：“被允许退出该方法”在当前语义下就是指不会调用 wait()而导致阻塞）。

除此之外，我们需要记录同一个线程重复对一个锁对象加锁的次数。否则，一次 unblock()调用就会解除整个锁，即使当前锁已经被加锁过多次。在 unlock()调用没有达到对应 lock()调用的次数之前，我们不希望锁被解除。

现在这个 Lock 类就是可重入的了。

锁的公平性
Java 的 synchronized 块并不保证尝试进入它们的线程的顺序。因此，如果多个线程不断竞争访问相同的 synchronized 同步块，就存在一种风险，其中一个或多个线程永远也得不到访问权 —— 也就是说访问权总是分配给了其它线程。这种情况被称作线程饥饿。为了避免这种问题，锁需要实现公平性。本文所展现的锁在内部是用 synchronized 同步块实现的，因此它们也不保证公平性。饥饿和公平中有更多关于该内容的讨论。

在 finally 语句中调用 unlock()
如果用 Lock 来保护临界区，并且临界区有可能会抛出异常，那么在 finally 语句中调用 unlock()就显得非常重要了。这样可以保证这个锁对象可以被解锁以便其它线程能继续对其加锁。以下是一个示例：

lock.lock();
try{
    //do critical section code,
    //which may throw exception
} finally {
    lock.unlock();
}
这个简单的结构可以保证当临界区抛出异常时 Lock 对象可以被解锁。如果不是在 finally 语句中调用的 unlock()，当临界区抛出异常时，Lock 对象将永远停留在被锁住的状态，这会导致其它所有在该 Lock 对象上调用 lock()的线程一直阻塞。




Java 中的读/写锁

相比 Java 中的锁(Locks in Java)里 Lock 实现，读写锁更复杂一些。假设你的程序中涉及到对一些共享资源的读和写操作，且写操作没有读操作那么频繁。在没有写操作的时候，两个线程同时读一个资源没有任何问题，所以应该允许多个线程能在同时读取共享资源。但是如果有一个线程想去写这些共享资源，就不应该再有其它线程对该资源进行读或写（译者注：也就是说：读-读能共存，读-写不能共存，写-写不能共存）。这就需要一个读/写锁来解决这个问题。

Java5 在 java.util.concurrent 包中已经包含了读写锁。尽管如此，我们还是应该了解其实现背后的原理。

以下是本文的主题

读/写锁的 Java 实现(Read / Write Lock Java Implementation)
读/写锁的重入(Read / Write Lock Reentrance)
读锁重入(Read Reentrance)
写锁重入(Write Reentrance)
读锁升级到写锁(Read to Write Reentrance)
写锁降级到读锁(Write to Read Reentrance)
可重入的 ReadWriteLock 的完整实现(Fully Reentrant ReadWriteLock)
在 finally 中调用 unlock() (Calling unlock() from a finally-clause)
读/写锁的 Java 实现
先让我们对读写访问资源的条件做个概述：

读取 没有线程正在做写操作，且没有线程在请求写操作。

写入 没有线程正在做读写操作。

如果某个线程想要读取资源，只要没有线程正在对该资源进行写操作且没有线程请求对该资源的写操作即可。我们假设对写操作的请求比对读操作的请求更重要，就要提升写请求的优先级。此外，如果读操作发生的比较频繁，我们又没有提升写操作的优先级，那么就会产生“饥饿”现象。请求写操作的线程会一直阻塞，直到所有的读线程都从 ReadWriteLock 上解锁了。如果一直保证新线程的读操作权限，那么等待写操作的线程就会一直阻塞下去，结果就是发生“饥饿”。因此，只有当没有线程正在锁住 ReadWriteLock 进行写操作，且没有线程请求该锁准备执行写操作时，才能保证读操作继续。

当其它线程没有对共享资源进行读操作或者写操作时，某个线程就有可能获得该共享资源的写锁，进而对共享资源进行写操作。有多少线程请求了写锁以及以何种顺序请求写锁并不重要，除非你想保证写锁请求的公平性。

按照上面的叙述，简单的实现出一个读/写锁，代码如下

public class ReadWriteLock{
    private int readers = 0;
    private int writers = 0;
    private int writeRequests = 0;

    public synchronized void lockRead() 
        throws InterruptedException{
        while(writers > 0 || writeRequests > 0){
            wait();
        }
        readers++;
    }

    public synchronized void unlockRead(){
        readers--;
        notifyAll();
    }

    public synchronized void lockWrite() 
        throws InterruptedException{
        writeRequests++;

        while(readers > 0 || writers > 0){
            wait();
        }
        writeRequests--;
        writers++;
    }

    public synchronized void unlockWrite() 
        throws InterruptedException{
        writers--;
        notifyAll();
    }
}
ReadWriteLock 类中，读锁和写锁各有一个获取锁和释放锁的方法。

读锁的实现在 lockRead()中,只要没有线程拥有写锁（writers==0），且没有线程在请求写锁（writeRequests ==0），所有想获得读锁的线程都能成功获取。

写锁的实现在 lockWrite()中,当一个线程想获得写锁的时候，首先会把写锁请求数加 1（writeRequests++），然后再去判断是否能够真能获得写锁，当没有线程持有读锁（readers==0 ）,且没有线程持有写锁（writers==0）时就能获得写锁。有多少线程在请求写锁并无关系。

需要注意的是，在两个释放锁的方法（unlockRead，unlockWrite）中，都调用了 notifyAll 方法，而不是 notify。要解释这个原因，我们可以想象下面一种情形：

如果有线程在等待获取读锁，同时又有线程在等待获取写锁。如果这时其中一个等待读锁的线程被 notify 方法唤醒，但因为此时仍有请求写锁的线程存在（writeRequests>0），所以被唤醒的线程会再次进入阻塞状态。然而，等待写锁的线程一个也没被唤醒，就像什么也没发生过一样（译者注：信号丢失现象）。如果用的是 notifyAll 方法，所有的线程都会被唤醒，然后判断能否获得其请求的锁。

用 notifyAll 还有一个好处。如果有多个读线程在等待读锁且没有线程在等待写锁时，调用 unlockWrite()后，所有等待读锁的线程都能立马成功获取读锁 —— 而不是一次只允许一个。

读/写锁的重入
上面实现的读/写锁(ReadWriteLock) 是不可重入的，当一个已经持有写锁的线程再次请求写锁时，就会被阻塞。原因是已经有一个写线程了——就是它自己。此外，考虑下面的例子：

Thread 1 获得了读锁。
Thread 2 请求写锁，但因为 Thread 1 持有了读锁，所以写锁请求被阻塞。
Thread 1 再想请求一次读锁，但因为 Thread 2 处于请求写锁的状态，所以想再次获取读锁也会被阻塞。 上面这种情形使用前面的 ReadWriteLock 就会被锁定——一种类似于死锁的情形。不会再有线程能够成功获取读锁或写锁了。
为了让 ReadWriteLock 可重入，需要对它做一些改进。下面会分别处理读锁的重入和写锁的重入。

读锁重入
为了让 ReadWriteLock 的读锁可重入，我们要先为读锁重入建立规则：

要保证某个线程中的读锁可重入，要么满足获取读锁的条件（没有写或写请求），要么已经持有读锁（不管是否有写请求）。 要确定一个线程是否已经持有读锁，可以用一个 map 来存储已经持有读锁的线程以及对应线程获取读锁的次数，当需要判断某个线程能否获得读锁时，就利用 map 中存储的数据进行判断。下面是方法 lockRead 和 unlockRead 修改后的的代码：

public class ReadWriteLock{
    private Map<Thread, Integer> readingThreads =
        new HashMap<Thread, Integer>();

    private int writers = 0;
    private int writeRequests = 0;

    public synchronized void lockRead() 
        throws InterruptedException{
        Thread callingThread = Thread.currentThread();
        while(! canGrantReadAccess(callingThread)){
            wait();                                                                   
        }

        readingThreads.put(callingThread,
            (getAccessCount(callingThread) + 1));
    }

    public synchronized void unlockRead(){
        Thread callingThread = Thread.currentThread();
        int accessCount = getAccessCount(callingThread);
        if(accessCount == 1) { 
            readingThreads.remove(callingThread); 
        } else {
            readingThreads.put(callingThread, (accessCount -1)); 
        }
        notifyAll();
    }

    private boolean canGrantReadAccess(Thread callingThread){
        if(writers > 0) return false;
        if(isReader(callingThread) return true;
        if(writeRequests > 0) return false;
        return true;
    }

    private int getReadAccessCount(Thread callingThread){
        Integer accessCount = readingThreads.get(callingThread);
        if(accessCount == null) return 0;
        return accessCount.intValue();
    }

    private boolean isReader(Thread callingThread){
        return readingThreads.get(callingThread) != null;
    }
}
代码中我们可以看到，只有在没有线程拥有写锁的情况下才允许读锁的重入。此外，重入的读锁比写锁优先级高。

写锁重入
仅当一个线程已经持有写锁，才允许写锁重入（再次获得写锁）。下面是方法 lockWrite 和 unlockWrite 修改后的的代码。

public class ReadWriteLock{
    private Map<Thread, Integer> readingThreads =
        new HashMap<Thread, Integer>();

    private int writeAccesses    = 0;
    private int writeRequests    = 0;
    private Thread writingThread = null;

    public synchronized void lockWrite() 
        throws InterruptedException{
        writeRequests++;
        Thread callingThread = Thread.currentThread();
        while(!canGrantWriteAccess(callingThread)){
            wait();
        }
        writeRequests--;
        writeAccesses++;
        writingThread = callingThread;
    }

    public synchronized void unlockWrite() 
        throws InterruptedException{
        writeAccesses--;
        if(writeAccesses == 0){
            writingThread = null;
        }
        notifyAll();
    }

    private boolean canGrantWriteAccess(Thread callingThread){
        if(hasReaders()) return false;
        if(writingThread == null)    return true;
        if(!isWriter(callingThread)) return false;
        return true;
    }

    private boolean hasReaders(){
        return readingThreads.size() > 0;
    }

    private boolean isWriter(Thread callingThread){
        return writingThread == callingThread;
    }
}
注意在确定当前线程是否能够获取写锁的时候，是如何处理的。

读锁升级到写锁
有时，我们希望一个拥有读锁的线程，也能获得写锁。想要允许这样的操作，要求这个线程是唯一一个拥有读锁的线程。writeLock()需要做点改动来达到这个目的：

public class ReadWriteLock{
    private Map<Thread, Integer> readingThreads =
        new HashMap<Thread, Integer>();

    private int writeAccesses    = 0;
    private int writeRequests    = 0;
    private Thread writingThread = null;

    public synchronized void lockWrite() 
        throws InterruptedException{
        writeRequests++;
        Thread callingThread = Thread.currentThread();
        while(!canGrantWriteAccess(callingThread)){
            wait();
        }
        writeRequests--;
        writeAccesses++;
        writingThread = callingThread;
    }

    public synchronized void unlockWrite() throws InterruptedException{
        writeAccesses--;
        if(writeAccesses == 0){
            writingThread = null;
        }
        notifyAll();
    }

    private boolean canGrantWriteAccess(Thread callingThread){
        if(isOnlyReader(callingThread)) return true;
        if(hasReaders()) return false;
        if(writingThread == null) return true;
        if(!isWriter(callingThread)) return false;
        return true;
    }

    private boolean hasReaders(){
        return readingThreads.size() > 0;
    }

    private boolean isWriter(Thread callingThread){
        return writingThread == callingThread;
    }

    private boolean isOnlyReader(Thread thread){
        return readers == 1 && readingThreads.get(callingThread) != null;
    }
}
现在 ReadWriteLock 类就可以从读锁升级到写锁了。

写锁降级到读锁
有时拥有写锁的线程也希望得到读锁。如果一个线程拥有了写锁，那么自然其它线程是不可能拥有读锁或写锁了。所以对于一个拥有写锁的线程，再获得读锁，是不会有什么危险的。我们仅仅需要对上面 canGrantReadAccess 方法进行简单地修改：

public class ReadWriteLock{
    private boolean canGrantReadAccess(Thread callingThread){
        if(isWriter(callingThread)) return true;
        if(writingThread != null) return false;
        if(isReader(callingThread) return true;
        if(writeRequests > 0) return false;
        return true;
    }
}
可重入的 ReadWriteLock 的完整实现
下面是完整的 ReadWriteLock 实现。为了便于代码的阅读与理解，简单对上面的代码做了重构。重构后的代码如下。

public class ReadWriteLock{
    private Map<Thread, Integer> readingThreads =
        new HashMap<Thread, Integer>();

    private int writeAccesses    = 0;
    private int writeRequests    = 0;
    private Thread writingThread = null;

    public synchronized void lockRead() 
        throws InterruptedException{
        Thread callingThread = Thread.currentThread();
        while(! canGrantReadAccess(callingThread)){
            wait();
        }

        readingThreads.put(callingThread,
            (getReadAccessCount(callingThread) + 1));
    }

    private boolean canGrantReadAccess(Thread callingThread){
        if(isWriter(callingThread)) return true;
        if(hasWriter()) return false;
        if(isReader(callingThread)) return true;
        if(hasWriteRequests()) return false;
        return true;
    }

    public synchronized void unlockRead(){
        Thread callingThread = Thread.currentThread();
        if(!isReader(callingThread)){
            throw new IllegalMonitorStateException(
                "Calling Thread does not" +
                " hold a read lock on this ReadWriteLock");
        }
        int accessCount = getReadAccessCount(callingThread);
        if(accessCount == 1){ 
            readingThreads.remove(callingThread); 
        } else { 
            readingThreads.put(callingThread, (accessCount -1));
        }
        notifyAll();
    }

    public synchronized void lockWrite() 
        throws InterruptedException{
        writeRequests++;
        Thread callingThread = Thread.currentThread();
        while(!canGrantWriteAccess(callingThread)){
            wait();
        }
        writeRequests--;
        writeAccesses++;
        writingThread = callingThread;
    }

    public synchronized void unlockWrite() 
        throws InterruptedException{
        if(!isWriter(Thread.currentThread()){
        throw new IllegalMonitorStateException(
            "Calling Thread does not" +
            " hold the write lock on this ReadWriteLock");
        }
        writeAccesses--;
        if(writeAccesses == 0){
            writingThread = null;
        }
        notifyAll();
    }

    private boolean canGrantWriteAccess(Thread callingThread){
        if(isOnlyReader(callingThread)) return true;
        if(hasReaders()) return false;
        if(writingThread == null) return true;
        if(!isWriter(callingThread)) return false;
        return true;
    }

    private int getReadAccessCount(Thread callingThread){
        Integer accessCount = readingThreads.get(callingThread);
        if(accessCount == null) return 0;
        return accessCount.intValue();
    }

    private boolean hasReaders(){
        return readingThreads.size() > 0;
    }

    private boolean isReader(Thread callingThread){
        return readingThreads.get(callingThread) != null;
    }

    private boolean isOnlyReader(Thread callingThread){
        return readingThreads.size() == 1 &&
            readingThreads.get(callingThread) != null;
    }

    private boolean hasWriter(){
        return writingThread != null;
    }

    private boolean isWriter(Thread callingThread){
        return writingThread == callingThread;
    }

    private boolean hasWriteRequests(){
        return this.writeRequests > 0;
    }
}
在 finally 中调用 unlock()
在利用 ReadWriteLock 来保护临界区时，如果临界区可能抛出异常，在 finally 块中调用 readUnlock()和 writeUnlock()就显得很重要了。这样做是为了保证 ReadWriteLock 能被成功解锁，然后其它线程可以请求到该锁。这里有个例子：

lock.lockWrite();
try{
    //do critical section code, which may throw exception
} finally {
    lock.unlockWrite();
}
上面这样的代码结构能够保证临界区中抛出异常时 ReadWriteLock 也会被释放。如果 unlockWrite 方法不是在 finally 块中调用的，当临界区抛出了异常时，ReadWriteLock 会一直保持在写锁定状态，就会导致所有调用 lockRead()或 lockWrite()的线程一直阻塞。唯一能够重新解锁 ReadWriteLock 的因素可能就是 ReadWriteLock 是可重入的，当抛出异常时，这个线程后续还可以成功获取这把锁，然后执行临界区以及再次调用 unlockWrite()，这就会再次释放 ReadWriteLock。但是如果该线程后续不再获取这把锁了呢？所以，在 finally 中调用 unlockWrite 对写出健壮代码是很重要的。



重入锁死

重入锁死与死锁和嵌套管程锁死非常相似。锁 和读写锁两篇文章中都有涉及到重入锁死的问题。

当一个线程重新获取锁，读写锁或其他不可重入的同步器时，就可能发生重入锁死。可重入的意思是线程可以重复获得它已经持有的锁。Java 的 synchronized 块是可重入的。因此下面的代码是没问题的：

（译者注：这里提到的锁都是指的不可重入的锁实现，并不是 Java 类库中的 Lock 与 ReadWriteLock 类）

public class Reentrant{
    public synchronized outer(){
        inner();
    }

    public synchronized inner(){
        //do something
    }
}
注意 outer()和 inner()都声明为 synchronized，这在 Java 中这相当于 synchronized(this)块（译者注：这里两个方法是实例方法，synchronized 的实例方法相当于在 this 上加锁，如果是 static 方法，则不然，更多阅读：哪个对象才是锁？）。如果某个线程调用了 outer()，outer()中的 inner()调用是没问题的，因为两个方法都是在同一个管程对象(即 this)上同步的。如果一个线程持有某个管程对象上的锁，那么它就有权访问所有在该管程对象上同步的块。这就叫可重入。若线程已经持有锁，那么它就可以重复访问所有使用该锁的代码块。

下面这个锁的实现是不可重入的：

public class Lock{
    private boolean isLocked = false;
    public synchronized void lock()
        throws InterruptedException{
        while(isLocked){
            wait();
        }
        isLocked = true;
    }

    public synchronized void unlock(){
        isLocked = false;
        notify();
    }
}
如果一个线程在两次调用 lock()间没有调用 unlock()方法，那么第二次调用 lock()就会被阻塞，这就出现了重入锁死。

避免重入锁死有两个选择：

编写代码时避免再次获取已经持有的锁
使用可重入锁
至于哪个选择最适合你的项目，得视具体情况而定。可重入锁通常没有不可重入锁那么好的表现，而且实现起来复杂，但这些情况在你的项目中也许算不上什么问题。无论你的项目用锁来实现方便还是不用锁方便，可重入特性都需要根据具体问题具体分析。





信号量

Semaphore（信号量）是一个线程同步结构，用于在线程间传递信号，以避免出现信号丢失（译者注：下文会具体介绍），或者像锁一样用于保护一个关键区域。自从 5.0 开始，jdk 在 java.util.concurrent 包里提供了 Semaphore 的官方实现，因此大家不需要自己去实现 Semaphore。但是还是很有必要去熟悉如何使用 Semaphore 及其背后的原理

本文的涉及的主题如下：

简单的 Semaphore 实现
使用 Semaphore 来发出信号
可计数的 Semaphore
有上限的 Semaphore
把 Semaphore 当锁来使用
简单的 Semaphore 实现
下面是一个信号量的简单实现：

public class Semaphore {

private boolean signal = false;

public synchronized void take() {

this.signal = true;

this.notify();

}

public synchronized void release() throws InterruptedException{

while(!this.signal) wait();

this.signal = false;

}

}
Take 方法发出一个被存放在 Semaphore 内部的信号，而 Release 方法则等待一个信号，当其接收到信号后，标记位 signal 被清空，然后该方法终止。

使用这个 semaphore 可以避免错失某些信号通知。用 take 方法来代替 notify，release 方法来代替 wait。如果某线程在调用 release 等待之前调用 take 方法，那么调用 release 方法的线程仍然知道 take 方法已经被某个线程调用过了，因为该 Semaphore 内部保存了 take 方法发出的信号。而 wait 和 notify 方法就没有这样的功能。

当用 semaphore 来产生信号时，take 和 release 这两个方法名看起来有点奇怪。这两个名字来源于后面把 semaphore 当做锁的例子，后面会详细介绍这个例子，在该例子中，take 和 release 这两个名字会变得很合理。

使用 Semaphore 来产生信号
下面的例子中，两个线程通过 Semaphore 发出的信号来通知对方

Semaphore semaphore = new Semaphore();

SendingThread sender = new SendingThread(semaphore)；

ReceivingThread receiver = new ReceivingThread(semaphore);

receiver.start();

sender.start();

public class SendingThread {

Semaphore semaphore = null;

public SendingThread(Semaphore semaphore){

this.semaphore = semaphore;

}

public void run(){

while(true){

//do something, then signal

this.semaphore.take();

}

}

}

public class RecevingThread {

Semaphore semaphore = null;

public ReceivingThread(Semaphore semaphore){

this.semaphore = semaphore;

}

public void run(){

while(true){

this.semaphore.release();

//receive signal, then do something...

}

}

}
可计数的 Semaphore
上面提到的 Semaphore 的简单实现并没有计算通过调用 take 方法所产生信号的数量。可以把它改造成具有计数功能的 Semaphore。下面是一个可计数的 Semaphore 的简单实现。

public class CountingSemaphore {

private int signals = 0;

public synchronized void take() {

this.signals++;

this.notify();

}

public synchronized void release() throws InterruptedException{

while(this.signals == 0) wait();

this.signals--;

}

}
有上限的 Semaphore
上面的 CountingSemaphore 并没有限制信号的数量。下面的代码将 CountingSemaphore 改造成一个信号数量有上限的 BoundedSemaphore。

public class BoundedSemaphore {

private int signals = 0;

private int bound   = 0;

public BoundedSemaphore(int upperBound){

this.bound = upperBound;

}

public synchronized void take() throws InterruptedException{

while(this.signals == bound) wait();

this.signals++;

this.notify();

}

public synchronized void release() throws InterruptedException{

while(this.signals == 0) wait();

this.signals--;

this.notify();

}

}
在 BoundedSemaphore 中，当已经产生的信号数量达到了上限，take 方法将阻塞新的信号产生请求，直到某个线程调用 release 方法后，被阻塞于 take 方法的线程才能传递自己的信号。

把 Semaphore 当锁来使用
当信号量的数量上限是 1 时，Semaphore 可以被当做锁来使用。通过 take 和 release 方法来保护关键区域。请看下面的例子：

BoundedSemaphore semaphore = new BoundedSemaphore(1);

...

semaphore.take();

try{

//critical section

} finally {

semaphore.release();

}
在前面的例子中，Semaphore 被用来在多个线程之间传递信号，这种情况下，take 和 release 分别被不同的线程调用。但是在锁这个例子中，take 和 release 方法将被同一线程调用，因为只允许一个线程来获取信号（允许进入关键区域的信号），其它调用 take 方法获取信号的线程将被阻塞，知道第一个调用 take 方法的线程调用 release 方法来释放信号。对 release 方法的调用永远不会被阻塞，这是因为任何一个线程都是先调用 take 方法，然后再调用 release。

通过有上限的 Semaphore 可以限制进入某代码块的线程数量。设想一下，在上面的例子中，如果 BoundedSemaphore 上限设为 5 将会发生什么？意味着允许 5 个线程同时访问关键区域，但是你必须保证，这个 5 个线程不会互相冲突。否则你的应用程序将不能正常运行。

必须注意，release 方法应当在 finally 块中被执行。这样可以保在关键区域的代码抛出异常的情况下，信号也一定会被释放。





阻塞队列

阻塞队列与普通队列的区别在于，当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。试图从空的阻塞队列中获取元素的线程将会被阻塞，直到其他的线程往空的队列插入新的元素。同样，试图往已满的阻塞队列中添加新元素的线程同样也会被阻塞，直到其他的线程使队列重新变得空闲起来，如从队列中移除一个或者多个元素，或者完全清空队列，下图展示了如何通过阻塞队列来合作：



线程 1 往阻塞队列中添加元素，而线程 2 从阻塞队列中移除元素

从 5.0 开始，JDK 在 java.util.concurrent 包里提供了阻塞队列的官方实现。尽管 JDK 中已经包含了阻塞队列的官方实现，但是熟悉其背后的原理还是很有帮助的。

阻塞队列的实现
阻塞队列的实现类似于带上限的 Semaphore 的实现。下面是阻塞队列的一个简单实现

public class BlockingQueue {

private List queue = new LinkedList();

private int  limit = 10;

public BlockingQueue(int limit){

this.limit = limit;

}

public synchronized void enqueue(Object item)

throws InterruptedException  {

while(this.queue.size() == this.limit) {

wait();

}

if(this.queue.size() == 0) {

notifyAll();

}

this.queue.add(item);

}

public synchronized Object dequeue()

throws InterruptedException{

while(this.queue.size() == 0){

wait();

}

if(this.queue.size() == this.limit){

notifyAll();

}

return this.queue.remove(0);

}

}
必须注意到，在 enqueue 和 dequeue 方法内部，只有队列的大小等于上限（limit）或者下限（0）时，才调用 notifyAll 方法。如果队列的大小既不等于上限，也不等于下限，任何线程调用 enqueue 或者 dequeue 方法时，都不会阻塞，都能够正常的往队列中添加或者移除元素。




线程池

线程池（Thread Pool）对于限制应用程序中同一时刻运行的线程数很有用。因为每启动一个新线程都会有相应的性能开销，每个线程都需要给栈分配一些内存等等。

我们可以把并发执行的任务传递给一个线程池，来替代为每个并发执行的任务都启动一个新的线程。只要池里有空闲的线程，任务就会分配给一个线程执行。在线程池的内部，任务被插入一个阻塞队列（Blocking Queue），线程池里的线程会去取这个队列里的任务。当一个新任务插入队列时，一个空闲线程就会成功的从队列中取出任务并且执行它。

线程池经常应用在多线程服务器上。每个通过网络到达服务器的连接都被包装成一个任务并且传递给线程池。线程池的线程会并发的处理连接上的请求。以后会再深入有关 Java 实现多线程服务器的细节。

Java 5 在 java.util.concurrent 包中自带了内置的线程池，所以你不用非得实现自己的线程池。你可以阅读我写的 java.util.concurrent.ExecutorService 的文章以了解更多有关内置线程池的知识。不过无论如何，知道一点关于线程池实现的知识总是有用的。

这里有一个简单的线程池实现：

public class ThreadPool {

  private BlockingQueue taskQueue = null;
  private List<PoolThread> threads = new ArrayList<PoolThread>();
  private boolean isStopped = false;

  public ThreadPool(int noOfThreads, int maxNoOfTasks) {
    taskQueue = new BlockingQueue(maxNoOfTasks);

    for (int i=0; i<noOfThreads; i++) {
      threads.add(new PoolThread(taskQueue));
    }
    for (PoolThread thread : threads) {
      thread.start();
    }
  }

  public void synchronized execute(Runnable task) {
    if(this.isStopped) throw
      new IllegalStateException("ThreadPool is stopped");

    this.taskQueue.enqueue(task);
  }

  public synchronized boolean stop() {
    this.isStopped = true;
    for (PoolThread thread : threads) {
      thread.stop();
    }
  }

}
(校注：原文有编译错误，我修改了下)

public class PoolThread extends Thread {

  private BlockingQueue<Runnable> taskQueue = null;
  private boolean       isStopped = false;

  public PoolThread(BlockingQueue<Runnable> queue) {
    taskQueue = queue;
  }

  public void run() {
    while (!isStopped()) {
      try {
        Runnable runnable =taskQueue.take();
        runnable.run();
      } catch(Exception e) {
        // 写日志或者报告异常,
        // 但保持线程池运行.
      }
    }
  }

  public synchronized void toStop() {
    isStopped = true;
    this.interrupt(); // 打断池中线程的 dequeue() 调用.
  }

  public synchronized boolean isStopped() {
    return isStopped;
  }
}
线程池的实现由两部分组成。类 ThreadPool 是线程池的公开接口，而类 PoolThread 用来实现执行任务的子线程。

为了执行一个任务，方法 ThreadPool.execute(Runnable r)用 Runnable 的实现作为调用参数。在内部，Runnable 对象被放入阻塞队列 (Blocking Queue) ，等待着被子线程取出队列。

一个空闲的 PoolThread 线程会把 Runnable 对象从队列中取出并执行。你可以在 PoolThread.run()方法里看到这些代码。执行完毕后，PoolThread 进入循环并且尝试从队列中再取出一个任务，直到线程终止。

调用 ThreadPool.stop()方法可以停止 ThreadPool。在内部，调用 stop 先会标记 isStopped 成员变量（为 true）。然后，线程池的每一个子线程都调用 PoolThread.stop()方法停止运行。注意，如果线程池的 execute()在 stop()之后调用，execute()方法会抛出 IllegalStateException 异常。

子线程会在完成当前执行的任务后停止。注意 PoolThread.stop() 方法中调用了 this.interrupt()。它确保阻塞在 taskQueue.dequeue() 里的 wait()调用的线程能够跳出 wait()调用（校对注：因为执行了中断 interrupt，它能够打断这个调用），并且抛出一个 InterruptedException 异常离开 dequeue()方法。这个异常在 PoolThread.run()方法中被截获、报告，然后再检查 isStopped 变量。由于 isStopped 的值是 true, 因此 PoolThread.run()方法退出，子线程终止。




CAS

CAS（Compare and swap）比较和替换是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量的值。这听起来可能有一点复杂但是实际上你理解之后发现很简单，接下来，让我们跟深入的了解一下这项技术。

CAS 的使用场景
在程序和算法中一个经常出现的模式就是“check and act”模式。先检查后操作模式发生在代码中首先检查一个变量的值，然后再基于这个值做一些操作。下面是一个简单的示例：

class MyLock {

    private boolean locked = false;

    public boolean lock() {
        if(!locked) {
            locked = true;
            return true;
        }
        return false;
    }
}
上面这段代码，如果用在多线程的程序会出现很多错误，不过现在请忘掉它。

如你所见，lock()方法首先检查 locked>成员变量是否等于 false，如果等于，就将 locked 设为 true。

如果同个线程访问同一个 MyLock 实例，上面的 lock()将不能保证正常工作。如果一个线程检查 locked 的值，然后将其设置为 false，与此同时，一个线程 B 也在检查 locked 的值，又或者，在线程 A 将 locked 的值设为 false 之前。因此，线程 A 和线程 B 可能都看到 locked 的值为 false，然后两者都基于这个信息做一些操作。

为了在一个多线程程序中良好的工作，”check then act” 操作必须是原子的。原子就是说”check“操作和”act“被当做一个原子代码块执行。不存在多个线程同时执行原子块。

下面是一个代码示例，把之前的 lock()方法用 synchronized 关键字重构成一个原子块。

class MyLock {

    private boolean locked = false;

    public synchronized boolean lock() {
        if(!locked) {
            locked = true;
            return true;
        }
        return false;
    }
}
现在 lock()方法是同步的，所以，在某一时刻只能有一个线程在同一个 MyLock 实例上执行它。

原子的 lock 方法实际上是一个”compare and swap“的例子。

CAS 用作原子操作
现在 CPU 内部已经执行原子的 CAS 操作。Java5 以来，你可以使用 java.util.concurrent.atomic 包中的一些原子类来使用 CPU 中的这些功能。

下面是一个使用 AtomicBoolean 类实现 lock()方法的例子：

public static class MyLock {
    private AtomicBoolean locked = new AtomicBoolean(false);

    public boolean lock() {
        return locked.compareAndSet(false, true);
    }

}
locked 变量不再是 boolean 类型而是 AtomicBoolean。这个类中有一个 compareAndSet()方法，它使用一个期望值和 AtomicBoolean 实例的值比较，和两者相等，则使用一个新值替换原来的值。在这个例子中，它比较 locked 的值和 false，如果 locked 的值为 false，则把修改为 true。 如果值被替换了，compareAndSet()返回 true，否则，返回 false。

使用 Java5+提供的 CAS 特性而不是使用自己实现的的好处是 Java5+中内置的 CAS 特性可以让你利用底层的你的程序所运行机器的 CPU 的 CAS 特性。这会使还有 CAS 的代码运行更快。



剖析同步器

虽然许多同步器（如锁，信号量，阻塞队列等）功能上各不相同，但它们的内部设计上却差别不大。换句话说，它们内部的的基础部分是相同（或相似）的。了解这些基础部件能在设计同步器的时候给我们大大的帮助。这就是本文要细说的内容。

注：本文的内容是哥本哈根信息技术大学一个由 Jakob Jenkov，Toke Johansen 和 Lars Bjørn 参与的 M.Sc.学生项目的部分成果。在此项目期间我们咨询 Doug Lea 是否知道类似的研究。有趣的是在开发 Java 5 并发工具包期间他已经提出了类似的结论。Doug Lea 的研究，我相信，在《Java Concurrency in Practice》一书中有描述。这本书有一章“剖析同步器”就类似于本文，但不尽相同。

大部分同步器都是用来保护某个区域（临界区）的代码，这些代码可能会被多线程并发访问。要实现这个目标，同步器一般要支持下列功能：

状态
访问条件
状态变化
通知策略
Test-and-Set 方法
Set 方法
并不是所有同步器都包含上述部分，也有些并不完全遵照上面的内容。但通常你能从中发现这些部分的一或多个。

状态
同步器中的状态是用来确定某个线程是否有访问权限。在 Lock 中，状态是 boolean 类型的，表示当前 Lock 对象是否处于锁定状态。在 BoundedSemaphore 中，内部状态包含一个计数器（int 类型）和一个上限（int 类型），分别表示当前已经获取的许可数和最大可获取的许可数。BlockingQueue 的状态是该队列中元素列表以及队列的最大容量。

下面是 Lock 和 BoundedSemaphore 中的两个代码片段。

public class Lock{
  //state is kept here
  private boolean isLocked = false; 
  public synchronized void lock()
  throws InterruptedException{
    while(isLocked){
      wait();
    }
    isLocked = true;
  }
  ...
}
public class BoundedSemaphore {
  //state is kept here
  private int signals = 0;
  private int bound   = 0;

  public BoundedSemaphore(int upperBound){
    this.bound = upperBound;
  }
  public synchronized void take() throws InterruptedException{
    while(this.signals == bound) wait();
    this.signal++;
    this.notify();
  }
  ...
}
访问条件
访问条件决定调用 test-and-set-state 方法的线程是否可以对状态进行设置。访问条件一般是基于同步器状态的。通常是放在一个 while 循环里，以避免虚假唤醒问题。访问条件的计算结果要么是 true 要么是 false。

Lock 中的访问条件只是简单地检查 isLocked 的值。根据执行的动作是“获取”还是“释放”，BoundedSemaphore 实际上有两个访问条件。如果某个线程想“获取”许可，将检查 signals 变量是否达到上限；如果某个线程想“释放”许可，将检查 signals 变量是否为 0。

这里有两个来自 Lock 和 BoundedSemaphore 的代码片段，它们都有访问条件。注意观察条件是怎样在 while 循环中检查的。

public class Lock{
  private boolean isLocked = false;
  public synchronized void lock()
  throws InterruptedException{
    //access condition
    while(isLocked){
      wait();
    }
    isLocked = true;
  }
  ...
}
public class BoundedSemaphore {
  private int signals = 0;
  private int bound = 0;

  public BoundedSemaphore(int upperBound){
    this.bound = upperBound;
  }
  public synchronized void take() throws InterruptedException{
    //access condition
    while(this.signals == bound) wait();
    this.signals++;
    this.notify();
  }
  public synchronized void release() throws InterruptedException{
    //access condition
    while(this.signals == 0) wait();
    this.signals--;
    this.notify();
  }
}
状态变化
一旦一个线程获得了临界区的访问权限，它得改变同步器的状态，让其它线程阻塞，防止它们进入临界区。换而言之，这个状态表示正有一个线程在执行临界区的代码。其它线程想要访问临界区的时候，该状态应该影响到访问条件的结果。

在 Lock 中，通过代码设置 isLocked = true 来改变状态，在信号量中，改变状态的是 signals–或 signals++;

这里有两个状态变化的代码片段：

public class Lock{

  private boolean isLocked = false;

  public synchronized void lock()
  throws InterruptedException{
    while(isLocked){
      wait();
    }
    //state change
    isLocked = true;
  }

  public synchronized void unlock(){
    //state change
    isLocked = false;
    notify();
  }
}
public class BoundedSemaphore {
  private int signals = 0;
  private int bound   = 0;

  public BoundedSemaphore(int upperBound){
    this.bound = upperBound;
  }

  public synchronized void take() throws InterruptedException{
    while(this.signals == bound) wait();
    //state change
    this.signals++;
    this.notify();
  }

  public synchronized void release() throws InterruptedException{
    while(this.signals == 0) wait();
    //state change
    this.signals--;
    this.notify();
  }
}
通知策略
一旦某个线程改变了同步器的状态，可能需要通知其它等待的线程状态已经变了。因为也许这个状态的变化会让其它线程的访问条件变为 true。

通知策略通常分为三种：

通知所有等待的线程
通知 N 个等待线程中的任意一个
通知 N 个等待线程中的某个指定的线程
通知所有等待的线程非常简单。所有等待的线程都调用的同一个对象上的 wait()方法，某个线程想要通知它们只需在这个对象上调用 notifyAll()方法。

通知等待线程中的任意一个也很简单，只需将 notifyAll()调用换成 notify()即可。调用 notify 方法没办法确定唤醒的是哪一个线程，也就是“等待线程中的任意一个”。

有时候可能需要通知指定的线程而非任意一个等待的线程。例如，如果你想保证线程被通知的顺序与它们进入同步块的顺序一致，或按某种优先级的顺序来通知。想要实现这种需求，每个等待的线程必须在其自有的对象上调用 wait()。当通知线程想要通知某个特定的等待线程时，调用该线程自有对象的 notify()方法即可。饥饿和公平中有这样的例子。

下面是通知策略的一个例子（通知任意一个等待线程）：

public class Lock{

  private boolean isLocked = false;

  public synchronized void lock()
  throws InterruptedException{
    while(isLocked){
      //wait strategy - related to notification strategy
      wait();
    }
    isLocked = true;
  }

  public synchronized void unlock(){
    isLocked = false;
    notify(); //notification strategy
  }
}
Test-and-Set 方法
同步器中最常见的有两种类型的方法，test-and-set 是第一种（set 是另一种）。Test-and-set 的意思是，调用这个方法的线程检查访问条件，如若满足，该线程设置同步器的内部状态来表示它已经获得了访问权限。

状态的改变通常使其它试图获取访问权限的线程计算条件状态时得到 false 的结果，但并不一定总是如此。例如，在读写锁中，获取读锁的线程会更新读写锁的状态来表示它获取到了读锁，但是，只要没有线程请求写锁，其它请求读锁的线程也能成功。

test-and-set 很有必要是原子的，也就是说在某个线程检查和设置状态期间，不允许有其它线程在 test-and-set 方法中执行。

test-and-set 方法的程序流通常遵照下面的顺序：

如有必要，在检查前先设置状态
检查访问条件
如果访问条件不满足，则等待
如果访问条件满足，设置状态，如有必要还要通知等待线程
下面的 ReadWriteLock 类的 lockWrite()方法展示了 test-and-set 方法。调用 lockWrite()的线程在检查之前先设置状态(writeRequests++)。然后检查 canGrantWriteAccess()中的访问条件，如果检查通过，在退出方法之前再次设置内部状态。这个方法中没有去通知等待线程。

public class ReadWriteLock{
    private Map<Thread, Integer> readingThreads =
        new HashMap<Thread, Integer>();

    private int writeAccesses    = 0;
    private int writeRequests    = 0;
    private Thread writingThread = null;

    ...

    public synchronized void lockWrite() throws InterruptedException{
      writeRequests++;
      Thread callingThread = Thread.currentThread();
      while(! canGrantWriteAccess(callingThread)){
        wait();
      }
      writeRequests--;
      writeAccesses++;
      writingThread = callingThread;
    } 

    ...
}
下面的 BoundedSemaphore 类有两个 test-and-set 方法：take()和 release()。两个方法都有检查和设置内部状态。

public class BoundedSemaphore {
  private int signals = 0;
  private int bound   = 0;

  public BoundedSemaphore(int upperBound){
    this.bound = upperBound;
  }

  public synchronized void take() throws InterruptedException{
    while(this.signals == bound) wait();
    this.signals++;
    this.notify();
  }

  public synchronized void release() throws InterruptedException{
    while(this.signals == 0) wait();
    this.signals--;
    this.notify();
  }
}
set 方法

set 方法是同步器中常见的第二种方法。set 方法仅是设置同步器的内部状态，而不先做检查。set 方法的一个典型例子是 Lock 类中的 unlock()方法。持有锁的某个线程总是能够成功解锁，而不需要检查该锁是否处于解锁状态。

set 方法的程序流通常如下：

设置内部状态
通知等待的线程
这里是 unlock()方法的一个例子：

public class Lock{
  private boolean isLocked = false;

  public synchronized void unlock(){
    isLocked = false;
    notify();
  }
}





无阻塞算法

在并发上下文中，非阻塞算法是一种允许线程在阻塞其他线程的情况下访问共享状态的算法。在绝大多数项目中，在算法中如果一个线程的挂起没有导致其它的线程挂起，我们就说这个算法是非阻塞的。

为了更好的理解阻塞算法和非阻塞算法之间的区别，我会先讲解阻塞算法然后再讲解非阻塞算法。

阻塞并发算法
一个阻塞并发算法一般分下面两步：

执行线程请求的操作
阻塞线程直到可以安全地执行操作
很多算法和并发数据结构都是阻塞的。例如，java.util.concurrent.BlockingQueue 的不同实现都是阻塞数据结构。如果一个线程要往一个阻塞队列中插入一个元素，队列中没有足够的空间，执行插入操作的线程就会阻塞直到队列中有了可以存放插入元素的空间。

下图演示了一个阻塞算法保证一个共享数据结构的行为：



非阻塞并发算法
一个非阻塞并发算法一般包含下面两步：

执行线程请求的操作
通知请求线程操作不能被执行
Java 也包含几个非阻塞数据结构。AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference 都是非阻塞数据结构的例子。

下图演示了一个非阻塞算法保证一个共享数据结构的行为：



非阻塞算法 vs 阻塞算法
阻塞算法和非阻塞算法的主要不同在于上面两部分描述的它们的行为的第二步。换句话说，它们之间的不同在于当请求操作不能够执行时阻塞算法和非阻塞算法会怎么做。

阻塞算法会阻塞线程知道请求操作可以被执行。非阻塞算法会通知请求线程操作不能够被执行，并返回。

一个使用了阻塞算法的线程可能会阻塞直到有可能去处理请求。通常，其它线程的动作使第一个线程执行请求的动作成为了可能。 如果，由于某些原因线程被阻塞在程序某处，因此不能让第一个线程的请求动作被执行，第一个线程会阻塞——可能一直阻塞或者直到其他线程执行完必要的动作。

例如，如果一个线程产生往一个已经满了的阻塞队列里插入一个元素，这个线程就会阻塞，直到其他线程从这个阻塞队列中取走了一些元素。如果由于某些原因，从阻塞队列中取元素的线程假定被阻塞在了程序的某处，那么，尝试往阻塞队列中添加新元素的线程就会阻塞，要么一直阻塞下去，要么知道从阻塞队列中取元素的线程最终从阻塞队列中取走了一个元素。

非阻塞并发数据结构
在一个多线程系统中，线程间通常通过一些数据结构”交流“。例如可以是任何的数据结构，从变量到更高级的俄数据结构（队列，栈等）。为了确保正确，并发线程在访问这些数据结构的时候，这些数据结构必须由一些并发算法来保证。这些并发算法让这些数据结构成为并发数据结构。

如果某个算法确保一个并发数据结构是阻塞的，它就被称为是一个阻塞算法。这个数据结构也被称为是一个阻塞，并发数据结构。

如果某个算法确保一个并发数据结构是非阻塞的，它就被称为是一个非阻塞算法。这个数据结构也被称为是一个非阻塞，并发数据结构。

每个并发数据结构被设计用来支持一个特定的通信方法。使用哪种并发数据结构取决于你的通信需要。在接下里的部分，我会引入一些非阻塞并发数据结构，并讲解它们各自的适用场景。通过这些并发数据结构工作原理的讲解应该能在非阻塞数据结构的设计和实现上一些启发。

Volatile 变量
Java 中的 volatile 变量是直接从主存中读取值的变量。当一个新的值赋给一个 volatile 变量时，这个值总是会被立即写回到主存中去。这样就确保了，一个 volatile 变量最新的值总是对跑在其他 CPU 上的线程可见。其他线程每次会从主存中读取变量的值，而不是比如线程所运行 CPU 的 CPU 缓存中。

colatile 变量是非阻塞的。修改一个 volatile 变量的值是一耳光原子操作。它不能够被中断。不过，在一个 volatile 变量上的一个 read-update-write 顺序的操作不是原子的。因此，下面的代码如果由多个线程执行可能导致竞态条件。

volatile myVar = 0;
...
int temp = myVar;
temp++;
myVar = temp;
首先，myVar 这个 volatile 变量的值被从主存中读出来赋给了 temp 变量。然后，temp 变量自增 1。然后，temp 变量的值又赋给了 myVar 这个 volatile 变量这意味着它会被写回到主存中。

如果两个线程执行这段代码，然后它们都读取 myVar 的值，加 1 后，把它的值写回到主存。这样就存在 myVar 仅被加 1，而没有被加 2 的风险。

你可能认为你不会写像上面这样的代码，但是在实践中上面的代码等同于如下的代码：

myVar++;
执行上面的代码时，myVar 的值读到一个 CPU 寄存器或者一个本地 CPU 缓存中，myVar 加 1，然后这个 CPU 寄存器或者 CPU 缓存中的值被写回到主存中。

单个写线程的情景
在一些场景下，你仅有一个线程在向一个共享变量写，多个线程在读这个变量。当仅有一个线程在更新一个变量，不管有多少个线程在读这个变量，都不会发生竞态条件。因此，无论时候当仅有一个线程在写一个共享变量时，你可以把这个变量声明为 volatile。

当多个线程在一个共享变量上执行一个 read-update-write 的顺序操作时才会发生竞态条件。如果你只有一个线程在执行一个 raed-update-write 的顺序操作，其他线程都在执行读操作，将不会发生竞态条件。

下面是一个单个写线程的例子，它没有采取同步手段但任然是并发的。

public class SingleWriterCounter{
    private volatile long count = 0;

    /**
     *Only one thread may ever call this method
     *or it will lead to race conditions
     */
     public void inc(){
         this.count++;
     }

     /**
      *Many reading threads may call this method
      *@return
      */
      public long count(){
          return this.count;
      }
}
多个线程访问同一个 Counter 实例，只要仅有一个线程调用 inc()方法，这里，我不是说在某一时刻一个线程，我的意思是，仅有相同的，单个的线程被允许去调用 inc()>方法。多个线程可以调用 count()方法。这样的场景将不会发生任何竞态条件。

下图，说明了线程是如何访问 count 这个 volatile 变量的。



基于 volatile 变量更高级的数据结构
使用多个 volatile 变量去创建数据结构是可以的，构建出的数据结构中每一个 volatile 变量仅被一个单个的线程写，被多个线程读。每个 volatile 变量可能被一个不同的线程写（但仅有一个）。使用像这样的数据结构多个线程可以使用这些 volatile 变量以一个非阻塞的方法彼此发送信息。

下面是一个简单的例子：

public class DoubleWriterCounter{
    private volatile long countA = 0;
    private volatile long countB = 0;

    /**
     *Only one (and the same from thereon) thread may ever call this method,
     *or it will lead to race conditions.
     */
     public void incA(){
         this.countA++;
     }

     /**
      *Only one (and the same from thereon) thread may ever call this method, 
      *or it will  lead to race conditions.
      */
      public void incB(){
          this.countB++;
      }

      /**
       *Many reading threads may call this method
       */
      public long countA(){
          return this.countA;
      }

     /**
      *Many reading threads may call this method
      */
      public long countB(){
          return this.countB;
      }
}
如你所见，DoubleWriterCoounter 现在包含两个 volatile 变量以及两对自增和读方法。在某一时刻，仅有一个单个的线程可以调用 inc()，仅有一个单个的线程可以访问 incB()。不过不同的线程可以同时调用 incA()和 incB()。countA()和 countB()可以被多个线程调用。这将不会引发竞态条件。

DoubleWriterCoounter 可以被用来比如线程间通信。countA 和 countB 可以分别用来存储生产的任务数和消费的任务数。下图，展示了两个线程通过类似于上面的一个数据结构进行通信的。



聪明的读者应该已经意识到使用两个 SingleWriterCounter 可以达到使用 DoubleWriterCoounter 的效果。如果需要，你甚至可以使用多个线程和 SingleWriterCounter 实例。

使用 CAS 的乐观锁
如果你确实需要多个线程区写同一个共享变量，volatile 变量是不合适的。你将会需要一些类型的排它锁（悲观锁）访问这个变量。下面代码演示了使用 Java 中的同步块进行排他访问的。
public class SynchronizedCounter{
    long count = 0;

    public void inc(){
        synchronized(this){
            count++;
        }
    }

    public long count(){
        synchronized(this){
            return this.count;
        }
    }
}
注意，inc()和 count()方法都包含一个同步块。这也是我们像避免的东西——同步块和 wait()-notify 调用等。

我们可以使用一种 Java 的原子变量来代替这两个同步块。在这个例子是 AtomicLong。下面是 SynchronizedCounter 类的 AtomicLong 实现版本。

import java.util.concurrent.atomic.AtomicLong;

public class AtomicLong{
    private AtomicLong count = new AtomicLong(0);

    public void inc(){
        boolean updated = false;
        while(!updated){
            long prevCount = this.count.get();
            updated = this.count.compareAndSet(prevCount, prevCount + 1);
        }
    }

    public long count(){
        return this.count.get();
    }
}
这个版本仅仅是上一个版本的线程安全版本。这一版我们感兴趣的是 inc()方法的实现。inc()方法中不再含有一个同步块。而是被下面这些代码替代：
boolean updated = false;
while(!updated){
    long prevCount = this.count.get();
    updated = this.count.compareAndSet(prevCount, prevCount + 1);
}
上面这些代码并不是一个原子操作。也就是说，对于两个不同的线程去调用 inc()方法，然后执行 long prevCount = this.count.get()语句，因此获得了这个计数器的上一个 count。但是，上面的代码并没有包含任何的竞态条件。

秘密就在于 while 循环里的第二行代码。compareAndSet()方法调用是一个原子操作。它用一个期望值和 AtomicLong 内部的值去比较，如果这两个值相等，就把 AtomicLong 内部值替换为一个新值。compareAndSet()通常被 CPU 中的 compare-and-swap 指令直接支持。因此，不需要去同步，也不需要去挂起线程。

假设，这个 AtomicLong 的内部值是 20。然后，两个线程去读这个值，都尝试调用 compareAndSet(20, 20 + 1)。尽管 compareAndSet()是一个原子操作，这个方法也会被这两个线程相继执行（某一个时刻只有一个）。

第一个线程会使用期望值 20（这个计数器的上一个值）与 AtomicLong 的内部值进行比较。由于两个值是相等的，AtomicLong 会更新它的内部值至 21（20 + 1 ）。变量 updated 被修改为 true，while 循环结束。

现在，第二个线程调用 compareAndSet(20, 20 + 1)。由于 AtomicLong 的内部值不再是 20，这个调用将不会成功。AtomicLong 的值不会再被修改为 21。变量，updated 被修改为 false，线程将会再次在 while 循环外自旋。这段时间，它会读到值 21 并企图把值更新为 22。如果在此期间没有其它线程调用 inc()。第二次迭代将会成功更新 AtomicLong 的内部值到 22。

为什么称它为乐观锁
上一部分展现的代码被称为乐观锁（optimistic locking）。乐观锁区别于传统的锁，有时也被称为悲观锁。传统的锁会使用同步块或其他类型的锁阻塞对临界区域的访问。一个同步块或锁可能会导致线程挂起。

乐观锁允许所有的线程在不发生阻塞的情况下创建一份共享内存的拷贝。这些线程接下来可能会对它们的拷贝进行修改，并企图把它们修改后的版本写回到共享内存中。如果没有其它线程对共享内存做任何修改， CAS 操作就允许线程将它的变化写回到共享内存中去。如果，另一个线程已经修改了共享内存，这个线程将不得不再次获得一个新的拷贝，在新的拷贝上做出修改，并尝试再次把它们写回到共享内存中去。

称之为“乐观锁”的原因就是，线程获得它们想修改的数据的拷贝并做出修改，在乐观的假在此期间没有线程对共享内存做出修改的情况下。当这个乐观假设成立时，这个线程仅仅在无锁的情况下完成共享内存的更新。当这个假设不成立时，线程所做的工作就会被丢弃，但任然不使用锁。

乐观锁使用于共享内存竞用不是非常高的情况。如果共享内存上的内容非常多，仅仅因为更新共享内存失败，就用浪费大量的 CPU 周期用在拷贝和修改上。但是，如果砸共享内存上有大量的内容，无论如何，你都要把你的代码设计的产生的争用更低。

乐观锁是非阻塞的
我们这里提到的乐观锁机制是非阻塞的。如果一个线程获得了一份共享内存的拷贝，当尝试修改时，发生了阻塞，其它线程去访问这块内存区域不会发生阻塞。

对于一个传统的加锁/解锁模式，当一个线程持有一个锁时，其它所有的线程都会一直阻塞直到持有锁的线程再次释放掉这个锁。如果持有锁的这个线程被阻塞在某处，这个锁将很长一段时间不能被释放，甚至可能一直不能被释放。

不可替换的数据结构
简单的 CAS 乐观锁可以用于共享数据结果，这样一来，整个数据结构都可以通过一个单个的 CAS 操作被替换成为一个新的数据结构。尽管，使用一个修改后的拷贝来替换真个数据结构并不总是可行的。

假设，这个共享数据结构是队列。每当线程尝试从向队列中插入或从队列中取出元素时，都必须拷贝这个队列然后在拷贝上做出期望的修改。我们可以通过使用一个 AtomicReference 来达到同样的目的。拷贝引用，拷贝和修改队列，尝试替换在 AtomicReference 中的引用让它指向新创建的队列。

然而，一个大的数据结构可能会需要大量的内存和 CPU 周期来复制。这会使你的程序占用大量的内存和浪费大量的时间再拷贝操作上。这将会降低你的程序的性能，特别是这个数据结构的竞用非常高情况下。更进一步说，一个线程花费在拷贝和修改这个数据结构上的时间越长，其它线程在此期间修改这个数据结构的可能性就越大。如你所知，如果另一个线程修改了这个数据结构在它被拷贝后，其它所有的线程都不等不再次执行 拷贝-修改 操作。这将会增大性能影响和内存浪费，甚至更多。

接下来的部分将会讲解一种实现非阻塞数据结构的方法，这种数据结构可以被并发修改，而不仅仅是拷贝和修改。

共享预期的修改
用来替换拷贝和修改整个数据结构，一个线程可以共享它们对共享数据结构预期的修改。一个线程向对修改某个数据结构的过程变成了下面这样：

检查是否另一个线程已经提交了对这个数据结构提交了修改
如果没有其他线程提交了一个预期的修改，创建一个预期的修改，然后向这个数据结构提交预期的修
执行对共享数据结构的修改
移除对这个预期的修改的引用，向其它线程发送信号，告诉它们这个预期的修改已经被执行
如你所见，第二步可以阻塞其他线程提交一个预期的修改。因此，第二步实际的工作是作为这个数据结构的一个锁。如果一个线程已经成功提交了一个预期的修改，其他线程就不可以再提交一个预期的修改直到第一个预期的修改执行完毕。

如果一个线程提交了一个预期的修改，然后做一些其它的工作时发生阻塞，这时候，这个共享数据结构实际上是被锁住的。其它线程可以检测到它们不能够提交一个预期的修改，然后回去做一些其它的事情。很明显，我们需要解决这个问题。

可完成的预期修改
为了避免一个已经提交的预期修改可以锁住共享数据结构，一个已经提交的预期修改必须包含足够的信息让其他线程来完成这次修改。因此，如果一个提交了预期修改的线程从未完成这次修改，其他线程可以在它的支持下完成这次修改，保证这个共享数据结构对其他线程可用。

下图说明了上面描述的非阻塞算法的蓝图：



修改必须被当做一个或多个 CAS 操作来执行。因此，如果两个线程尝试去完成同一个预期修改，仅有一个线程可以所有的 CAS 操作。一旦一条 CAS 操作完成后，再次企图完成这个 CAS 操作都不会“得逞”。

A-B-A 问题
上面演示的算法可以称之为 A-B-A 问题。A-B-A 问题指的是一个变量被从 A 修改到了 B，然后又被修改回 A 的一种情景。其他线程对于这种情况却一无所知。

如果线程 A 检查正在进行的数据更新，拷贝，被线程调度器挂起，一个线程 B 在此期可能可以访问这个共享数据结构。如果线程对这个数据结构执行了全部的更新，移除了它的预期修改，这样看起来，好像线程 A 自从拷贝了这个数据结构以来没有对它做任何的修改。然而，一个修改确实已经发生了。当线程 A 继续基于现在已经过期的数据拷贝执行它的更新时，这个数据修改已经被线程 B 的修改破坏。

下图说明了上面提到的 A-B-A 问题：



A-B-A 问题的解决方案
A-B-A 通常的解决方法就是不再仅仅替换指向一个预期修改对象的指针，而是指针结合一个计数器，然后使用一个单个的 CAS 操作来替换指针 + 计数器。这在支持指针的语言像 C 和 C++中是可行的。因此，尽管当前修改指针被设置回指向 “不是正在进行的修改”（no ongoing modification），指针 + 计数器的计数器部分将会被自增，使修改对其它线程是可见的。

在 Java 中，你不能将一个引用和一个计数器归并在一起形成一个单个的变量。不过 Java 提供了 AtomicStampedReference 类，利用这个类可以使用一个 CAS 操作自动的替换一个引用和一个标记（stamp）。

一个非阻塞算法模板
下面的代码意在在如何实现非阻塞算法上一些启发。这个模板基于这篇教程所讲的东西。

注意：在非阻塞算法方面，我并不是一位专家，所以，下面的模板可能错误。不要基于我提供的模板实现自己的非阻塞算法。这个模板意在给你一个关于非阻塞算法大致是什么样子的一个 idea。如果，你想实现自己的非阻塞算法，首先学习一些实际的工业水平的非阻塞算法的时间，在实践中学习更多关于非阻塞算法实现的知识。

import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicStampedReference;

public class NonblockingTemplate{
    public static class IntendedModification{
        public AtomicBoolean completed = new AtomicBoolean(false);
    }

    private AtomicStampedReference<IntendedModification> ongoinMod = new AtomicStampedReference<IntendedModification>(null, 0);
    //declare the state of the data structure here.

    public void modify(){
        while(!attemptModifyASR());
    }

    public boolean attemptModifyASR(){
        boolean modified = false;

        IntendedMOdification currentlyOngoingMod = ongoingMod.getReference();
        int stamp = ongoingMod.getStamp();

        if(currentlyOngoingMod == null){
            //copy data structure - for use
            //in intended modification

            //prepare intended modification
            IntendedModification newMod = new IntendModification();

            boolean modSubmitted = ongoingMod.compareAndSet(null, newMod, stamp, stamp + 1);

            if(modSubmitted){
                 //complete modification via a series of compare-and-swap operations.
                //note: other threads may assist in completing the compare-and-swap
                // operations, so some CAS may fail
                modified = true;
            }
        }else{
             //attempt to complete ongoing modification, so the data structure is freed up
            //to allow access from this thread.
            modified = false;
        }

        return modified;
    }
}
非阻塞算法是不容易实现的
正确的设计和实现非阻塞算法是不容易的。在尝试设计你的非阻塞算法之前，看一看是否已经有人设计了一种非阻塞算法正满足你的需求。

Java 已经提供了一些非阻塞实现（比如 ConcurrentLinkedQueue），相信在 Java 未来的版本中会带来更多的非阻塞算法的实现。

除了 Java 内置非阻塞数据结构还有很多开源的非阻塞数据结构可以使用。例如，LAMX Disrupter 和 Cliff Click 实现的非阻塞 HashMap。查看我的 Java concurrency references page 查看更多的资源。

使用非阻塞算法的好处
非阻塞算法和阻塞算法相比有几个好处。下面让我们分别看一下：

选择

非阻塞算法的第一个好处是，给了线程一个选择当它们请求的动作不能够被执行时做些什么。不再是被阻塞在那，请求线程关于做什么有了一个选择。有时候，一个线程什么也不能做。在这种情况下，它可以选择阻塞或自我等待，像这样把 CPU 的使用权让给其它的任务。不过至少给了请求线程一个选择的机会。

在一个单个的 CPU 系统可能会挂起一个不能执行请求动作的线程，这样可以让其它线程获得 CPU 的使用权。不过即使在一个单个的 CPU 系统阻塞可能导致死锁，线程饥饿等并发问题。

没有死锁

非阻塞算法的第二个好处是，一个线程的挂起不能导致其它线程挂起。这也意味着不会发生死锁。两个线程不能互相彼此等待来获得被对方持有的锁。因为线程不会阻塞当它们不能执行它们的请求动作时，它们不能阻塞互相等待。非阻塞算法任然可能产生活锁（live lock），两个线程一直请求一些动作，但一直被告知不能够被执行（因为其他线程的动作）。

没有线程挂起

挂起和恢复一个线程的代价是昂贵的。没错，随着时间的推移，操作系统和线程库已经越来越高效，线程挂起和恢复的成本也不断降低。不过，线程的挂起和户对任然需要付出很高的代价。

无论什么时候，一个线程阻塞，就会被挂起。因此，引起了线程挂起和恢复过载。由于使用非阻塞算法线程不会被挂起，这种过载就不会发生。这就意味着 CPU 有可能花更多时间在执行实际的业务逻辑上而不是上下文切换。

在一个多个 CPU 的系统上，阻塞算法会对阻塞算法产生重要的影响。运行在 CPUA 上的一个线程阻塞等待运行在 CPU B 上的一个线程。这就降低了程序天生就具备的并行水平。当然，CPU A 可以调度其他线程去运行，但是挂起和激活线程（上下文切换）的代价是昂贵的。需要挂起的线程越少越好。

降低线程延迟

在这里我们提到的延迟指的是一个请求产生到线程实际的执行它之间的时间。因为在非阻塞算法中线程不会被挂起，它们就不需要付昂贵的，缓慢的线程激活成本。这就意味着当一个请求执行时可以得到更快的响应，减少它们的响应延迟。

非阻塞算法通常忙等待直到请求动作可以被执行来降低延迟。当然，在一个非阻塞数据数据结构有着很高的线程争用的系统中，CPU 可能在它们忙等待期间停止消耗大量的 CPU 周期。这一点需要牢牢记住。非阻塞算法可能不是最好的选择如果你的数据结构哦有着很高的线程争用。不过，也常常存在通过重构你的程序来达到更低的线程争用。






阿姆达尔定律

阿姆达尔定律可以用来计算处理器平行运算之后效率提升的能力。阿姆达尔定律因 Gene Amdal 在 1967 年提出这个定律而得名。绝大多数使用并行或并发系统的开发者有一种并发或并行可能会带来提速的感觉，甚至不知道阿姆达尔定律。不管怎样，了解阿姆达尔定律还是有用的。

我会首先以算术的方式介绍阿姆达尔定律定律，然后再用图表演示一下。

阿姆达尔定律定义
一个程序（或者一个算法）可以按照是否可以被并行化分为下面两个部分：

可以被并行化的部分
不可以被并行化的部分
假设一个程序处理磁盘上的文件。这个程序的一小部分用来扫描路径和在内存中创建文件目录。做完这些后，每个文件交个一个单独的线程去处理。扫描路径和创建文件目录的部分不可以被并行化，不过处理文件的过程可以。

程序串行（非并行）执行的总时间我们记为 T。时间 T 包括不可以被并行和可以被并行部分的时间。不可以被并行的部分我们记为 B。那么可以被并行的部分就是 T-B。下面的列表总结了这些定义：

T = 串行执行的总时间
B = 不可以并行的总时间
T- B = 并行部分的总时间
从上面可以得出：

T = B + (T – B)

首先，这个看起来可能有一点奇怪，程序的可并行部分在上面这个公式中并没有自己的标识。然而，由于这个公式中可并行可以用总时间 T 和 B（不可并行部分）表示出来，这个公式实际上已经从概念上得到了简化，也即是指以这种方式减少了变量的个数。

T- B 是可并行化的部分，以并行的方式执行可以提高程序的运行速度。可以提速多少取决于有多少线程或者多少个 CPU 来执行。线程或者 CPU 的个数我们记为 N。可并行化部分被执行的最快时间可以通过下面的公式计算出来：

(T – B ) / N

或者通过这种方式

(1 / N) * (T – B)

维基中使用的是第二种方式。

根据阿姆达尔定律，当一个程序的可并行部分使用 N 个线程或 CPU 执行时，执行的总时间为：

T(N) = B + ( T – B ) / N

T(N)指的是在并行因子为 N 时的总执行时间。因此，T(1)就执行在并行因子为 1 时程序的总执行时间。使用 T(1)代替 T，阿姆达尔定律定律看起来像这样：

T(N) = B + (T(1) – B) / N

表达的意思都是是一样的。

一个计算例子
为了更好的理解阿姆达尔定律，让我们来看一个计算的例子。执行一个程序的总时间设为 1。程序的不可并行化占 40%，按总时间 1 计算，就是 0.4，可并行部分就是 1–0.4=0.6.

在并行因子为 2 的情况下，程序的执行时间将会是：

T(2) = 0.4 + ( 1 - 0.4 ) / 2
 = 0.4 + 0.6 / 2
 = 0.4 + 0.3
 = 0.7
在并行因子为 5 的情况下，程序的执行时间将会是：

T(5) = 0.4 + ( 1 - 0.4 ) / 5
 = 0.4 + 0.6 / 6
 = 0.4 + 0.12
 = 0.52
阿姆达尔定律图示

为了更好地理解阿姆达尔定律，我会尝试演示这个定定律是如何诞生的。

首先，一个程序可以被分割为两部分，一部分为不可并行部分 B，一部分为可并行部分 1–B。如下图：



在顶部被带有分割线的那条直线代表总时间 T(1)。

下面你可以看到在并行因子为 2 的情况下的执行时间：



并行因子为 3 的情况：



优化算法
从阿姆达尔定律可以看出，程序的可并行化部分可以通过使用更多的硬件（更多的线程或 CPU）运行更快。对于不可并行化的部分，只能通过优化代码来达到提速的目的。因此，你可以通过优化不可并行化部分来提高你的程序的运行速度和并行能力。你可以对不可并行化在算法上做一点改动，如果有可能，你也可以把一些移到可并行化放的部分。

优化串行分量

如果你优化一个程序的串行化部分，你也可以使用阿姆达尔定律来计算程序优化后的执行时间。如果不可并行部分通过一个因子 O 来优化，那么阿姆达尔定律看起来就像这样：

T(O, N) = B / O + (1 - B / O) / N
记住，现在程序的不可并行化部分占了 B / O 的时间，所以，可并行化部分就占了 1 - B / O 的时间。

如果 B 为 0.1，O 为 2，N 为 5，计算看起来就像这样：

T(2,5) = 0.4 / 2 + (1 - 0.4 / 2) / 5
   = 0.2 + (1 - 0.4 / 2) / 5
   = 0.2 + (1 - 0.2) / 5
   = 0.2 + 0.8 / 5
   = 0.2 + 0.16
   = 0.36
运行时间 vs. 加速
到目前为止，我们只用阿姆达尔定律计算了一个程序或算法在优化后或者并行化后的执行时间。我们也可以使用阿姆达尔定律计算加速比（speedup），也就是经过优化后或者串行化后的程序或算法比原来快了多少。

如果旧版本的程序或算法的执行时间为 T，那么增速比就是：

Speedup = T / T(O , N);
为了计算执行时间，我们常常把 T 设为 1，加速比为原来时间的一个分数。公式大致像下面这样：

Speedup = 1 / T（O,N)
如果我们使用阿姆达尔定律来代替 T(O,N)，我们可以得到下面的公式：

Speedup = 1 / ( B / O + (1 - B / O) / N)
如果 B = 0.4， O = 2， N = 5， 计算变成下面这样：

Speedup = 1 / ( 0.4 / 2 + (1 - 0.4 / 2) / 5)
    = 1 / ( 0.2 + (1 - 0.4 / 2) / 5)
    = 1 / ( 0.2 + (1 - 0.2) / 5 )
    = 1 / ( 0.2 + 0.8 / 5 )
    = 1 / ( 0.2 + 0.16 )
    = 1 / 0.36
    = 2.77777 ...
上面的计算结果可以看出，如果你通过一个因子 2 来优化不可并行化部分，一个因子 5 来并行化可并行化部分，这个程序或算法的最新优化版本最多可以比原来的版本快 2.77777 倍。

测量，不要仅是计算
虽然阿姆达尔定律允许你并行化一个算法的理论加速比，但是不要过度依赖这样的计算。在实际场景中，当你优化或并行化一个算法时，可以有很多的因子可以被考虑进来。

内存的速度，CPU 缓存，磁盘，网卡等可能都是一个限制因子。如果一个算法的最新版本是并行化的，但是导致了大量的 CPU 缓存浪费，你可能不会再使用 xN 个 CPU 来获得 xN 的期望加速。如果你的内存总线（memory bus），磁盘，网卡或者网络连接都处于高负载状态，也是一样的情况。

我们的建议是，使用阿姆达尔定律定律来指导我们优化程序，而不是用来测量优化带来的实际加速比。记住，有时候一个高度串行化的算法胜过一个并行化的算法，因为串行化版本不需要进行协调管理（上下文切换），而且一个单个的 CPU 在底层硬件工作（CPU 管道、CPU 缓存等）上的一致性可能更好。


 